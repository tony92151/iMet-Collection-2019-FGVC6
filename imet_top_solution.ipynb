{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pytorch_seresnext101-32x4d+kfold+focal loss v3.0\n",
    "\n",
    "\n",
    "* fold = 4\n",
    "* epoch = 3\n",
    "* Î³=0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov 22 00:31:16 2019       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 418.56       Driver Version: 418.56       CUDA Version: 10.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:01:00.0  On |                  N/A |\r\n",
      "| 41%   68C    P0    79W / 250W |    625MiB / 11175MiB |    100%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:02:00.0 Off |                  N/A |\r\n",
      "| 34%   64C    P0    66W / 250W |      2MiB / 11178MiB |     32%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0      1137      G   /usr/lib/xorg/Xorg                            84MiB |\r\n",
      "|    0      2214      G   /opt/teamviewer/tv_bin/TeamViewer              2MiB |\r\n",
      "|    0     12945      G   ...uest-channel-token=14083820793621432878    85MiB |\r\n",
      "|    0     22250      G   /usr/lib/xorg/Xorg                           170MiB |\r\n",
      "|    0     22494      G                                                  4MiB |\r\n",
      "|    0     22924      G   compiz                                       140MiB |\r\n",
      "|    0     23722      G   /usr/lib/firefox/firefox                       2MiB |\r\n",
      "|    0     31156      G   ...uest-channel-token=12496746042476819744    88MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageOps, ImageFilter\n",
    "from datetime import datetime\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, models, transforms\n",
    "import random\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "import cv2  \n",
    "from sklearn import preprocessing \n",
    "from sklearn.model_selection import KFold\n",
    "import h5py\n",
    "\n",
    "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import (\n",
    "    HorizontalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
    "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, RandomBrightnessContrast, IAAPiecewiseAffine,\n",
    "    IAASharpen, IAAEmboss, Flip, OneOf, Compose,RandomContrast,RandomBrightness,Resize\n",
    ")\n",
    "import albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from prefetch_generator import BackgroundGenerator\n",
    "\n",
    "class DataLoaderX(DataLoader):\n",
    "\n",
    "    def __iter__(self):\n",
    "        return BackgroundGenerator(super().__iter__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user1/Downloads/imet-2019-practice\n"
     ]
    }
   ],
   "source": [
    "# os.chdir(\"../input/pretrained_PyTorch/\")\n",
    "path = os.getcwd()\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(path+\"/train.csv\")\n",
    "lable = pd.read_csv(path+\"/labels.csv\")\n",
    "test = pd.read_csv(path+\"/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109237\n",
      "1103\n",
      "38801\n"
     ]
    }
   ],
   "source": [
    "lable_length = len(lable)\n",
    "train_length = len(train)\n",
    "test_length = len(test)\n",
    "print(train_length)\n",
    "print(lable_length)\n",
    "print(test_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[397 'culture::zurich']\n",
      "[398 'tag::abbies']\n",
      "398\n",
      "705\n"
     ]
    }
   ],
   "source": [
    "print(np.array(lable)[397])\n",
    "print(np.array(lable)[398])\n",
    "c_length = len(np.array(lable)[:398])\n",
    "t_length = len(np.array(lable)[398:])\n",
    "print(c_length)\n",
    "print(t_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.array(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.array(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(p=.5):\n",
    "    return Compose([\n",
    "        HorizontalFlip(p=0.5),\n",
    "        OneOf([\n",
    "            RandomBrightness(0.1, p=1),\n",
    "            RandomContrast(0.1, p=1),\n",
    "        ], p=0.3),\n",
    "        ShiftScaleRotate(shift_limit=0.1, scale_limit=0.0, rotate_limit=15, p=0.3),\n",
    "        IAAAdditiveGaussianNoise(p=0.3),\n",
    "        Resize(100,100)\n",
    "    ], p=p)\n",
    "def strong_aug(p=.5):\n",
    "    return Compose([\n",
    "        RandomRotate90(),\n",
    "        Flip(),\n",
    "        Transpose(),\n",
    "        OneOf([\n",
    "            IAAAdditiveGaussianNoise(),\n",
    "            GaussNoise(),\n",
    "        ], p=0.2),\n",
    "        OneOf([\n",
    "            MotionBlur(p=.2),\n",
    "            MedianBlur(blur_limit=3, p=0.1),\n",
    "            Blur(blur_limit=3, p=0.1),\n",
    "        ], p=0.2),\n",
    "        ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=45, p=0.2),\n",
    "        OneOf([\n",
    "            OpticalDistortion(p=0.3),\n",
    "            GridDistortion(p=.1),\n",
    "            IAAPiecewiseAffine(p=0.3),\n",
    "        ], p=0.2),\n",
    "        OneOf([\n",
    "            CLAHE(clip_limit=2),\n",
    "            IAASharpen(),\n",
    "            IAAEmboss(),\n",
    "            RandomBrightnessContrast(),            \n",
    "        ], p=0.3),\n",
    "        HueSaturationValue(p=0.3),\n",
    "    ], p=p)\n",
    "\n",
    "aug = augment(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creatData(train,lable_length):\n",
    "    train = np.array(train)\n",
    "    trainA_data = []\n",
    "    lab_data = []\n",
    "    #trainC_data = []\n",
    "    #trainT_data = []\n",
    "    for t in range(train_length):\n",
    "        v = np.zeros(lable_length)\n",
    "        #print(train[t,1])\n",
    "        lab = []\n",
    "        for s in train[t,1].split(\" \"):\n",
    "            #print(s)\n",
    "            v[int(s)] = 1\n",
    "            lab.append(int(s))\n",
    "            \n",
    "#         img = Image.open(path+\"/train/\"+format(train[t,0])+'.png')  # PIL image\n",
    "#         img = cv2.cvtColor(np.asarray(img),cv2.COLOR_RGB2BGR)\n",
    "#         img = aug(image = img)['image']\n",
    "#         #openCV to PIL\n",
    "#         img = Image.fromarray(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "        trainA_data.append([train[t,0],v])\n",
    "        lab_data.append([train[t,0],np.array(lab)])\n",
    "\n",
    "        #trainC_data.append([train[t,0],v[:c_length]])\n",
    "        #trainT_data.append([train[t,0],v[c_length:]])\n",
    "    return np.array(trainA_data),np.array(lab_data)\n",
    "    #return np.array(trainA_data)#,np.array(trainC_data),np.array(trainT_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_a,train_lab = creatData(train,lable_length)\n",
    "#train_a,train_c,train_t = creatData(train,lable_length)\n",
    "#train_t.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1000483014d91860', array([147, 616, 813])], dtype=object)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lab[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove the item that only have one feature (not work well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfilter(data,th):\n",
    "    dfilter = []\n",
    "    for i in range(len(data)):\n",
    "        if train_a[i][1].sum()>th:\n",
    "            dfilter.append(train_a[i])\n",
    "    return np.array(dfilter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafilter = dfilter(train_a,1) # remain feature great then 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount of image before: 109237\n",
      "amount of image after: 104913\n"
     ]
    }
   ],
   "source": [
    "print(\"amount of image before: {}\".format(len(train_a)))\n",
    "\n",
    "print(\"amount of image after: {}\".format(len(datafilter)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not use\n",
    "datafilter = train_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1000483014d91860', array([0., 0., 0., ..., 0., 0., 0.])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datafilter[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_resize = 200\n",
    "data_transforms2 = transforms.Compose([\n",
    "    transforms.Resize((image_resize,image_resize)),\n",
    "    #transforms.RandomResizedCrop(250),\n",
    "    #transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "            [0.485, 0.456, 0.406], \n",
    "            [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((image_resize,image_resize)),\n",
    "    #transforms.RandomResizedCrop(250),\n",
    "    #transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize(\n",
    "    #        [0.485, 0.456, 0.406], \n",
    "    #        [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "train_transformer = transforms.Compose([\n",
    "    transforms.Resize((128,128)),              # resize the image to \n",
    "    #transforms.RandomHorizontalFlip(),  # randomly flip image horizontally\n",
    "    #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    transforms.ToTensor(),           # transform it into a PyTorch Tensor\n",
    "    #transforms.Normalize(mean = (0.5, 0.5, 0.5), std = (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_transforms = transforms.Compose([\n",
    "#     augment()['image'],\n",
    "#     transforms.Resize((image_resize,image_resize)),\n",
    "#     HorizontalFlip(p=0.5),\n",
    "#     OneOf([\n",
    "#         RandomBrightness(0.1, p=1),\n",
    "#         RandomContrast(0.1, p=1),\n",
    "#     ], p=0.3),\n",
    "#     ShiftScaleRotate(shift_limit=0.1, scale_limit=0.0, rotate_limit=15, p=0.3),\n",
    "#     IAAAdditiveGaussianNoise(p=0.3),\n",
    "#     #transforms.RandomResizedCrop(250),\n",
    "#     #transforms.RandomHorizontalFlip(),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(\n",
    "#             [0.485, 0.456, 0.406], \n",
    "#             [0.229, 0.224, 0.225])\n",
    "#     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset_h5(torch.utils.data.Dataset):\n",
    "    def __init__(self, in_file, transform, kdata):\n",
    "        super(dataset_h5, self).__init__()\n",
    "\n",
    "        self.file = h5py.File(in_file, 'r')\n",
    "        self.n_images = len(kdata)\n",
    "        self.kdata = kdata\n",
    "        self.transform = transform\n",
    "        self.preloadimg = self.file['train_img'][self.kdata,:,:]\n",
    "        self.preloadleb = self.file['train_labels'][self.kdata,:]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        input_img = Image.fromarray(self.preloadimg[index])\n",
    "        \n",
    "        input_img = self.transform(input_img)\n",
    "        \n",
    "        input_lab = self.preloadleb[index]\n",
    "        return input_img,input_lab\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class trainDataset(Dataset):\n",
    "    def __init__(self, train_lib, transform,transform2):\n",
    "        self.filenames = train_lib[:,0]\n",
    "        self.labels = train_lib[:,1]\n",
    "        self.transform = transform\n",
    "        self.transform2 = transform2\n",
    "        #self.new_feature = \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(path+\"/train/\"+format(self.filenames[idx])+'.png')  # PIL image\n",
    "        \n",
    "        #PIL to openCV\n",
    "        imgv = cv2.cvtColor(np.asarray(img),cv2.COLOR_RGB2BGR)\n",
    "        imgv = aug(image = imgv)['image']\n",
    "        #openCV to PIL\n",
    "        img = Image.fromarray(cv2.cvtColor(imgv,cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "        #image= image.filter(ImageFilter.EDGE_ENHANCE)\n",
    "        #image2 = image.filter(ImageFilter.FIND_EDGES)\n",
    "        image = self.transform(img)\n",
    "        image2 = self.transform2(img)\n",
    "        #return image, self.labels[idx]\n",
    "        return image,image2, self.labels[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class testDataset(Dataset):\n",
    "    def __init__(self, test_lib, transform,transform2):\n",
    "        test_lib = np.array(test_lib)\n",
    "        self.filenames = test_lib[:,0]\n",
    "        #self.labels = test_lib[:,1]\n",
    "        self.transform = transform\n",
    "        self.transform2 = transform2\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(path+\"/test/\"+format(self.filenames[idx])+'.png')  # PIL image\n",
    "        #image= image.filter(ImageFilter.EDGE_ENHANCE)\n",
    "        #image2 = image.filter(ImageFilter.FIND_EDGES)\n",
    "        image = self.transform(img)\n",
    "        image2 = self.transform2(img)\n",
    "        #return image,self.filenames[idx]\n",
    "        return image,image2,self.filenames[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainA_dataloader = DataLoader(dataset_h5(\"all_data_109237v1.h5\", data_transforms2),batch_size=128, shuffle=True,num_workers=2, pin_memory=True)\n",
    "#trainC_dataloader = DataLoader(trainDataset(train_c, data_transforms,data_transforms2),batch_size=32, shuffle=True,num_workers=2, pin_memory=True)\n",
    "#trainT_dataloader = DataLoader(trainDataset(train_t, data_transforms,data_transforms2),batch_size=32, shuffle=True,num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_dataloader = DataLoaderX(trainDataset(datafilter[:1000], data_transforms,data_transforms2),batch_size=128, shuffle=False,num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoaderX(testDataset(test, data_transforms,data_transforms2),batch_size=128,shuffle=False,num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10,10))\n",
    "# plt.subplot(2,2,1)\n",
    "# plt.imshow(transforms.ToPILImage()(trainA_dataloader.dataset[15][0]).convert('RGB'))\n",
    "# plt.subplot(2,2,2)\n",
    "# plt.imshow(transforms.ToPILImage()(trainA_dataloader.dataset[15][1]).convert('RGB'))\n",
    "# plt.subplot(2,2,3)\n",
    "# plt.imshow(transforms.ToPILImage()(trainA_dataloader.dataset[29][0]).convert('RGB'))\n",
    "# plt.subplot(2,2,4)\n",
    "# plt.imshow(transforms.ToPILImage()(trainA_dataloader.dataset[29][1]).convert('RGB'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(np.array(trainC_dataloader.dataset[4][0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/Cadene/pretrained-models.pytorch/blob/master/pretrainedmodels/models/senet.py\n",
    "\"\"\"\n",
    "ResNet code gently borrowed from\n",
    "https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py\n",
    "\"\"\"\n",
    "from __future__ import print_function, division, absolute_import\n",
    "from collections import OrderedDict\n",
    "import math\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils import model_zoo\n",
    "\n",
    "__all__ = ['SENet', 'senet154', 'se_resnet50', 'se_resnet101', 'se_resnet152',\n",
    "           'se_resnext50_32x4d', 'se_resnext101_32x4d']\n",
    "\n",
    "pretrained_settings = {\n",
    "    'senet154': {\n",
    "        'imagenet': {\n",
    "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/senet154-c7b49a05.pth',\n",
    "            'input_space': 'RGB',\n",
    "            'input_size': [3, 224, 224],\n",
    "            'input_range': [0, 1],\n",
    "            'mean': [0.485, 0.456, 0.406],\n",
    "            'std': [0.229, 0.224, 0.225],\n",
    "            'num_classes': 1000\n",
    "        }\n",
    "    },\n",
    "    'se_resnet50': {\n",
    "        'imagenet': {\n",
    "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnet50-ce0d4300.pth',\n",
    "            'input_space': 'RGB',\n",
    "            'input_size': [3, 224, 224],\n",
    "            'input_range': [0, 1],\n",
    "            'mean': [0.485, 0.456, 0.406],\n",
    "            'std': [0.229, 0.224, 0.225],\n",
    "            'num_classes': 1000\n",
    "        }\n",
    "    },\n",
    "    'se_resnet101': {\n",
    "        'imagenet': {\n",
    "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnet101-7e38fcc6.pth',\n",
    "            'input_space': 'RGB',\n",
    "            'input_size': [3, 224, 224],\n",
    "            'input_range': [0, 1],\n",
    "            'mean': [0.485, 0.456, 0.406],\n",
    "            'std': [0.229, 0.224, 0.225],\n",
    "            'num_classes': 1000\n",
    "        }\n",
    "    },\n",
    "    'se_resnet152': {\n",
    "        'imagenet': {\n",
    "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnet152-d17c99b7.pth',\n",
    "            'input_space': 'RGB',\n",
    "            'input_size': [3, 224, 224],\n",
    "            'input_range': [0, 1],\n",
    "            'mean': [0.485, 0.456, 0.406],\n",
    "            'std': [0.229, 0.224, 0.225],\n",
    "            'num_classes': 1000\n",
    "        }\n",
    "    },\n",
    "    'se_resnext50_32x4d': {\n",
    "        'imagenet': {\n",
    "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnext50_32x4d-a260b3a4.pth',\n",
    "            'input_space': 'RGB',\n",
    "            'input_size': [3, 224, 224],\n",
    "            'input_range': [0, 1],\n",
    "            'mean': [0.485, 0.456, 0.406],\n",
    "            'std': [0.229, 0.224, 0.225],\n",
    "            'num_classes': 1000\n",
    "        }\n",
    "    },\n",
    "    'se_resnext101_32x4d': {\n",
    "        'imagenet': {\n",
    "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnext101_32x4d-3b2fe3d8.pth',\n",
    "            'input_space': 'RGB',\n",
    "            'input_size': [3, 224, 224],\n",
    "            'input_range': [0, 1],\n",
    "            'mean': [0.485, 0.456, 0.406],\n",
    "            'std': [0.229, 0.224, 0.225],\n",
    "            'num_classes': 1000\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "class SEModule(nn.Module):\n",
    "\n",
    "    def __init__(self, channels, reduction):\n",
    "        super(SEModule, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Conv2d(channels, channels // reduction, kernel_size=1,\n",
    "                             padding=0)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Conv2d(channels // reduction, channels, kernel_size=1,\n",
    "                             padding=0)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        module_input = x\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return module_input * x\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    \"\"\"\n",
    "    Base class for bottlenecks that implements `forward()` method.\n",
    "    \"\"\"\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out = self.se_module(out) + residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class SEBottleneck(Bottleneck):\n",
    "    \"\"\"\n",
    "    Bottleneck for SENet154.\n",
    "    \"\"\"\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n",
    "                 downsample=None):\n",
    "        super(SEBottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes * 2, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes * 2)\n",
    "        self.conv2 = nn.Conv2d(planes * 2, planes * 4, kernel_size=3,\n",
    "                               stride=stride, padding=1, groups=groups,\n",
    "                               bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes * 4)\n",
    "        self.conv3 = nn.Conv2d(planes * 4, planes * 4, kernel_size=1,\n",
    "                               bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.se_module = SEModule(planes * 4, reduction=reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "\n",
    "class SEResNetBottleneck(Bottleneck):\n",
    "    \"\"\"\n",
    "    ResNet bottleneck with a Squeeze-and-Excitation module. It follows Caffe\n",
    "    implementation and uses `stride=stride` in `conv1` and not in `conv2`\n",
    "    (the latter is used in the torchvision implementation of ResNet).\n",
    "    \"\"\"\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n",
    "                 downsample=None):\n",
    "        super(SEResNetBottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False,\n",
    "                               stride=stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, padding=1,\n",
    "                               groups=groups, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.se_module = SEModule(planes * 4, reduction=reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "\n",
    "class SEResNeXtBottleneck(Bottleneck):\n",
    "    \"\"\"\n",
    "    ResNeXt bottleneck type C with a Squeeze-and-Excitation module.\n",
    "    \"\"\"\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n",
    "                 downsample=None, base_width=4):\n",
    "        super(SEResNeXtBottleneck, self).__init__()\n",
    "        width = math.floor(planes * (base_width / 64)) * groups\n",
    "        self.conv1 = nn.Conv2d(inplanes, width, kernel_size=1, bias=False,\n",
    "                               stride=1)\n",
    "        self.bn1 = nn.BatchNorm2d(width)\n",
    "        self.conv2 = nn.Conv2d(width, width, kernel_size=3, stride=stride,\n",
    "                               padding=1, groups=groups, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(width)\n",
    "        self.conv3 = nn.Conv2d(width, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.se_module = SEModule(planes * 4, reduction=reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "\n",
    "class SENet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, groups, reduction, dropout_p=0.2,\n",
    "                 inplanes=128, input_3x3=True, downsample_kernel_size=3,\n",
    "                 downsample_padding=1, num_classes=1000):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        block (nn.Module): Bottleneck class.\n",
    "            - For SENet154: SEBottleneck\n",
    "            - For SE-ResNet models: SEResNetBottleneck\n",
    "            - For SE-ResNeXt models:  SEResNeXtBottleneck\n",
    "        layers (list of ints): Number of residual blocks for 4 layers of the\n",
    "            network (layer1...layer4).\n",
    "        groups (int): Number of groups for the 3x3 convolution in each\n",
    "            bottleneck block.\n",
    "            - For SENet154: 64\n",
    "            - For SE-ResNet models: 1\n",
    "            - For SE-ResNeXt models:  32\n",
    "        reduction (int): Reduction ratio for Squeeze-and-Excitation modules.\n",
    "            - For all models: 16\n",
    "        dropout_p (float or None): Drop probability for the Dropout layer.\n",
    "            If `None` the Dropout layer is not used.\n",
    "            - For SENet154: 0.2\n",
    "            - For SE-ResNet models: None\n",
    "            - For SE-ResNeXt models: None\n",
    "        inplanes (int):  Number of input channels for layer1.\n",
    "            - For SENet154: 128\n",
    "            - For SE-ResNet models: 64\n",
    "            - For SE-ResNeXt models: 64\n",
    "        input_3x3 (bool): If `True`, use three 3x3 convolutions instead of\n",
    "            a single 7x7 convolution in layer0.\n",
    "            - For SENet154: True\n",
    "            - For SE-ResNet models: False\n",
    "            - For SE-ResNeXt models: False\n",
    "        downsample_kernel_size (int): Kernel size for downsampling convolutions\n",
    "            in layer2, layer3 and layer4.\n",
    "            - For SENet154: 3\n",
    "            - For SE-ResNet models: 1\n",
    "            - For SE-ResNeXt models: 1\n",
    "        downsample_padding (int): Padding for downsampling convolutions in\n",
    "            layer2, layer3 and layer4.\n",
    "            - For SENet154: 1\n",
    "            - For SE-ResNet models: 0\n",
    "            - For SE-ResNeXt models: 0\n",
    "        num_classes (int): Number of outputs in `last_linear` layer.\n",
    "            - For all models: 1000\n",
    "        \"\"\"\n",
    "        super(SENet, self).__init__()\n",
    "        self.inplanes = inplanes\n",
    "        if input_3x3:\n",
    "            layer0_modules = [\n",
    "                ('conv1', nn.Conv2d(3, 64, 3, stride=2, padding=1,\n",
    "                                    bias=False)),\n",
    "                ('bn1', nn.BatchNorm2d(64)),\n",
    "                ('relu1', nn.ReLU(inplace=True)),\n",
    "                ('conv2', nn.Conv2d(64, 64, 3, stride=1, padding=1,\n",
    "                                    bias=False)),\n",
    "                ('bn2', nn.BatchNorm2d(64)),\n",
    "                ('relu2', nn.ReLU(inplace=True)),\n",
    "                ('conv3', nn.Conv2d(64, inplanes, 3, stride=1, padding=1,\n",
    "                                    bias=False)),\n",
    "                ('bn3', nn.BatchNorm2d(inplanes)),\n",
    "                ('relu3', nn.ReLU(inplace=True)),\n",
    "            ]\n",
    "        else:\n",
    "            layer0_modules = [\n",
    "                ('conv1', nn.Conv2d(3, inplanes, kernel_size=7, stride=2,\n",
    "                                    padding=3, bias=False)),\n",
    "                ('bn1', nn.BatchNorm2d(inplanes)),\n",
    "                ('relu1', nn.ReLU(inplace=True)),\n",
    "            ]\n",
    "        # To preserve compatibility with Caffe weights `ceil_mode=True`\n",
    "        # is used instead of `padding=1`.\n",
    "        layer0_modules.append(('pool', nn.MaxPool2d(3, stride=2,\n",
    "                                                    ceil_mode=True)))\n",
    "        self.layer0 = nn.Sequential(OrderedDict(layer0_modules))\n",
    "        self.layer1 = self._make_layer(\n",
    "            block,\n",
    "            planes=64,\n",
    "            blocks=layers[0],\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=1,\n",
    "            downsample_padding=0\n",
    "        )\n",
    "        self.layer2 = self._make_layer(\n",
    "            block,\n",
    "            planes=128,\n",
    "            blocks=layers[1],\n",
    "            stride=2,\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=downsample_kernel_size,\n",
    "            downsample_padding=downsample_padding\n",
    "        )\n",
    "        self.layer3 = self._make_layer(\n",
    "            block,\n",
    "            planes=256,\n",
    "            blocks=layers[2],\n",
    "            stride=2,\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=downsample_kernel_size,\n",
    "            downsample_padding=downsample_padding\n",
    "        )\n",
    "        self.layer4 = self._make_layer(\n",
    "            block,\n",
    "            planes=512,\n",
    "            blocks=layers[3],\n",
    "            stride=2,\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=downsample_kernel_size,\n",
    "            downsample_padding=downsample_padding\n",
    "        )\n",
    "        self.avg_pool = nn.AvgPool2d(7, stride=1)\n",
    "        self.dropout = nn.Dropout(dropout_p) if dropout_p is not None else None\n",
    "        self.last_linear = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, groups, reduction, stride=1,\n",
    "                    downsample_kernel_size=1, downsample_padding=0):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=downsample_kernel_size, stride=stride,\n",
    "                          padding=downsample_padding, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, groups, reduction, stride,\n",
    "                            downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups, reduction))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def features(self, x):\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        return x\n",
    "\n",
    "    def logits(self, x):\n",
    "        x = self.avg_pool(x)\n",
    "        if self.dropout is not None:\n",
    "            x = self.dropout(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.last_linear(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.logits(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def initialize_pretrained_model(model, num_classes, settings):\n",
    "    assert num_classes == settings['num_classes'], \\\n",
    "        'num_classes should be {}, but is {}'.format(\n",
    "            settings['num_classes'], num_classes)\n",
    "    model.load_state_dict(model_zoo.load_url(settings['url']))\n",
    "    model.input_space = settings['input_space']\n",
    "    model.input_size = settings['input_size']\n",
    "    model.input_range = settings['input_range']\n",
    "    model.mean = settings['mean']\n",
    "    model.std = settings['std']\n",
    "\n",
    "\n",
    "def senet154(num_classes=1000, pretrained='imagenet'):\n",
    "    model = SENet(SEBottleneck, [3, 8, 36, 3], groups=64, reduction=16,\n",
    "                  dropout_p=0.2, num_classes=num_classes)\n",
    "    if pretrained is not None:\n",
    "        settings = pretrained_settings['senet154'][pretrained]\n",
    "        initialize_pretrained_model(model, num_classes, settings)\n",
    "    return model\n",
    "\n",
    "\n",
    "def se_resnet50(num_classes=1000, pretrained='imagenet'):\n",
    "    model = SENet(SEResNetBottleneck, [3, 4, 6, 3], groups=1, reduction=16,\n",
    "                  dropout_p=None, inplanes=64, input_3x3=False,\n",
    "                  downsample_kernel_size=1, downsample_padding=0,\n",
    "                  num_classes=num_classes)\n",
    "    if pretrained is not None:\n",
    "        settings = pretrained_settings['se_resnet50'][pretrained]\n",
    "        initialize_pretrained_model(model, num_classes, settings)\n",
    "    return model\n",
    "\n",
    "\n",
    "def se_resnet101(num_classes=1000, pretrained='imagenet'):\n",
    "    model = SENet(SEResNetBottleneck, [3, 4, 23, 3], groups=1, reduction=16,\n",
    "                  dropout_p=None, inplanes=64, input_3x3=False,\n",
    "                  downsample_kernel_size=1, downsample_padding=0,\n",
    "                  num_classes=num_classes)\n",
    "    if pretrained is not None:\n",
    "        settings = pretrained_settings['se_resnet101'][pretrained]\n",
    "        initialize_pretrained_model(model, num_classes, settings)\n",
    "    return model\n",
    "\n",
    "\n",
    "def se_resnet152(num_classes=1000, pretrained='imagenet'):\n",
    "    model = SENet(SEResNetBottleneck, [3, 8, 36, 3], groups=1, reduction=16,\n",
    "                  dropout_p=None, inplanes=64, input_3x3=False,\n",
    "                  downsample_kernel_size=1, downsample_padding=0,\n",
    "                  num_classes=num_classes)\n",
    "    if pretrained is not None:\n",
    "        settings = pretrained_settings['se_resnet152'][pretrained]\n",
    "        initialize_pretrained_model(model, num_classes, settings)\n",
    "    return model\n",
    "\n",
    "\n",
    "def se_resnext50_32x4d(num_classes=1000, pretrained='imagenet'):\n",
    "    model = SENet(SEResNeXtBottleneck, [3, 4, 6, 3], groups=32, reduction=16,\n",
    "                  dropout_p=None, inplanes=64, input_3x3=False,\n",
    "                  downsample_kernel_size=1, downsample_padding=0,\n",
    "                  num_classes=num_classes)\n",
    "    if pretrained is not None:\n",
    "        settings = pretrained_settings['se_resnext50_32x4d'][pretrained]\n",
    "        initialize_pretrained_model(model, num_classes, settings)\n",
    "    return model\n",
    "\n",
    "\n",
    "def se_resnext101_32x4d(num_classes=1000, pretrained='imagenet'):\n",
    "    model = SENet(SEResNeXtBottleneck, [3, 4, 23, 3], groups=32, reduction=16,\n",
    "                  dropout_p=None, inplanes=64, input_3x3=False,\n",
    "                  downsample_kernel_size=1, downsample_padding=0,\n",
    "                  num_classes=num_classes)\n",
    "    if pretrained is not None:\n",
    "        settings = pretrained_settings['se_resnext101_32x4d'][pretrained]\n",
    "        initialize_pretrained_model(model, num_classes, settings)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from shutil import copyfile\n",
    "# from os.path import isfile, join, abspath, exists, isdir, expanduser\n",
    "# from os import listdir, makedirs, getcwd, remove\n",
    "\n",
    "# cache_dir = expanduser(join('~', '.torch'))\n",
    "# if not exists(cache_dir):\n",
    "#     makedirs(cache_dir)\n",
    "# models_dir = join(cache_dir, 'models/')\n",
    "# if not exists(models_dir):\n",
    "#     makedirs(models_dir)\n",
    "    \n",
    "# copyfile(\"../input/pretrained-pytorch/densenet201-c1103571.pth\", models_dir+\"densenet201-c1103571.pth\")\n",
    "# copyfile(\"../input/pretrained-pytorch/resnet50-19c8e357.pth\", models_dir+\"resnet50-19c8e357.pth\")\n",
    "# copyfile(\"../input/pretrained-se-resnet/se_resnext101_32x4d-3b2fe3d8.pth\", models_dir+\"se_resnext101_32x4d-3b2fe3d8.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls ~/.torch/models  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): SENet(\n",
       "    (layer0): Sequential(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    )\n",
       "    (layer1): Sequential(\n",
       "      (0): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (2): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (2): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (3): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (2): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (3): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (4): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (5): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (6): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (7): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (8): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (9): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (10): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (11): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (12): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (13): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (14): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (15): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (16): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (17): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (18): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (19): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (20): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (21): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (22): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (2): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (avg_pool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "    (last_linear): Linear(in_features=2048, out_features=1103, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Ensemble(nn.Module):\n",
    "    def __init__(self, modelA, modelB,input_length,output_length):\n",
    "        super(Ensemble, self).__init__()\n",
    "        self.modelA = modelA\n",
    "        self.modelB = modelB\n",
    "        self.classifier = nn.Linear(input_length, output_length)\n",
    "        \n",
    "    def forward(self, xin,xin2):\n",
    "        x1 = self.modelA(xin)\n",
    "        x2 = self.modelB(xin2)\n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "        x = self.classifier(F.relu(x))\n",
    "        return x\n",
    "\n",
    "    \n",
    "# efficientNet = EfficientNet.from_name('efficientnet-b7') \n",
    "# efficientNet._fc = nn.Linear(in_features=1280, out_features=lable_length)\n",
    "\n",
    "\n",
    "seresnext_model = se_resnext101_32x4d(pretrained='imagenet')\n",
    "seresnext_model.last_linear = nn.Linear(in_features=2048, out_features=lable_length, bias=True)\n",
    "\n",
    "#densenet_model = models.densenet201(pretrained=True)\n",
    "#densenet_model.load_state_dict(torch.load( models_dir+\"densenet201-c1103571.pth\"))\n",
    "#densenet_model.classifier= nn.Linear(in_features=1920,out_features=lable_length)\n",
    "\n",
    "#efficientNet = EfficientNet(width_coeff=2.0, depth_coeff=3.1,drop_connect_rate=0.5,num_classes = lable_length)\n",
    "\n",
    "resnet_model = models.resnet50(pretrained=True)\n",
    "#resnet_model.load_state_dict(torch.load(\"../models/resnet50.pth\"))\n",
    "resnet_model.fc= nn.Linear(in_features=2048, out_features=lable_length)\n",
    "\n",
    "#model = Ensemble(seresnext_model, resnet_model,lable_length*2,lable_length)\n",
    "#model.to(device)\n",
    "\n",
    "\n",
    "model = seresnext_model\n",
    "#model = nn.DataParallel(model)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    # device_ids has a default : all\n",
    "    model = torch.nn.DataParallel(model, device_ids=[0,1]) \n",
    "model.to(device)\n",
    "\n",
    "#model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch,fnum,dloader):\n",
    "    model.train()\n",
    "    for step, (x,y) in enumerate(dloader):\n",
    "        data = Variable(x).cuda()   # batch x\n",
    "        #data2 = Variable(x2).cuda()\n",
    "        target = Variable(y).cuda(async=True)   # batch y\n",
    "        #print(data.size())\n",
    "        #print(data2.size())\n",
    "        #print(target.size())\n",
    "        #output = model(data,data2)\n",
    "        #print(data.size())\n",
    "        output = model(data)\n",
    "        #print(\"out\",output.size())\n",
    "        #print(\"target\",target.size())\n",
    "\n",
    "        loss = loss_func(output, target.float())   # cross entropy loss\n",
    "        optimizer.zero_grad()           # clear gradients for this training step\n",
    "        loss.backward()                 # backpropagation, compute gradients\n",
    "        optimizer.step()                # apply gradients\n",
    "        if step==0:\n",
    "            start = time.time()\n",
    "            #break\n",
    "            ti = 0\n",
    "        elif step==100:\n",
    "            ti = time.time()-start #total time = ti*(length/100)\n",
    "            #print(ti)\n",
    "            ti = ti*(len(dloader)/100)\n",
    "        if step % 100 == 0:\n",
    "            second = ti*(((len(dloader)-step)/len(dloader)))#*(5-epoch)*(4-fnum)\n",
    "            print('Train Fold:{}/4  Ep: {}/5 [{}/{} ({:.0f}%)]\\t Loss: {:.6f}\\t Remain : {} '.\n",
    "                     format(fnum+1,\n",
    "                            epoch+1, \n",
    "                            step * len(data), \n",
    "                            len(dloader.dataset),\n",
    "                            100.*step/len(dloader), \n",
    "                            loss.data.item(),\n",
    "                            datetime.timedelta(seconds = int(second))))\n",
    "        #data.cpu()\n",
    "        #data2.cpu()\n",
    "        #target.cpu()\n",
    "        torch.cuda.empty_cache()\n",
    "    print(\"Finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(dloader):\n",
    "    model.eval()\n",
    "    los = []\n",
    "    for step, (x, y) in enumerate(dloader):\n",
    "        data = Variable(x).cuda()\n",
    "        #data2 = Variable(x2).cuda()\n",
    "        target = Variable(y).cuda()\n",
    "        \n",
    "        #output = model(data,data2)\n",
    "        with torch.no_grad():\n",
    "            output = model(data)\n",
    "        \n",
    "        loss = loss_func(output, target.float())\n",
    "        los.append(loss.item())\n",
    "        \n",
    "        \n",
    "        if step %100 == 0:\n",
    "            print('[{}/{} ({:.1f}%)]'.format(step * len(data), \n",
    "                                        len(dloader.dataset),\n",
    "                                        100.*step/len(dloader)))\n",
    "        #data.cpu()\n",
    "        #data2.cpu()\n",
    "        #arget.cpu()\n",
    "        torch.cuda.empty_cache()\n",
    "    los = np.array(los)\n",
    "    avg_val_loss = los.sum()/len(los)\n",
    "    print(\"Avg val loss:{}\".format(avg_val_loss))\n",
    "    #return ans,out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def forward(self, input, target):\n",
    "        # Inspired by the implementation of binary_cross_entropy_with_logits\n",
    "        if not (target.size() == input.size()):\n",
    "            raise ValueError(\"Target size ({}) must be the same as input size ({})\".format(target.size(), input.size()))\n",
    "\n",
    "        max_val = (-input).clamp(min=0)\n",
    "        loss = input - input * target + max_val + ((-max_val).exp() + (-input - max_val).exp()).log()\n",
    "\n",
    "        # This formula gives us the log sigmoid of 1-p if y is 0 and of p if y is 1\n",
    "        invprobs = F.logsigmoid(-input * (target * 2 - 1))\n",
    "        loss = (invprobs * self.gamma).exp() * loss\n",
    "        \n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Fold:1/4  Ep: 1/5 [0/81927 (0%)]\t Loss: 0.535525\t Remain : 0:00:00 \n",
      "Train Fold:1/4  Ep: 1/5 [10000/81927 (12%)]\t Loss: 0.010199\t Remain : 0:17:23 \n",
      "Train Fold:1/4  Ep: 1/5 [20000/81927 (24%)]\t Loss: 0.009656\t Remain : 0:14:58 \n",
      "Train Fold:1/4  Ep: 1/5 [30000/81927 (37%)]\t Loss: 0.009418\t Remain : 0:12:33 \n",
      "Train Fold:1/4  Ep: 1/5 [40000/81927 (49%)]\t Loss: 0.008177\t Remain : 0:10:08 \n",
      "Train Fold:1/4  Ep: 1/5 [50000/81927 (61%)]\t Loss: 0.008405\t Remain : 0:07:43 \n",
      "Train Fold:1/4  Ep: 1/5 [60000/81927 (73%)]\t Loss: 0.007279\t Remain : 0:05:18 \n",
      "Train Fold:1/4  Ep: 1/5 [70000/81927 (85%)]\t Loss: 0.006894\t Remain : 0:02:53 \n",
      "Train Fold:1/4  Ep: 1/5 [80000/81927 (98%)]\t Loss: 0.007903\t Remain : 0:00:28 \n",
      "Finish\n",
      "[0/27310 (0.0%)]\n",
      "[10000/27310 (36.5%)]\n",
      "[20000/27310 (73.0%)]\n",
      "Avg val loss:0.007591246759831687\n",
      "Train Fold:1/4  Ep: 2/5 [0/81927 (0%)]\t Loss: 0.006486\t Remain : 0:00:00 \n",
      "Train Fold:1/4  Ep: 2/5 [10000/81927 (12%)]\t Loss: 0.007512\t Remain : 0:17:28 \n",
      "Train Fold:1/4  Ep: 2/5 [20000/81927 (24%)]\t Loss: 0.007316\t Remain : 0:15:02 \n",
      "Train Fold:1/4  Ep: 2/5 [30000/81927 (37%)]\t Loss: 0.008148\t Remain : 0:12:37 \n",
      "Train Fold:1/4  Ep: 2/5 [40000/81927 (49%)]\t Loss: 0.007996\t Remain : 0:10:11 \n",
      "Train Fold:1/4  Ep: 2/5 [50000/81927 (61%)]\t Loss: 0.006580\t Remain : 0:07:45 \n",
      "Train Fold:1/4  Ep: 2/5 [60000/81927 (73%)]\t Loss: 0.007849\t Remain : 0:05:20 \n",
      "Train Fold:1/4  Ep: 2/5 [70000/81927 (85%)]\t Loss: 0.007454\t Remain : 0:02:54 \n",
      "Train Fold:1/4  Ep: 2/5 [80000/81927 (98%)]\t Loss: 0.007784\t Remain : 0:00:29 \n",
      "Finish\n",
      "[0/27310 (0.0%)]\n",
      "[10000/27310 (36.5%)]\n",
      "[20000/27310 (73.0%)]\n",
      "Avg val loss:0.007564516615693587\n",
      "Train Fold:1/4  Ep: 3/5 [0/81927 (0%)]\t Loss: 0.008357\t Remain : 0:00:00 \n",
      "Train Fold:1/4  Ep: 3/5 [10000/81927 (12%)]\t Loss: 0.007240\t Remain : 0:17:35 \n",
      "Train Fold:1/4  Ep: 3/5 [20000/81927 (24%)]\t Loss: 0.008309\t Remain : 0:15:09 \n",
      "Train Fold:1/4  Ep: 3/5 [30000/81927 (37%)]\t Loss: 0.007664\t Remain : 0:12:42 \n",
      "Train Fold:1/4  Ep: 3/5 [40000/81927 (49%)]\t Loss: 0.007528\t Remain : 0:10:15 \n",
      "Train Fold:1/4  Ep: 3/5 [50000/81927 (61%)]\t Loss: 0.007289\t Remain : 0:07:49 \n",
      "Train Fold:1/4  Ep: 3/5 [60000/81927 (73%)]\t Loss: 0.007738\t Remain : 0:05:22 \n",
      "Train Fold:1/4  Ep: 3/5 [70000/81927 (85%)]\t Loss: 0.007593\t Remain : 0:02:55 \n",
      "Train Fold:1/4  Ep: 3/5 [80000/81927 (98%)]\t Loss: 0.007816\t Remain : 0:00:29 \n",
      "Finish\n",
      "[0/27310 (0.0%)]\n",
      "[10000/27310 (36.5%)]\n",
      "[20000/27310 (73.0%)]\n",
      "Avg val loss:0.007571251123096713\n",
      "Train Fold:1/4  Ep: 4/5 [0/81927 (0%)]\t Loss: 0.007866\t Remain : 0:00:00 \n",
      "Train Fold:1/4  Ep: 4/5 [10000/81927 (12%)]\t Loss: 0.007418\t Remain : 0:17:29 \n",
      "Train Fold:1/4  Ep: 4/5 [20000/81927 (24%)]\t Loss: 0.007846\t Remain : 0:15:03 \n",
      "Train Fold:1/4  Ep: 4/5 [30000/81927 (37%)]\t Loss: 0.007349\t Remain : 0:12:38 \n",
      "Train Fold:1/4  Ep: 4/5 [40000/81927 (49%)]\t Loss: 0.007827\t Remain : 0:10:12 \n",
      "Train Fold:1/4  Ep: 4/5 [50000/81927 (61%)]\t Loss: 0.007126\t Remain : 0:07:46 \n",
      "Train Fold:1/4  Ep: 4/5 [60000/81927 (73%)]\t Loss: 0.007471\t Remain : 0:05:20 \n",
      "Train Fold:1/4  Ep: 4/5 [70000/81927 (85%)]\t Loss: 0.006871\t Remain : 0:02:54 \n",
      "Train Fold:1/4  Ep: 4/5 [80000/81927 (98%)]\t Loss: 0.007218\t Remain : 0:00:29 \n",
      "Finish\n",
      "[0/27310 (0.0%)]\n",
      "[10000/27310 (36.5%)]\n",
      "[20000/27310 (73.0%)]\n",
      "Avg val loss:0.007561949088516897\n",
      "Train Fold:1/4  Ep: 5/5 [0/81927 (0%)]\t Loss: 0.007950\t Remain : 0:00:00 \n",
      "Train Fold:1/4  Ep: 5/5 [10000/81927 (12%)]\t Loss: 0.007232\t Remain : 0:17:30 \n",
      "Train Fold:1/4  Ep: 5/5 [20000/81927 (24%)]\t Loss: 0.007518\t Remain : 0:15:04 \n",
      "Train Fold:1/4  Ep: 5/5 [30000/81927 (37%)]\t Loss: 0.007206\t Remain : 0:12:39 \n",
      "Train Fold:1/4  Ep: 5/5 [40000/81927 (49%)]\t Loss: 0.007785\t Remain : 0:10:13 \n",
      "Train Fold:1/4  Ep: 5/5 [50000/81927 (61%)]\t Loss: 0.006759\t Remain : 0:07:47 \n",
      "Train Fold:1/4  Ep: 5/5 [60000/81927 (73%)]\t Loss: 0.007304\t Remain : 0:05:21 \n",
      "Train Fold:1/4  Ep: 5/5 [70000/81927 (85%)]\t Loss: 0.007080\t Remain : 0:02:55 \n",
      "Train Fold:1/4  Ep: 5/5 [80000/81927 (98%)]\t Loss: 0.008018\t Remain : 0:00:29 \n",
      "Finish\n",
      "[0/27310 (0.0%)]\n",
      "[10000/27310 (36.5%)]\n",
      "[20000/27310 (73.0%)]\n",
      "Avg val loss:0.007564915738401622\n",
      "Train Fold:2/4  Ep: 1/5 [0/81928 (0%)]\t Loss: 0.007097\t Remain : 0:00:00 \n",
      "Train Fold:2/4  Ep: 1/5 [10000/81928 (12%)]\t Loss: 0.008457\t Remain : 0:17:27 \n",
      "Train Fold:2/4  Ep: 1/5 [20000/81928 (24%)]\t Loss: 0.007257\t Remain : 0:15:02 \n",
      "Train Fold:2/4  Ep: 1/5 [30000/81928 (37%)]\t Loss: 0.006997\t Remain : 0:12:36 \n",
      "Train Fold:2/4  Ep: 1/5 [40000/81928 (49%)]\t Loss: 0.006978\t Remain : 0:10:11 \n",
      "Train Fold:2/4  Ep: 1/5 [50000/81928 (61%)]\t Loss: 0.006679\t Remain : 0:07:45 \n",
      "Train Fold:2/4  Ep: 1/5 [60000/81928 (73%)]\t Loss: 0.007286\t Remain : 0:05:20 \n",
      "Train Fold:2/4  Ep: 1/5 [70000/81928 (85%)]\t Loss: 0.007270\t Remain : 0:02:54 \n",
      "Train Fold:2/4  Ep: 1/5 [80000/81928 (98%)]\t Loss: 0.005972\t Remain : 0:00:29 \n",
      "Finish\n",
      "[0/27309 (0.0%)]\n",
      "[10000/27309 (36.5%)]\n",
      "[20000/27309 (73.0%)]\n",
      "Avg val loss:0.006475997845689855\n",
      "Train Fold:2/4  Ep: 2/5 [0/81928 (0%)]\t Loss: 0.005667\t Remain : 0:00:00 \n",
      "Train Fold:2/4  Ep: 2/5 [10000/81928 (12%)]\t Loss: 0.005549\t Remain : 0:17:33 \n",
      "Train Fold:2/4  Ep: 2/5 [20000/81928 (24%)]\t Loss: 0.005867\t Remain : 0:15:07 \n",
      "Train Fold:2/4  Ep: 2/5 [30000/81928 (37%)]\t Loss: 0.005769\t Remain : 0:12:40 \n",
      "Train Fold:2/4  Ep: 2/5 [40000/81928 (49%)]\t Loss: 0.005893\t Remain : 0:10:14 \n",
      "Train Fold:2/4  Ep: 2/5 [50000/81928 (61%)]\t Loss: 0.006276\t Remain : 0:07:48 \n",
      "Train Fold:2/4  Ep: 2/5 [60000/81928 (73%)]\t Loss: 0.005777\t Remain : 0:05:21 \n",
      "Train Fold:2/4  Ep: 2/5 [70000/81928 (85%)]\t Loss: 0.006122\t Remain : 0:02:55 \n",
      "Train Fold:2/4  Ep: 2/5 [80000/81928 (98%)]\t Loss: 0.005467\t Remain : 0:00:29 \n",
      "Finish\n",
      "[0/27309 (0.0%)]\n",
      "[10000/27309 (36.5%)]\n",
      "[20000/27309 (73.0%)]\n",
      "Avg val loss:0.006469938863259163\n",
      "Train Fold:2/4  Ep: 3/5 [0/81928 (0%)]\t Loss: 0.005611\t Remain : 0:00:00 \n",
      "Train Fold:2/4  Ep: 3/5 [10000/81928 (12%)]\t Loss: 0.005763\t Remain : 0:17:30 \n",
      "Train Fold:2/4  Ep: 3/5 [20000/81928 (24%)]\t Loss: 0.006004\t Remain : 0:15:04 \n",
      "Train Fold:2/4  Ep: 3/5 [30000/81928 (37%)]\t Loss: 0.005803\t Remain : 0:12:38 \n",
      "Train Fold:2/4  Ep: 3/5 [40000/81928 (49%)]\t Loss: 0.006127\t Remain : 0:10:12 \n",
      "Train Fold:2/4  Ep: 3/5 [50000/81928 (61%)]\t Loss: 0.005810\t Remain : 0:07:46 \n",
      "Train Fold:2/4  Ep: 3/5 [60000/81928 (73%)]\t Loss: 0.005737\t Remain : 0:05:20 \n",
      "Train Fold:2/4  Ep: 3/5 [70000/81928 (85%)]\t Loss: 0.005424\t Remain : 0:02:55 \n",
      "Train Fold:2/4  Ep: 3/5 [80000/81928 (98%)]\t Loss: 0.006207\t Remain : 0:00:29 \n",
      "Finish\n",
      "[0/27309 (0.0%)]\n",
      "[10000/27309 (36.5%)]\n",
      "[20000/27309 (73.0%)]\n",
      "Avg val loss:0.006470440360071668\n",
      "Train Fold:2/4  Ep: 4/5 [0/81928 (0%)]\t Loss: 0.006104\t Remain : 0:00:00 \n",
      "Train Fold:2/4  Ep: 4/5 [10000/81928 (12%)]\t Loss: 0.006190\t Remain : 0:17:34 \n",
      "Train Fold:2/4  Ep: 4/5 [20000/81928 (24%)]\t Loss: 0.005767\t Remain : 0:15:08 \n",
      "Train Fold:2/4  Ep: 4/5 [30000/81928 (37%)]\t Loss: 0.005986\t Remain : 0:12:41 \n",
      "Train Fold:2/4  Ep: 4/5 [40000/81928 (49%)]\t Loss: 0.005306\t Remain : 0:10:15 \n",
      "Train Fold:2/4  Ep: 4/5 [50000/81928 (61%)]\t Loss: 0.005402\t Remain : 0:07:48 \n",
      "Train Fold:2/4  Ep: 4/5 [60000/81928 (73%)]\t Loss: 0.005538\t Remain : 0:05:22 \n",
      "Train Fold:2/4  Ep: 4/5 [70000/81928 (85%)]\t Loss: 0.006292\t Remain : 0:02:55 \n",
      "Train Fold:2/4  Ep: 4/5 [80000/81928 (98%)]\t Loss: 0.005670\t Remain : 0:00:29 \n",
      "Finish\n",
      "[0/27309 (0.0%)]\n",
      "[10000/27309 (36.5%)]\n",
      "[20000/27309 (73.0%)]\n",
      "Avg val loss:0.006465548938344212\n",
      "Train Fold:2/4  Ep: 5/5 [0/81928 (0%)]\t Loss: 0.005956\t Remain : 0:00:00 \n",
      "Train Fold:2/4  Ep: 5/5 [10000/81928 (12%)]\t Loss: 0.006275\t Remain : 0:17:34 \n",
      "Train Fold:2/4  Ep: 5/5 [20000/81928 (24%)]\t Loss: 0.005820\t Remain : 0:15:07 \n",
      "Train Fold:2/4  Ep: 5/5 [30000/81928 (37%)]\t Loss: 0.005735\t Remain : 0:12:41 \n",
      "Train Fold:2/4  Ep: 5/5 [40000/81928 (49%)]\t Loss: 0.006221\t Remain : 0:10:14 \n",
      "Train Fold:2/4  Ep: 5/5 [50000/81928 (61%)]\t Loss: 0.005563\t Remain : 0:07:48 \n",
      "Train Fold:2/4  Ep: 5/5 [60000/81928 (73%)]\t Loss: 0.005033\t Remain : 0:05:22 \n",
      "Train Fold:2/4  Ep: 5/5 [70000/81928 (85%)]\t Loss: 0.006021\t Remain : 0:02:55 \n",
      "Train Fold:2/4  Ep: 5/5 [80000/81928 (98%)]\t Loss: 0.005225\t Remain : 0:00:29 \n",
      "Finish\n",
      "[0/27309 (0.0%)]\n",
      "[10000/27309 (36.5%)]\n",
      "[20000/27309 (73.0%)]\n",
      "Avg val loss:0.006458866411656903\n",
      "Train Fold:3/4  Ep: 1/5 [0/81928 (0%)]\t Loss: 0.006352\t Remain : 0:00:00 \n",
      "Train Fold:3/4  Ep: 1/5 [10000/81928 (12%)]\t Loss: 0.005615\t Remain : 0:17:26 \n",
      "Train Fold:3/4  Ep: 1/5 [20000/81928 (24%)]\t Loss: 0.006849\t Remain : 0:15:01 \n",
      "Train Fold:3/4  Ep: 1/5 [30000/81928 (37%)]\t Loss: 0.005027\t Remain : 0:12:36 \n",
      "Train Fold:3/4  Ep: 1/5 [40000/81928 (49%)]\t Loss: 0.005807\t Remain : 0:10:10 \n",
      "Train Fold:3/4  Ep: 1/5 [50000/81928 (61%)]\t Loss: 0.006298\t Remain : 0:07:45 \n",
      "Train Fold:3/4  Ep: 1/5 [60000/81928 (73%)]\t Loss: 0.006195\t Remain : 0:05:19 \n",
      "Train Fold:3/4  Ep: 1/5 [70000/81928 (85%)]\t Loss: 0.005896\t Remain : 0:02:54 \n",
      "Train Fold:3/4  Ep: 1/5 [80000/81928 (98%)]\t Loss: 0.006249\t Remain : 0:00:29 \n",
      "Finish\n",
      "[0/27309 (0.0%)]\n",
      "[10000/27309 (36.5%)]\n",
      "[20000/27309 (73.0%)]\n",
      "Avg val loss:0.005684898568004588\n",
      "Train Fold:3/4  Ep: 2/5 [0/81928 (0%)]\t Loss: 0.004984\t Remain : 0:00:00 \n",
      "Train Fold:3/4  Ep: 2/5 [10000/81928 (12%)]\t Loss: 0.004244\t Remain : 0:17:36 \n",
      "Train Fold:3/4  Ep: 2/5 [20000/81928 (24%)]\t Loss: 0.004653\t Remain : 0:15:09 \n",
      "Train Fold:3/4  Ep: 2/5 [30000/81928 (37%)]\t Loss: 0.004664\t Remain : 0:12:42 \n",
      "Train Fold:3/4  Ep: 2/5 [40000/81928 (49%)]\t Loss: 0.004904\t Remain : 0:10:16 \n",
      "Train Fold:3/4  Ep: 2/5 [50000/81928 (61%)]\t Loss: 0.004406\t Remain : 0:07:49 \n",
      "Train Fold:3/4  Ep: 2/5 [60000/81928 (73%)]\t Loss: 0.005550\t Remain : 0:05:22 \n",
      "Train Fold:3/4  Ep: 2/5 [70000/81928 (85%)]\t Loss: 0.004718\t Remain : 0:02:56 \n",
      "Train Fold:3/4  Ep: 2/5 [80000/81928 (98%)]\t Loss: 0.005336\t Remain : 0:00:29 \n",
      "Finish\n",
      "[0/27309 (0.0%)]\n",
      "[10000/27309 (36.5%)]\n",
      "[20000/27309 (73.0%)]\n",
      "Avg val loss:0.005668193142670784\n",
      "Train Fold:3/4  Ep: 3/5 [0/81928 (0%)]\t Loss: 0.004376\t Remain : 0:00:00 \n",
      "Train Fold:3/4  Ep: 3/5 [10000/81928 (12%)]\t Loss: 0.005072\t Remain : 0:17:30 \n",
      "Train Fold:3/4  Ep: 3/5 [20000/81928 (24%)]\t Loss: 0.004795\t Remain : 0:15:04 \n",
      "Train Fold:3/4  Ep: 3/5 [30000/81928 (37%)]\t Loss: 0.005546\t Remain : 0:12:38 \n",
      "Train Fold:3/4  Ep: 3/5 [40000/81928 (49%)]\t Loss: 0.004663\t Remain : 0:10:12 \n",
      "Train Fold:3/4  Ep: 3/5 [50000/81928 (61%)]\t Loss: 0.005055\t Remain : 0:07:46 \n",
      "Train Fold:3/4  Ep: 3/5 [60000/81928 (73%)]\t Loss: 0.004724\t Remain : 0:05:20 \n",
      "Train Fold:3/4  Ep: 3/5 [70000/81928 (85%)]\t Loss: 0.005080\t Remain : 0:02:55 \n",
      "Train Fold:3/4  Ep: 3/5 [80000/81928 (98%)]\t Loss: 0.004707\t Remain : 0:00:29 \n",
      "Finish\n",
      "[0/27309 (0.0%)]\n",
      "[10000/27309 (36.5%)]\n",
      "[20000/27309 (73.0%)]\n",
      "Avg val loss:0.0056705799677755925\n",
      "Train Fold:3/4  Ep: 4/5 [0/81928 (0%)]\t Loss: 0.004997\t Remain : 0:00:00 \n",
      "Train Fold:3/4  Ep: 4/5 [10000/81928 (12%)]\t Loss: 0.005142\t Remain : 0:17:32 \n",
      "Train Fold:3/4  Ep: 4/5 [20000/81928 (24%)]\t Loss: 0.005420\t Remain : 0:15:06 \n",
      "Train Fold:3/4  Ep: 4/5 [30000/81928 (37%)]\t Loss: 0.004986\t Remain : 0:12:40 \n",
      "Train Fold:3/4  Ep: 4/5 [40000/81928 (49%)]\t Loss: 0.005309\t Remain : 0:10:13 \n",
      "Train Fold:3/4  Ep: 4/5 [50000/81928 (61%)]\t Loss: 0.005057\t Remain : 0:07:47 \n",
      "Train Fold:3/4  Ep: 4/5 [60000/81928 (73%)]\t Loss: 0.005790\t Remain : 0:05:21 \n",
      "Train Fold:3/4  Ep: 4/5 [70000/81928 (85%)]\t Loss: 0.004966\t Remain : 0:02:55 \n",
      "Train Fold:3/4  Ep: 4/5 [80000/81928 (98%)]\t Loss: 0.004820\t Remain : 0:00:29 \n",
      "Finish\n",
      "[0/27309 (0.0%)]\n",
      "[10000/27309 (36.5%)]\n",
      "[20000/27309 (73.0%)]\n",
      "Avg val loss:0.005662389337527056\n",
      "Train Fold:3/4  Ep: 5/5 [0/81928 (0%)]\t Loss: 0.004653\t Remain : 0:00:00 \n",
      "Train Fold:3/4  Ep: 5/5 [10000/81928 (12%)]\t Loss: 0.004721\t Remain : 0:17:33 \n",
      "Train Fold:3/4  Ep: 5/5 [20000/81928 (24%)]\t Loss: 0.005178\t Remain : 0:15:07 \n",
      "Train Fold:3/4  Ep: 5/5 [30000/81928 (37%)]\t Loss: 0.005014\t Remain : 0:12:40 \n",
      "Train Fold:3/4  Ep: 5/5 [40000/81928 (49%)]\t Loss: 0.005142\t Remain : 0:10:14 \n",
      "Train Fold:3/4  Ep: 5/5 [50000/81928 (61%)]\t Loss: 0.005570\t Remain : 0:07:48 \n",
      "Train Fold:3/4  Ep: 5/5 [60000/81928 (73%)]\t Loss: 0.004896\t Remain : 0:05:21 \n",
      "Train Fold:3/4  Ep: 5/5 [70000/81928 (85%)]\t Loss: 0.005057\t Remain : 0:02:55 \n",
      "Train Fold:3/4  Ep: 5/5 [80000/81928 (98%)]\t Loss: 0.005110\t Remain : 0:00:29 \n",
      "Finish\n",
      "[0/27309 (0.0%)]\n",
      "[10000/27309 (36.5%)]\n",
      "[20000/27309 (73.0%)]\n",
      "Avg val loss:0.00567402518150417\n",
      "Train Fold:4/4  Ep: 1/5 [0/81928 (0%)]\t Loss: 0.005584\t Remain : 0:00:00 \n",
      "Train Fold:4/4  Ep: 1/5 [10000/81928 (12%)]\t Loss: 0.005455\t Remain : 0:17:40 \n",
      "Train Fold:4/4  Ep: 1/5 [20000/81928 (24%)]\t Loss: 0.005084\t Remain : 0:15:12 \n",
      "Train Fold:4/4  Ep: 1/5 [30000/81928 (37%)]\t Loss: 0.005695\t Remain : 0:12:45 \n",
      "Train Fold:4/4  Ep: 1/5 [40000/81928 (49%)]\t Loss: 0.004708\t Remain : 0:10:18 \n",
      "Train Fold:4/4  Ep: 1/5 [50000/81928 (61%)]\t Loss: 0.005212\t Remain : 0:07:51 \n",
      "Train Fold:4/4  Ep: 1/5 [60000/81928 (73%)]\t Loss: 0.004862\t Remain : 0:05:23 \n",
      "Train Fold:4/4  Ep: 1/5 [70000/81928 (85%)]\t Loss: 0.006203\t Remain : 0:02:56 \n",
      "Train Fold:4/4  Ep: 1/5 [80000/81928 (98%)]\t Loss: 0.005477\t Remain : 0:00:29 \n",
      "Finish\n",
      "[0/27309 (0.0%)]\n",
      "[10000/27309 (36.5%)]\n",
      "[20000/27309 (73.0%)]\n",
      "Avg val loss:0.00491921268709439\n",
      "Train Fold:4/4  Ep: 2/5 [0/81928 (0%)]\t Loss: 0.005019\t Remain : 0:00:00 \n",
      "Train Fold:4/4  Ep: 2/5 [10000/81928 (12%)]\t Loss: 0.004786\t Remain : 0:17:53 \n",
      "Train Fold:4/4  Ep: 2/5 [20000/81928 (24%)]\t Loss: 0.004603\t Remain : 0:15:24 \n",
      "Train Fold:4/4  Ep: 2/5 [30000/81928 (37%)]\t Loss: 0.004169\t Remain : 0:12:55 \n",
      "Train Fold:4/4  Ep: 2/5 [40000/81928 (49%)]\t Loss: 0.004727\t Remain : 0:10:25 \n",
      "Train Fold:4/4  Ep: 2/5 [50000/81928 (61%)]\t Loss: 0.004674\t Remain : 0:07:56 \n",
      "Train Fold:4/4  Ep: 2/5 [60000/81928 (73%)]\t Loss: 0.004280\t Remain : 0:05:27 \n",
      "Train Fold:4/4  Ep: 2/5 [70000/81928 (85%)]\t Loss: 0.005030\t Remain : 0:02:58 \n",
      "Train Fold:4/4  Ep: 2/5 [80000/81928 (98%)]\t Loss: 0.004513\t Remain : 0:00:29 \n",
      "Finish\n",
      "[0/27309 (0.0%)]\n",
      "[10000/27309 (36.5%)]\n",
      "[20000/27309 (73.0%)]\n",
      "Avg val loss:0.004893070630674815\n",
      "Train Fold:4/4  Ep: 3/5 [0/81928 (0%)]\t Loss: 0.004901\t Remain : 0:00:00 \n",
      "Train Fold:4/4  Ep: 3/5 [10000/81928 (12%)]\t Loss: 0.004466\t Remain : 0:17:52 \n",
      "Train Fold:4/4  Ep: 3/5 [20000/81928 (24%)]\t Loss: 0.004643\t Remain : 0:15:23 \n",
      "Train Fold:4/4  Ep: 3/5 [30000/81928 (37%)]\t Loss: 0.004771\t Remain : 0:12:54 \n",
      "Train Fold:4/4  Ep: 3/5 [40000/81928 (49%)]\t Loss: 0.004382\t Remain : 0:10:25 \n",
      "Train Fold:4/4  Ep: 3/5 [50000/81928 (61%)]\t Loss: 0.004091\t Remain : 0:07:56 \n",
      "Train Fold:4/4  Ep: 3/5 [60000/81928 (73%)]\t Loss: 0.004595\t Remain : 0:05:27 \n",
      "Train Fold:4/4  Ep: 3/5 [70000/81928 (85%)]\t Loss: 0.003790\t Remain : 0:02:58 \n",
      "Train Fold:4/4  Ep: 3/5 [80000/81928 (98%)]\t Loss: 0.004438\t Remain : 0:00:29 \n",
      "Finish\n",
      "[0/27309 (0.0%)]\n",
      "[10000/27309 (36.5%)]\n",
      "[20000/27309 (73.0%)]\n",
      "Avg val loss:0.004896896840311097\n",
      "Train Fold:4/4  Ep: 4/5 [0/81928 (0%)]\t Loss: 0.004836\t Remain : 0:00:00 \n",
      "Train Fold:4/4  Ep: 4/5 [10000/81928 (12%)]\t Loss: 0.004670\t Remain : 0:17:51 \n",
      "Train Fold:4/4  Ep: 4/5 [20000/81928 (24%)]\t Loss: 0.004554\t Remain : 0:15:22 \n",
      "Train Fold:4/4  Ep: 4/5 [30000/81928 (37%)]\t Loss: 0.003856\t Remain : 0:12:53 \n",
      "Train Fold:4/4  Ep: 4/5 [40000/81928 (49%)]\t Loss: 0.004570\t Remain : 0:10:24 \n",
      "Train Fold:4/4  Ep: 4/5 [50000/81928 (61%)]\t Loss: 0.004140\t Remain : 0:07:56 \n",
      "Train Fold:4/4  Ep: 4/5 [60000/81928 (73%)]\t Loss: 0.004084\t Remain : 0:05:27 \n",
      "Train Fold:4/4  Ep: 4/5 [70000/81928 (85%)]\t Loss: 0.003887\t Remain : 0:02:58 \n",
      "Train Fold:4/4  Ep: 4/5 [80000/81928 (98%)]\t Loss: 0.004668\t Remain : 0:00:29 \n",
      "Finish\n",
      "[0/27309 (0.0%)]\n",
      "[10000/27309 (36.5%)]\n",
      "[20000/27309 (73.0%)]\n",
      "Avg val loss:0.00489702706062065\n",
      "Train Fold:4/4  Ep: 5/5 [0/81928 (0%)]\t Loss: 0.004477\t Remain : 0:00:00 \n",
      "Train Fold:4/4  Ep: 5/5 [10000/81928 (12%)]\t Loss: 0.004216\t Remain : 0:17:53 \n",
      "Train Fold:4/4  Ep: 5/5 [20000/81928 (24%)]\t Loss: 0.004118\t Remain : 0:15:24 \n",
      "Train Fold:4/4  Ep: 5/5 [30000/81928 (37%)]\t Loss: 0.004649\t Remain : 0:12:55 \n",
      "Train Fold:4/4  Ep: 5/5 [40000/81928 (49%)]\t Loss: 0.004438\t Remain : 0:10:26 \n",
      "Train Fold:4/4  Ep: 5/5 [50000/81928 (61%)]\t Loss: 0.004323\t Remain : 0:07:57 \n",
      "Train Fold:4/4  Ep: 5/5 [60000/81928 (73%)]\t Loss: 0.004336\t Remain : 0:05:27 \n",
      "Train Fold:4/4  Ep: 5/5 [70000/81928 (85%)]\t Loss: 0.004639\t Remain : 0:02:58 \n",
      "Train Fold:4/4  Ep: 5/5 [80000/81928 (98%)]\t Loss: 0.004317\t Remain : 0:00:29 \n",
      "Finish\n",
      "[0/27309 (0.0%)]\n",
      "[10000/27309 (36.5%)]\n",
      "[20000/27309 (73.0%)]\n",
      "Avg val loss:0.0048936777391273825\n"
     ]
    }
   ],
   "source": [
    "fold = KFold(n_splits = 4, random_state = 10)\n",
    "for fold_num, (trn_idx, val_idx) in enumerate(fold.split(datafilter)):\n",
    "    Ftrain_dataloader = datafilter[trn_idx, :]\n",
    "    Fval_dataloader = datafilter[val_idx, :]\n",
    "    #print(trn_idx,val_idx)\n",
    "\n",
    "    val_dataloader = DataLoader(dataset_h5(\"all_data_109237v1.h5\", data_transforms2, val_idx),batch_size=100, shuffle=False,num_workers=2, pin_memory=True)\n",
    "    train_dataloader = DataLoader(dataset_h5(\"all_data_109237v1.h5\", data_transforms2, trn_idx),batch_size=100, shuffle=True,num_workers=2, pin_memory=True)\n",
    "    for epoch in range(5):\n",
    "        ###########################################\n",
    "        if epoch==0:\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=0.0001/(2**epoch))\n",
    "        else:\n",
    "            optimizer = torch.optim.SGD(model.parameters(), lr=0.00008,momentum=0.9, weight_decay=1e-4)\n",
    "        #optimizer = torch.optim.Adam(model.parameters(), lr=0.00002/(2**epoch))\n",
    "        #optimizer = torch.optim.SGD(net.parameters(), lr=args.lr, momentum=0.9, weight_decay=1e-4)\n",
    "        loss_func = FocalLoss(0.4)\n",
    "        #loss_func = torch.nn.MSELoss()\n",
    "        ###########################################\n",
    "        train(epoch,fold_num,train_dataloader) \n",
    "        val(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov 22 07:41:53 2019       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 418.56       Driver Version: 418.56       CUDA Version: 10.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:01:00.0  On |                  N/A |\r\n",
      "| 66%   83C    P2    80W / 250W |   1813MiB / 11175MiB |      2%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:02:00.0 Off |                  N/A |\r\n",
      "| 52%   75C    P2    78W / 250W |    619MiB / 11178MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0      1137      G   /usr/lib/xorg/Xorg                            80MiB |\r\n",
      "|    0      2214      G   /opt/teamviewer/tv_bin/TeamViewer              2MiB |\r\n",
      "|    0     12945      G   ...uest-channel-token=14083820793621432878    85MiB |\r\n",
      "|    0     22250      G   /usr/lib/xorg/Xorg                           172MiB |\r\n",
      "|    0     22494      G                                                  4MiB |\r\n",
      "|    0     22924      G   compiz                                       140MiB |\r\n",
      "|    0     23722      G   /usr/lib/firefox/firefox                       2MiB |\r\n",
      "|    0     25016      C   /home/user1/pytorch_g/bin/python            1189MiB |\r\n",
      "|    0     31156      G   ...uest-channel-token=12496746042476819744    88MiB |\r\n",
      "|    1     25016      C   /home/user1/pytorch_g/bin/python             607MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user1/pytorch_g/lib/python3.5/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DataParallel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/user1/pytorch_g/lib/python3.5/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type SENet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/user1/pytorch_g/lib/python3.5/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/user1/pytorch_g/lib/python3.5/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Conv2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/user1/pytorch_g/lib/python3.5/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BatchNorm2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/user1/pytorch_g/lib/python3.5/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ReLU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/user1/pytorch_g/lib/python3.5/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type MaxPool2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/user1/pytorch_g/lib/python3.5/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type SEResNeXtBottleneck. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/user1/pytorch_g/lib/python3.5/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type SEModule. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/user1/pytorch_g/lib/python3.5/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type AdaptiveAvgPool2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/user1/pytorch_g/lib/python3.5/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sigmoid. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/user1/pytorch_g/lib/python3.5/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type AvgPool2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/user1/pytorch_g/lib/python3.5/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model, 'net.pkl')\n",
    "#model = torch.load('net.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('ag_net_4k_5e.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findPre(output,gate):\n",
    "    a = ''\n",
    "    output = np.array(output)\n",
    "    m = np.max(output)\n",
    "\n",
    "    for i in range(len(output)):\n",
    "        #s = np.where(v[i] > 0.95, 1, 0)\n",
    "        if output[i]>gate:\n",
    "            #print(output[i])\n",
    "            a = a + format(i)+' '\n",
    "            \n",
    "    #print(a)\n",
    "    return a\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,dloader,threshold):\n",
    "    model = model.eval().cuda()\n",
    "    #lengthD = len(dloader.dataset)\n",
    "    ans = []\n",
    "    out = []\n",
    "    for step, (x,x2, y) in enumerate(dloader):\n",
    "        data = Variable(x).cuda()\n",
    "        #data2 = Variable(x2).cuda()\n",
    "        #data = Variable(x)\n",
    "        target = y\n",
    "        #output = model(data,data2)\n",
    "        with torch.no_grad():\n",
    "            output = model(data).detach()\n",
    "        \n",
    "        #data.cpu()   # batch x\n",
    "        #data2.cpu()   # batch x\n",
    "        #target.cpu()   # batch y\n",
    "        #torch.cuda.empty_cache()\n",
    "        \n",
    "        v = output.cpu()\n",
    "        v = torch.sigmoid(v)\n",
    "        \n",
    "        v = torch.sigmoid(v)\n",
    "        v = np.array(v)\n",
    "        v = preprocessing.minmax_scale(v, feature_range=(0,1),axis=1)\n",
    "        for i in range(len(v)):\n",
    "            out.append(np.where(v[i] > threshold, 1, 0))\n",
    "            s = findPre(v[i],threshold)\n",
    "            ans.append([target[i],s])\n",
    "        if step %10 == 0:\n",
    "            print('[{}/{} ({:.1f}%)]'.format(step * len(data), \n",
    "                                        len(dloader.dataset),\n",
    "                                        100.*step/len(dloader)))\n",
    "            \n",
    "        data.cpu()\n",
    "        #data2.detach()\n",
    "        #target.detach()\n",
    "        torch.cuda.empty_cache()\n",
    "    print(\"Finish\")\n",
    "    return ans,out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "def makeScore(pre,ans):\n",
    "    pre = np.array(pre)\n",
    "    va = fbeta_score(y_pred=pre, y_true=ans, beta=2, average=\"samples\")\n",
    "    print(\"Score : {:.5f}\".format(va))\n",
    "    return va\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findThreshold():\n",
    "    score = []\n",
    "    candidates = np.arange(0, 1.0, 0.01)\n",
    "    for th in candidates:\n",
    "        print(\"Threshold : {:.2f}\".format(th))\n",
    "        _,pre = test(model = model,dloader = score_dataloader,threshold = th)\n",
    "        #return pre\n",
    "        score.append(makeScore(np.array(pre),np.array(train_a[:1000,1].tolist())))\n",
    "        print(\"=============================\")\n",
    "    pm = np.array(score).argmax()\n",
    "    best_th, best_score = candidates[pm], score[pm]\n",
    "    return best_th, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold : 0.00\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.01485\n",
      "=============================\n",
      "Threshold : 0.01\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.26739\n",
      "=============================\n",
      "Threshold : 0.02\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.35817\n",
      "=============================\n",
      "Threshold : 0.03\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.42349\n",
      "=============================\n",
      "Threshold : 0.04\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.47302\n",
      "=============================\n",
      "Threshold : 0.05\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.50969\n",
      "=============================\n",
      "Threshold : 0.06\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.54215\n",
      "=============================\n",
      "Threshold : 0.07\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.56198\n",
      "=============================\n",
      "Threshold : 0.08\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.58430\n",
      "=============================\n",
      "Threshold : 0.09\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.60071\n",
      "=============================\n",
      "Threshold : 0.10\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.61466\n",
      "=============================\n",
      "Threshold : 0.11\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.62545\n",
      "=============================\n",
      "Threshold : 0.12\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.63513\n",
      "=============================\n",
      "Threshold : 0.13\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.64105\n",
      "=============================\n",
      "Threshold : 0.14\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.65070\n",
      "=============================\n",
      "Threshold : 0.15\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.65495\n",
      "=============================\n",
      "Threshold : 0.16\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.65725\n",
      "=============================\n",
      "Threshold : 0.17\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.66051\n",
      "=============================\n",
      "Threshold : 0.18\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.66598\n",
      "=============================\n",
      "Threshold : 0.19\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.66613\n",
      "=============================\n",
      "Threshold : 0.20\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.66525\n",
      "=============================\n",
      "Threshold : 0.21\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.66853\n",
      "=============================\n",
      "Threshold : 0.22\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.67215\n",
      "=============================\n",
      "Threshold : 0.23\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.67657\n",
      "=============================\n",
      "Threshold : 0.24\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.67874\n",
      "=============================\n",
      "Threshold : 0.25\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.67900\n",
      "=============================\n",
      "Threshold : 0.26\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.67547\n",
      "=============================\n",
      "Threshold : 0.27\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.67110\n",
      "=============================\n",
      "Threshold : 0.28\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.67388\n",
      "=============================\n",
      "Threshold : 0.29\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.67017\n",
      "=============================\n",
      "Threshold : 0.30\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.67153\n",
      "=============================\n",
      "Threshold : 0.31\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.66651\n",
      "=============================\n",
      "Threshold : 0.32\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.66907\n",
      "=============================\n",
      "Threshold : 0.33\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.66548\n",
      "=============================\n",
      "Threshold : 0.34\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.66851\n",
      "=============================\n",
      "Threshold : 0.35\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.66011\n",
      "=============================\n",
      "Threshold : 0.36\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.66087\n",
      "=============================\n",
      "Threshold : 0.37\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.66022\n",
      "=============================\n",
      "Threshold : 0.38\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.65694\n",
      "=============================\n",
      "Threshold : 0.39\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.65757\n",
      "=============================\n",
      "Threshold : 0.40\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.65588\n",
      "=============================\n",
      "Threshold : 0.41\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.64974\n",
      "=============================\n",
      "Threshold : 0.42\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.64063\n",
      "=============================\n",
      "Threshold : 0.43\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.63137\n",
      "=============================\n",
      "Threshold : 0.44\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.63948\n",
      "=============================\n",
      "Threshold : 0.45\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.62907\n",
      "=============================\n",
      "Threshold : 0.46\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.63170\n",
      "=============================\n",
      "Threshold : 0.47\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.62294\n",
      "=============================\n",
      "Threshold : 0.48\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.61683\n",
      "=============================\n",
      "Threshold : 0.49\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.62174\n",
      "=============================\n",
      "Threshold : 0.50\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.61883\n",
      "=============================\n",
      "Threshold : 0.51\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.61242\n",
      "=============================\n",
      "Threshold : 0.52\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.60240\n",
      "=============================\n",
      "Threshold : 0.53\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.59748\n",
      "=============================\n",
      "Threshold : 0.54\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.59112\n",
      "=============================\n",
      "Threshold : 0.55\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.59745\n",
      "=============================\n",
      "Threshold : 0.56\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.59848\n",
      "=============================\n",
      "Threshold : 0.57\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.59287\n",
      "=============================\n",
      "Threshold : 0.58\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.59069\n",
      "=============================\n",
      "Threshold : 0.59\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.58251\n",
      "=============================\n",
      "Threshold : 0.60\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.58646\n",
      "=============================\n",
      "Threshold : 0.61\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.57715\n",
      "=============================\n",
      "Threshold : 0.62\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.56666\n",
      "=============================\n",
      "Threshold : 0.63\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.56625\n",
      "=============================\n",
      "Threshold : 0.64\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.56532\n",
      "=============================\n",
      "Threshold : 0.65\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.55639\n",
      "=============================\n",
      "Threshold : 0.66\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.56219\n",
      "=============================\n",
      "Threshold : 0.67\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.56167\n",
      "=============================\n",
      "Threshold : 0.68\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.54543\n",
      "=============================\n",
      "Threshold : 0.69\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.54571\n",
      "=============================\n",
      "Threshold : 0.70\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.53811\n",
      "=============================\n",
      "Threshold : 0.71\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.53989\n",
      "=============================\n",
      "Threshold : 0.72\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.53536\n",
      "=============================\n",
      "Threshold : 0.73\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.52467\n",
      "=============================\n",
      "Threshold : 0.74\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.51751\n",
      "=============================\n",
      "Threshold : 0.75\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.52003\n",
      "=============================\n",
      "Threshold : 0.76\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.51937\n",
      "=============================\n",
      "Threshold : 0.77\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.50724\n",
      "=============================\n",
      "Threshold : 0.78\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.50691\n",
      "=============================\n",
      "Threshold : 0.79\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.49654\n",
      "=============================\n",
      "Threshold : 0.80\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.50539\n",
      "=============================\n",
      "Threshold : 0.81\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.49205\n",
      "=============================\n",
      "Threshold : 0.82\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.48559\n",
      "=============================\n",
      "Threshold : 0.83\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.47974\n",
      "=============================\n",
      "Threshold : 0.84\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.47620\n",
      "=============================\n",
      "Threshold : 0.85\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.46767\n",
      "=============================\n",
      "Threshold : 0.86\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.46845\n",
      "=============================\n",
      "Threshold : 0.87\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.46134\n",
      "=============================\n",
      "Threshold : 0.88\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.45142\n",
      "=============================\n",
      "Threshold : 0.89\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.44587\n",
      "=============================\n",
      "Threshold : 0.90\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.43968\n",
      "=============================\n",
      "Threshold : 0.91\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.43281\n",
      "=============================\n",
      "Threshold : 0.92\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.43084\n",
      "=============================\n",
      "Threshold : 0.93\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.42357\n",
      "=============================\n",
      "Threshold : 0.94\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.41901\n",
      "=============================\n",
      "Threshold : 0.95\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.40715\n",
      "=============================\n",
      "Threshold : 0.96\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.39934\n",
      "=============================\n",
      "Threshold : 0.97\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.39459\n",
      "=============================\n",
      "Threshold : 0.98\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.38638\n",
      "=============================\n",
      "Threshold : 0.99\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.36602\n",
      "=============================\n",
      "Best Threshold : 0.25\n",
      "Best Score : 0.67900\n"
     ]
    }
   ],
   "source": [
    "bt, bs = findThreshold()\n",
    "print(\"Best Threshold : {:.2f}\".format(bt))\n",
    "print(\"Best Score : {:.5f}\".format(bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov 22 11:52:41 2019       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 418.56       Driver Version: 418.56       CUDA Version: 10.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:01:00.0  On |                  N/A |\r\n",
      "| 55%   76C    P2    81W / 250W |   2007MiB / 11175MiB |      5%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:02:00.0 Off |                  N/A |\r\n",
      "| 42%   69C    P2    76W / 250W |    621MiB / 11178MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0      1137      G   /usr/lib/xorg/Xorg                            80MiB |\r\n",
      "|    0      2214      G   /opt/teamviewer/tv_bin/TeamViewer              2MiB |\r\n",
      "|    0     12945      G   ...uest-channel-token=14083820793621432878    85MiB |\r\n",
      "|    0     22250      G   /usr/lib/xorg/Xorg                           172MiB |\r\n",
      "|    0     22494      G                                                  4MiB |\r\n",
      "|    0     22924      G   compiz                                       140MiB |\r\n",
      "|    0     23722      G   /usr/lib/firefox/firefox                       2MiB |\r\n",
      "|    0     25016      C   /home/user1/pytorch_g/bin/python            1381MiB |\r\n",
      "|    0     31156      G   ...uest-channel-token=12496746042476819744    88MiB |\r\n",
      "|    1     25016      C   /home/user1/pytorch_g/bin/python             607MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataFrame' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-63d2bacc5a25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msub\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'DataFrame' object is not callable"
     ]
    }
   ],
   "source": [
    "sub,_ = test(model = model,dloader = test_dataloader,threshold = bt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub =  pd.DataFrame(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = sub.rename(index=str, columns={0: \"id\", 1: \"attribute_ids\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
