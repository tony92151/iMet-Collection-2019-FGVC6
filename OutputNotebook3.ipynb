{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import torch\n",
      "from torch import nn, optim\n",
      "import torch.nn.functional as F\n",
      "import matplotlib.pyplot as plt\n",
      "import sys\n",
      "import time\n",
      "import numpy as np\n",
      "import math\n",
      "import pandas as pd\n",
      "from PIL import Image, ImageOps, ImageFilter\n",
      "from datetime import datetime\n",
      "from torch.autograd import Variable\n",
      "from torch.utils.data import Dataset, DataLoader\n",
      "import torchvision.transforms as transforms\n",
      "from torchvision import datasets, models, transforms\n",
      "import random\n",
      "import datetime\n",
      "import os\n",
      "\n",
      "import cv2  \n",
      "from sklearn import preprocessing \n",
      "from sklearn.model_selection import KFold\n",
      "import h5py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
      "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
      "print(device)\n",
      "\n",
      "print(\"GPU\",torch.cuda.device_count())\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "cuda:0\n",
        "GPU 1\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!nvidia-smi"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Sat Nov 23 16:02:57 2019       \r\n",
        "+-----------------------------------------------------------------------------+\r\n",
        "| NVIDIA-SMI 410.104      Driver Version: 410.104      CUDA Version: 10.0     |\r\n",
        "|-------------------------------+----------------------+----------------------+\r\n",
        "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
        "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
        "|===============================+======================+======================|\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "|   0  Tesla V100-PCIE...  Off  | 00000000:1E:00.0 Off |                    0 |\r\n",
        "| N/A   32C    P0    27W / 250W |     11MiB / 32480MiB |      0%      Default |\r\n",
        "+-------------------------------+----------------------+----------------------+\r\n",
        "                                                                               \r\n",
        "+-----------------------------------------------------------------------------+\r\n",
        "| Processes:                                                       GPU Memory |\r\n",
        "|  GPU       PID   Type   Process name                             Usage      |\r\n",
        "|=============================================================================|\r\n",
        "|  No running processes found                                                 |\r\n",
        "+-----------------------------------------------------------------------------+\r\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from albumentations import (\n",
      "    HorizontalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
      "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
      "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, RandomBrightnessContrast, IAAPiecewiseAffine,\n",
      "    IAASharpen, IAAEmboss, Flip, OneOf, Compose,RandomContrast,RandomBrightness,Resize\n",
      ")\n",
      "import albumentations\n",
      "\n",
      "\n",
      "# In[4]:\n",
      "\n",
      "\n",
      "from torch.utils.data import DataLoader\n",
      "from prefetch_generator import BackgroundGenerator\n",
      "\n",
      "class DataLoaderX(DataLoader):\n",
      "\n",
      "    def __iter__(self):\n",
      "        return BackgroundGenerator(super().__iter__())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# os.chdir(\"../input/pretrained_PyTorch/\")\n",
      "path = os.getcwd()\n",
      "print(path)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/root/notebooks/imet/iMet-Collection-2019-FGVC6\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train = pd.read_csv(path+\"/train.csv\")\n",
      "lable = pd.read_csv(path+\"/labels.csv\")\n",
      "test = pd.read_csv(path+\"/sample_submission.csv\")\n",
      "\n",
      "\n",
      "# In[7]:\n",
      "\n",
      "\n",
      "lable_length = len(lable)\n",
      "train_length = len(train)\n",
      "test_length = len(test)\n",
      "print(train_length)\n",
      "print(lable_length)\n",
      "print(test_length)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "109237\n",
        "1103\n",
        "38801\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(np.array(lable)[397])\n",
      "print(np.array(lable)[398])\n",
      "c_length = len(np.array(lable)[:398])\n",
      "t_length = len(np.array(lable)[398:])\n",
      "print(c_length)\n",
      "print(t_length)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[397 'culture::zurich']\n",
        "[398 'tag::abbies']\n",
        "398\n",
        "705\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def creatData(train,lable_length):\n",
      "    train = np.array(train)\n",
      "    trainA_data = []\n",
      "    lab_data = []\n",
      "    #trainC_data = []\n",
      "    #trainT_data = []\n",
      "    for t in range(train_length):\n",
      "        v = np.zeros(lable_length)\n",
      "        #print(train[t,1])\n",
      "        lab = []\n",
      "        for s in train[t,1].split(\" \"):\n",
      "            #print(s)\n",
      "            v[int(s)] = 1\n",
      "            lab.append(int(s))\n",
      "            \n",
      "#         img = Image.open(path+\"/train/\"+format(train[t,0])+'.png')  # PIL image\n",
      "#         img = cv2.cvtColor(np.asarray(img),cv2.COLOR_RGB2BGR)\n",
      "#         img = aug(image = img)['image']\n",
      "#         #openCV to PIL\n",
      "#         img = Image.fromarray(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\n",
      "        \n",
      "        trainA_data.append([train[t,0],v])\n",
      "        lab_data.append([train[t,0],np.array(lab)])\n",
      "\n",
      "        #trainC_data.append([train[t,0],v[:c_length]])\n",
      "        #trainT_data.append([train[t,0],v[c_length:]])\n",
      "    return np.array(trainA_data),np.array(lab_data)\n",
      "    #return np.array(trainA_data)#,np.array(trainC_data),np.array(trainT_data)\n",
      "\n",
      "\n",
      "# In[14]:\n",
      "\n",
      "\n",
      "train_a,train_lab = creatData(train,lable_length)\n",
      "#train_a,train_c,train_t = creatData(train,lable_length)\n",
      "\n",
      "\n",
      "def dfilter(data,th):\n",
      "    dfilter = []\n",
      "    for i in range(len(data)):\n",
      "        if train_a[i][1].sum()>th:\n",
      "            dfilter.append(train_a[i])\n",
      "    return np.array(dfilter)\n",
      "\n",
      "\n",
      "# In[17]:\n",
      "\n",
      "\n",
      "datafilter = dfilter(train_a,1) # remain feature great then 1\n",
      "\n",
      "\n",
      "# In[18]:\n",
      "\n",
      "\n",
      "print(\"amount of image before: {}\".format(len(train_a)))\n",
      "\n",
      "print(\"amount of image after: {}\".format(len(datafilter)))\n",
      "\n",
      "\n",
      "# In[19]:\n",
      "\n",
      "\n",
      "# not use\n",
      "datafilter = train_a"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "amount of image before: 109237\n",
        "amount of image after: 104913\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "image_resize = 200\n",
      "data_transforms2 = transforms.Compose([\n",
      "    transforms.Resize((image_resize,image_resize)),\n",
      "    #transforms.RandomResizedCrop(250),\n",
      "    #transforms.RandomHorizontalFlip(),\n",
      "    transforms.ToTensor(),\n",
      "    transforms.Normalize(\n",
      "            [0.485, 0.456, 0.406], \n",
      "            [0.229, 0.224, 0.225])\n",
      "    ])\n",
      "\n",
      "\n",
      "data_transforms = transforms.Compose([\n",
      "    transforms.Resize((image_resize,image_resize)),\n",
      "    #transforms.RandomResizedCrop(250),\n",
      "    #transforms.RandomHorizontalFlip(),\n",
      "    transforms.ToTensor(),\n",
      "    #transforms.Normalize(\n",
      "    #        [0.485, 0.456, 0.406], \n",
      "    #        [0.229, 0.224, 0.225])\n",
      "    ])\n",
      "\n",
      "train_transformer = transforms.Compose([\n",
      "    transforms.Resize((128,128)),              # resize the image to \n",
      "    #transforms.RandomHorizontalFlip(),  # randomly flip image horizontally\n",
      "    #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
      "    transforms.ToTensor(),           # transform it into a PyTorch Tensor\n",
      "    #transforms.Normalize(mean = (0.5, 0.5, 0.5), std = (0.5, 0.5, 0.5))\n",
      "])\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load2mem(in_file,transform):\n",
      "    print(\"Load data from .h5 file...\")\n",
      "    t = time.time()\n",
      "    prefile = h5py.File(in_file, 'r')\n",
      "#     preloadimg = []\n",
      "#     for i in prefile['train_img'][:,:,:]:\n",
      "#         preloadimg.append(transform(i))\n",
      "    preloadimg = prefile['train_img'][:,:,:]\n",
      "    preloadleb = prefile['train_labels'][:,:]\n",
      "    print(\"Done\")\n",
      "    print(\"Take\",datetime.timedelta(seconds = int(time.time()-t)),\"seconds\")\n",
      "    return preloadimg, preloadleb\n",
      "\n",
      "\n",
      "\n",
      "a,b = load2mem(\"all_data_109237v1.h5\", data_transforms2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Load data from .h5 file...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Done\n",
        "Take 0:12:07 seconds\n"
       ]
      }
     ],
     "prompt_number": 10
    }
   ],
   "metadata": {}
  }
 ]
}
