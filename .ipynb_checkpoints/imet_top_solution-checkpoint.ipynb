{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pytorch_seresnext101-32x4d+kfold+focal loss v3.0\n",
    "\n",
    "\n",
    "* fold = 4\n",
    "* epoch = 3\n",
    "* Î³=0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Nov 23 05:31:29 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 410.104      Driver Version: 410.104      CUDA Version: 10.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-PCIE...  Off  | 00000000:1E:00.0 Off |                    0 |\n",
      "| N/A   32C    P0    27W / 250W |      0MiB / 32480MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageOps, ImageFilter\n",
    "from datetime import datetime\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, models, transforms\n",
    "import random\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "import cv2  \n",
    "from sklearn import preprocessing \n",
    "from sklearn.model_selection import KFold\n",
    "import h5py\n",
    "\n",
    "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import (\n",
    "    HorizontalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
    "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, RandomBrightnessContrast, IAAPiecewiseAffine,\n",
    "    IAASharpen, IAAEmboss, Flip, OneOf, Compose,RandomContrast,RandomBrightness,Resize\n",
    ")\n",
    "import albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from prefetch_generator import BackgroundGenerator\n",
    "\n",
    "class DataLoaderX(DataLoader):\n",
    "\n",
    "    def __iter__(self):\n",
    "        return BackgroundGenerator(super().__iter__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/notebooks/imet/iMet-Collection-2019-FGVC6\n"
     ]
    }
   ],
   "source": [
    "# os.chdir(\"../input/pretrained_PyTorch/\")\n",
    "path = os.getcwd()\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(path+\"/train.csv\")\n",
    "lable = pd.read_csv(path+\"/labels.csv\")\n",
    "test = pd.read_csv(path+\"/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109237\n",
      "1103\n",
      "38801\n"
     ]
    }
   ],
   "source": [
    "lable_length = len(lable)\n",
    "train_length = len(train)\n",
    "test_length = len(test)\n",
    "print(train_length)\n",
    "print(lable_length)\n",
    "print(test_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[397 'culture::zurich']\n",
      "[398 'tag::abbies']\n",
      "398\n",
      "705\n"
     ]
    }
   ],
   "source": [
    "print(np.array(lable)[397])\n",
    "print(np.array(lable)[398])\n",
    "c_length = len(np.array(lable)[:398])\n",
    "t_length = len(np.array(lable)[398:])\n",
    "print(c_length)\n",
    "print(t_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.array(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.array(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(p=.5):\n",
    "    return Compose([\n",
    "        HorizontalFlip(p=0.5),\n",
    "        OneOf([\n",
    "            RandomBrightness(0.1, p=1),\n",
    "            RandomContrast(0.1, p=1),\n",
    "        ], p=0.3),\n",
    "        ShiftScaleRotate(shift_limit=0.1, scale_limit=0.0, rotate_limit=15, p=0.3),\n",
    "        IAAAdditiveGaussianNoise(p=0.3),\n",
    "        Resize(100,100)\n",
    "    ], p=p)\n",
    "def strong_aug(p=.5):\n",
    "    return Compose([\n",
    "        RandomRotate90(),\n",
    "        Flip(),\n",
    "        Transpose(),\n",
    "        OneOf([\n",
    "            IAAAdditiveGaussianNoise(),\n",
    "            GaussNoise(),\n",
    "        ], p=0.2),\n",
    "        OneOf([\n",
    "            MotionBlur(p=.2),\n",
    "            MedianBlur(blur_limit=3, p=0.1),\n",
    "            Blur(blur_limit=3, p=0.1),\n",
    "        ], p=0.2),\n",
    "        ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=45, p=0.2),\n",
    "        OneOf([\n",
    "            OpticalDistortion(p=0.3),\n",
    "            GridDistortion(p=.1),\n",
    "            IAAPiecewiseAffine(p=0.3),\n",
    "        ], p=0.2),\n",
    "        OneOf([\n",
    "            CLAHE(clip_limit=2),\n",
    "            IAASharpen(),\n",
    "            IAAEmboss(),\n",
    "            RandomBrightnessContrast(),            \n",
    "        ], p=0.3),\n",
    "        HueSaturationValue(p=0.3),\n",
    "    ], p=p)\n",
    "\n",
    "aug = augment(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creatData(train,lable_length):\n",
    "    train = np.array(train)\n",
    "    trainA_data = []\n",
    "    lab_data = []\n",
    "    #trainC_data = []\n",
    "    #trainT_data = []\n",
    "    for t in range(train_length):\n",
    "        v = np.zeros(lable_length)\n",
    "        #print(train[t,1])\n",
    "        lab = []\n",
    "        for s in train[t,1].split(\" \"):\n",
    "            #print(s)\n",
    "            v[int(s)] = 1\n",
    "            lab.append(int(s))\n",
    "            \n",
    "#         img = Image.open(path+\"/train/\"+format(train[t,0])+'.png')  # PIL image\n",
    "#         img = cv2.cvtColor(np.asarray(img),cv2.COLOR_RGB2BGR)\n",
    "#         img = aug(image = img)['image']\n",
    "#         #openCV to PIL\n",
    "#         img = Image.fromarray(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "        trainA_data.append([train[t,0],v])\n",
    "        lab_data.append([train[t,0],np.array(lab)])\n",
    "\n",
    "        #trainC_data.append([train[t,0],v[:c_length]])\n",
    "        #trainT_data.append([train[t,0],v[c_length:]])\n",
    "    return np.array(trainA_data),np.array(lab_data)\n",
    "    #return np.array(trainA_data)#,np.array(trainC_data),np.array(trainT_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_a,train_lab = creatData(train,lable_length)\n",
    "#train_a,train_c,train_t = creatData(train,lable_length)\n",
    "#train_t.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1000483014d91860', array([147, 616, 813])], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lab[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove the item that only have one feature (not work well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfilter(data,th):\n",
    "    dfilter = []\n",
    "    for i in range(len(data)):\n",
    "        if train_a[i][1].sum()>th:\n",
    "            dfilter.append(train_a[i])\n",
    "    return np.array(dfilter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafilter = dfilter(train_a,1) # remain feature great then 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount of image before: 109237\n",
      "amount of image after: 104913\n"
     ]
    }
   ],
   "source": [
    "print(\"amount of image before: {}\".format(len(train_a)))\n",
    "\n",
    "print(\"amount of image after: {}\".format(len(datafilter)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not use\n",
    "datafilter = train_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1000483014d91860', array([0., 0., 0., ..., 0., 0., 0.])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datafilter[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_resize = 200\n",
    "data_transforms2 = transforms.Compose([\n",
    "    transforms.Resize((image_resize,image_resize)),\n",
    "    #transforms.RandomResizedCrop(250),\n",
    "    #transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "            [0.485, 0.456, 0.406], \n",
    "            [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((image_resize,image_resize)),\n",
    "    #transforms.RandomResizedCrop(250),\n",
    "    #transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize(\n",
    "    #        [0.485, 0.456, 0.406], \n",
    "    #        [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "train_transformer = transforms.Compose([\n",
    "    transforms.Resize((128,128)),              # resize the image to \n",
    "    #transforms.RandomHorizontalFlip(),  # randomly flip image horizontally\n",
    "    #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    transforms.ToTensor(),           # transform it into a PyTorch Tensor\n",
    "    #transforms.Normalize(mean = (0.5, 0.5, 0.5), std = (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_transforms = transforms.Compose([\n",
    "#     augment()['image'],\n",
    "#     transforms.Resize((image_resize,image_resize)),\n",
    "#     HorizontalFlip(p=0.5),\n",
    "#     OneOf([\n",
    "#         RandomBrightness(0.1, p=1),\n",
    "#         RandomContrast(0.1, p=1),\n",
    "#     ], p=0.3),\n",
    "#     ShiftScaleRotate(shift_limit=0.1, scale_limit=0.0, rotate_limit=15, p=0.3),\n",
    "#     IAAAdditiveGaussianNoise(p=0.3),\n",
    "#     #transforms.RandomResizedCrop(250),\n",
    "#     #transforms.RandomHorizontalFlip(),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(\n",
    "#             [0.485, 0.456, 0.406], \n",
    "#             [0.229, 0.224, 0.225])\n",
    "#     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load2mem(in_file,transform):\n",
    "    print(\"Load data from .h5 file...\")\n",
    "    t = time.time()\n",
    "    prefile = h5py.File(in_file, 'r')\n",
    "#     preloadimg = []\n",
    "#     for i in prefile['train_img'][:,:,:]:\n",
    "#         preloadimg.append(transform(i))\n",
    "    preloadimg = prefile['train_img'][:,:,:]\n",
    "    preloadleb = prefile['train_labels'][:,:]\n",
    "    print(\"Done\")\n",
    "    print(\"Take\",datetime.timedelta(seconds = int(time.time()-t)),\"seconds\")\n",
    "    return preloadimg, preloadleb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a,b = load2mem(\"all_data_109237v1.h5\", data_transforms2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset_h5(torch.utils.data.Dataset):\n",
    "    def __init__(self, in_file, transform, kdata):\n",
    "        super(dataset_h5, self).__init__()\n",
    "\n",
    "        self.file = h5py.File(in_file, 'r')\n",
    "        self.n_images = len(kdata)\n",
    "        self.kdata = kdata\n",
    "        self.transform = transform\n",
    "        print(\"Load data from .h5 file...\")\n",
    "        t = time.time()\n",
    "        self.preloadimg = self.file['train_img'][self.kdata,:,:]\n",
    "        self.preloadleb = self.file['train_labels'][self.kdata,:]\n",
    "        print(\"Take\",datetime.timedelta(seconds = int(time.time()-t)),\"seconds\")\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        input_img = Image.fromarray(self.preloadimg[index])\n",
    "        \n",
    "        input_img = self.transform(input_img)\n",
    "        \n",
    "        input_lab = self.preloadleb[index]\n",
    "        return input_img,input_lab\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class trainDataset(Dataset):\n",
    "    def __init__(self, train_lib, transform,transform2):\n",
    "        self.filenames = train_lib[:,0]\n",
    "        self.labels = train_lib[:,1]\n",
    "        self.transform = transform\n",
    "        self.transform2 = transform2\n",
    "        #self.new_feature = \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(path+\"/train/\"+format(self.filenames[idx])+'.png')  # PIL image\n",
    "        \n",
    "        #PIL to openCV\n",
    "        imgv = cv2.cvtColor(np.asarray(img),cv2.COLOR_RGB2BGR)\n",
    "        imgv = aug(image = imgv)['image']\n",
    "        #openCV to PIL\n",
    "        img = Image.fromarray(cv2.cvtColor(imgv,cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "        #image= image.filter(ImageFilter.EDGE_ENHANCE)\n",
    "        #image2 = image.filter(ImageFilter.FIND_EDGES)\n",
    "        image = self.transform(img)\n",
    "        image2 = self.transform2(img)\n",
    "        #return image, self.labels[idx]\n",
    "        return image,image2, self.labels[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class testDataset(Dataset):\n",
    "    def __init__(self, test_lib, transform,transform2):\n",
    "        test_lib = np.array(test_lib)\n",
    "        self.filenames = test_lib[:,0]\n",
    "        #self.labels = test_lib[:,1]\n",
    "        self.transform = transform\n",
    "        self.transform2 = transform2\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(path+\"/test/\"+format(self.filenames[idx])+'.png')  # PIL image\n",
    "        #image= image.filter(ImageFilter.EDGE_ENHANCE)\n",
    "        #image2 = image.filter(ImageFilter.FIND_EDGES)\n",
    "        image = self.transform(img)\n",
    "        image2 = self.transform2(img)\n",
    "        #return image,self.filenames[idx]\n",
    "        return image,image2,self.filenames[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainA_dataloader = DataLoader(dataset_h5(\"all_data_109237v1.h5\", data_transforms2),batch_size=128, shuffle=True,num_workers=2, pin_memory=True)\n",
    "#trainC_dataloader = DataLoader(trainDataset(train_c, data_transforms,data_transforms2),batch_size=32, shuffle=True,num_workers=2, pin_memory=True)\n",
    "#trainT_dataloader = DataLoader(trainDataset(train_t, data_transforms,data_transforms2),batch_size=32, shuffle=True,num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_dataloader = DataLoaderX(trainDataset(datafilter[:1000], data_transforms,data_transforms2),batch_size=128, shuffle=False,num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoaderX(testDataset(test, data_transforms,data_transforms2),batch_size=128,shuffle=False,num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10,10))\n",
    "# plt.subplot(2,2,1)\n",
    "# plt.imshow(transforms.ToPILImage()(trainA_dataloader.dataset[15][0]).convert('RGB'))\n",
    "# plt.subplot(2,2,2)\n",
    "# plt.imshow(transforms.ToPILImage()(trainA_dataloader.dataset[15][1]).convert('RGB'))\n",
    "# plt.subplot(2,2,3)\n",
    "# plt.imshow(transforms.ToPILImage()(trainA_dataloader.dataset[29][0]).convert('RGB'))\n",
    "# plt.subplot(2,2,4)\n",
    "# plt.imshow(transforms.ToPILImage()(trainA_dataloader.dataset[29][1]).convert('RGB'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(np.array(trainC_dataloader.dataset[4][0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/Cadene/pretrained-models.pytorch/blob/master/pretrainedmodels/models/senet.py\n",
    "\"\"\"\n",
    "ResNet code gently borrowed from\n",
    "https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py\n",
    "\"\"\"\n",
    "from __future__ import print_function, division, absolute_import\n",
    "from collections import OrderedDict\n",
    "import math\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils import model_zoo\n",
    "\n",
    "__all__ = ['SENet', 'senet154', 'se_resnet50', 'se_resnet101', 'se_resnet152',\n",
    "           'se_resnext50_32x4d', 'se_resnext101_32x4d']\n",
    "\n",
    "pretrained_settings = {\n",
    "    'senet154': {\n",
    "        'imagenet': {\n",
    "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/senet154-c7b49a05.pth',\n",
    "            'input_space': 'RGB',\n",
    "            'input_size': [3, 224, 224],\n",
    "            'input_range': [0, 1],\n",
    "            'mean': [0.485, 0.456, 0.406],\n",
    "            'std': [0.229, 0.224, 0.225],\n",
    "            'num_classes': 1000\n",
    "        }\n",
    "    },\n",
    "    'se_resnet50': {\n",
    "        'imagenet': {\n",
    "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnet50-ce0d4300.pth',\n",
    "            'input_space': 'RGB',\n",
    "            'input_size': [3, 224, 224],\n",
    "            'input_range': [0, 1],\n",
    "            'mean': [0.485, 0.456, 0.406],\n",
    "            'std': [0.229, 0.224, 0.225],\n",
    "            'num_classes': 1000\n",
    "        }\n",
    "    },\n",
    "    'se_resnet101': {\n",
    "        'imagenet': {\n",
    "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnet101-7e38fcc6.pth',\n",
    "            'input_space': 'RGB',\n",
    "            'input_size': [3, 224, 224],\n",
    "            'input_range': [0, 1],\n",
    "            'mean': [0.485, 0.456, 0.406],\n",
    "            'std': [0.229, 0.224, 0.225],\n",
    "            'num_classes': 1000\n",
    "        }\n",
    "    },\n",
    "    'se_resnet152': {\n",
    "        'imagenet': {\n",
    "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnet152-d17c99b7.pth',\n",
    "            'input_space': 'RGB',\n",
    "            'input_size': [3, 224, 224],\n",
    "            'input_range': [0, 1],\n",
    "            'mean': [0.485, 0.456, 0.406],\n",
    "            'std': [0.229, 0.224, 0.225],\n",
    "            'num_classes': 1000\n",
    "        }\n",
    "    },\n",
    "    'se_resnext50_32x4d': {\n",
    "        'imagenet': {\n",
    "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnext50_32x4d-a260b3a4.pth',\n",
    "            'input_space': 'RGB',\n",
    "            'input_size': [3, 224, 224],\n",
    "            'input_range': [0, 1],\n",
    "            'mean': [0.485, 0.456, 0.406],\n",
    "            'std': [0.229, 0.224, 0.225],\n",
    "            'num_classes': 1000\n",
    "        }\n",
    "    },\n",
    "    'se_resnext101_32x4d': {\n",
    "        'imagenet': {\n",
    "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnext101_32x4d-3b2fe3d8.pth',\n",
    "            'input_space': 'RGB',\n",
    "            'input_size': [3, 224, 224],\n",
    "            'input_range': [0, 1],\n",
    "            'mean': [0.485, 0.456, 0.406],\n",
    "            'std': [0.229, 0.224, 0.225],\n",
    "            'num_classes': 1000\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "class SEModule(nn.Module):\n",
    "\n",
    "    def __init__(self, channels, reduction):\n",
    "        super(SEModule, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Conv2d(channels, channels // reduction, kernel_size=1,\n",
    "                             padding=0)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Conv2d(channels // reduction, channels, kernel_size=1,\n",
    "                             padding=0)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        module_input = x\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return module_input * x\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    \"\"\"\n",
    "    Base class for bottlenecks that implements `forward()` method.\n",
    "    \"\"\"\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out = self.se_module(out) + residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class SEBottleneck(Bottleneck):\n",
    "    \"\"\"\n",
    "    Bottleneck for SENet154.\n",
    "    \"\"\"\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n",
    "                 downsample=None):\n",
    "        super(SEBottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes * 2, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes * 2)\n",
    "        self.conv2 = nn.Conv2d(planes * 2, planes * 4, kernel_size=3,\n",
    "                               stride=stride, padding=1, groups=groups,\n",
    "                               bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes * 4)\n",
    "        self.conv3 = nn.Conv2d(planes * 4, planes * 4, kernel_size=1,\n",
    "                               bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.se_module = SEModule(planes * 4, reduction=reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "\n",
    "class SEResNetBottleneck(Bottleneck):\n",
    "    \"\"\"\n",
    "    ResNet bottleneck with a Squeeze-and-Excitation module. It follows Caffe\n",
    "    implementation and uses `stride=stride` in `conv1` and not in `conv2`\n",
    "    (the latter is used in the torchvision implementation of ResNet).\n",
    "    \"\"\"\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n",
    "                 downsample=None):\n",
    "        super(SEResNetBottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False,\n",
    "                               stride=stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, padding=1,\n",
    "                               groups=groups, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.se_module = SEModule(planes * 4, reduction=reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "\n",
    "class SEResNeXtBottleneck(Bottleneck):\n",
    "    \"\"\"\n",
    "    ResNeXt bottleneck type C with a Squeeze-and-Excitation module.\n",
    "    \"\"\"\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n",
    "                 downsample=None, base_width=4):\n",
    "        super(SEResNeXtBottleneck, self).__init__()\n",
    "        width = math.floor(planes * (base_width / 64)) * groups\n",
    "        self.conv1 = nn.Conv2d(inplanes, width, kernel_size=1, bias=False,\n",
    "                               stride=1)\n",
    "        self.bn1 = nn.BatchNorm2d(width)\n",
    "        self.conv2 = nn.Conv2d(width, width, kernel_size=3, stride=stride,\n",
    "                               padding=1, groups=groups, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(width)\n",
    "        self.conv3 = nn.Conv2d(width, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.se_module = SEModule(planes * 4, reduction=reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "\n",
    "class SENet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, groups, reduction, dropout_p=0.2,\n",
    "                 inplanes=128, input_3x3=True, downsample_kernel_size=3,\n",
    "                 downsample_padding=1, num_classes=1000):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        block (nn.Module): Bottleneck class.\n",
    "            - For SENet154: SEBottleneck\n",
    "            - For SE-ResNet models: SEResNetBottleneck\n",
    "            - For SE-ResNeXt models:  SEResNeXtBottleneck\n",
    "        layers (list of ints): Number of residual blocks for 4 layers of the\n",
    "            network (layer1...layer4).\n",
    "        groups (int): Number of groups for the 3x3 convolution in each\n",
    "            bottleneck block.\n",
    "            - For SENet154: 64\n",
    "            - For SE-ResNet models: 1\n",
    "            - For SE-ResNeXt models:  32\n",
    "        reduction (int): Reduction ratio for Squeeze-and-Excitation modules.\n",
    "            - For all models: 16\n",
    "        dropout_p (float or None): Drop probability for the Dropout layer.\n",
    "            If `None` the Dropout layer is not used.\n",
    "            - For SENet154: 0.2\n",
    "            - For SE-ResNet models: None\n",
    "            - For SE-ResNeXt models: None\n",
    "        inplanes (int):  Number of input channels for layer1.\n",
    "            - For SENet154: 128\n",
    "            - For SE-ResNet models: 64\n",
    "            - For SE-ResNeXt models: 64\n",
    "        input_3x3 (bool): If `True`, use three 3x3 convolutions instead of\n",
    "            a single 7x7 convolution in layer0.\n",
    "            - For SENet154: True\n",
    "            - For SE-ResNet models: False\n",
    "            - For SE-ResNeXt models: False\n",
    "        downsample_kernel_size (int): Kernel size for downsampling convolutions\n",
    "            in layer2, layer3 and layer4.\n",
    "            - For SENet154: 3\n",
    "            - For SE-ResNet models: 1\n",
    "            - For SE-ResNeXt models: 1\n",
    "        downsample_padding (int): Padding for downsampling convolutions in\n",
    "            layer2, layer3 and layer4.\n",
    "            - For SENet154: 1\n",
    "            - For SE-ResNet models: 0\n",
    "            - For SE-ResNeXt models: 0\n",
    "        num_classes (int): Number of outputs in `last_linear` layer.\n",
    "            - For all models: 1000\n",
    "        \"\"\"\n",
    "        super(SENet, self).__init__()\n",
    "        self.inplanes = inplanes\n",
    "        if input_3x3:\n",
    "            layer0_modules = [\n",
    "                ('conv1', nn.Conv2d(3, 64, 3, stride=2, padding=1,\n",
    "                                    bias=False)),\n",
    "                ('bn1', nn.BatchNorm2d(64)),\n",
    "                ('relu1', nn.ReLU(inplace=True)),\n",
    "                ('conv2', nn.Conv2d(64, 64, 3, stride=1, padding=1,\n",
    "                                    bias=False)),\n",
    "                ('bn2', nn.BatchNorm2d(64)),\n",
    "                ('relu2', nn.ReLU(inplace=True)),\n",
    "                ('conv3', nn.Conv2d(64, inplanes, 3, stride=1, padding=1,\n",
    "                                    bias=False)),\n",
    "                ('bn3', nn.BatchNorm2d(inplanes)),\n",
    "                ('relu3', nn.ReLU(inplace=True)),\n",
    "            ]\n",
    "        else:\n",
    "            layer0_modules = [\n",
    "                ('conv1', nn.Conv2d(3, inplanes, kernel_size=7, stride=2,\n",
    "                                    padding=3, bias=False)),\n",
    "                ('bn1', nn.BatchNorm2d(inplanes)),\n",
    "                ('relu1', nn.ReLU(inplace=True)),\n",
    "            ]\n",
    "        # To preserve compatibility with Caffe weights `ceil_mode=True`\n",
    "        # is used instead of `padding=1`.\n",
    "        layer0_modules.append(('pool', nn.MaxPool2d(3, stride=2,\n",
    "                                                    ceil_mode=True)))\n",
    "        self.layer0 = nn.Sequential(OrderedDict(layer0_modules))\n",
    "        self.layer1 = self._make_layer(\n",
    "            block,\n",
    "            planes=64,\n",
    "            blocks=layers[0],\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=1,\n",
    "            downsample_padding=0\n",
    "        )\n",
    "        self.layer2 = self._make_layer(\n",
    "            block,\n",
    "            planes=128,\n",
    "            blocks=layers[1],\n",
    "            stride=2,\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=downsample_kernel_size,\n",
    "            downsample_padding=downsample_padding\n",
    "        )\n",
    "        self.layer3 = self._make_layer(\n",
    "            block,\n",
    "            planes=256,\n",
    "            blocks=layers[2],\n",
    "            stride=2,\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=downsample_kernel_size,\n",
    "            downsample_padding=downsample_padding\n",
    "        )\n",
    "        self.layer4 = self._make_layer(\n",
    "            block,\n",
    "            planes=512,\n",
    "            blocks=layers[3],\n",
    "            stride=2,\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=downsample_kernel_size,\n",
    "            downsample_padding=downsample_padding\n",
    "        )\n",
    "        self.avg_pool = nn.AvgPool2d(7, stride=1)\n",
    "        self.dropout = nn.Dropout(dropout_p) if dropout_p is not None else None\n",
    "        self.last_linear = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, groups, reduction, stride=1,\n",
    "                    downsample_kernel_size=1, downsample_padding=0):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=downsample_kernel_size, stride=stride,\n",
    "                          padding=downsample_padding, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, groups, reduction, stride,\n",
    "                            downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups, reduction))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def features(self, x):\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        return x\n",
    "\n",
    "    def logits(self, x):\n",
    "        x = self.avg_pool(x)\n",
    "        if self.dropout is not None:\n",
    "            x = self.dropout(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.last_linear(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.logits(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def initialize_pretrained_model(model, num_classes, settings):\n",
    "    assert num_classes == settings['num_classes'], \\\n",
    "        'num_classes should be {}, but is {}'.format(\n",
    "            settings['num_classes'], num_classes)\n",
    "    model.load_state_dict(model_zoo.load_url(settings['url']))\n",
    "    model.input_space = settings['input_space']\n",
    "    model.input_size = settings['input_size']\n",
    "    model.input_range = settings['input_range']\n",
    "    model.mean = settings['mean']\n",
    "    model.std = settings['std']\n",
    "\n",
    "\n",
    "def senet154(num_classes=1000, pretrained='imagenet'):\n",
    "    model = SENet(SEBottleneck, [3, 8, 36, 3], groups=64, reduction=16,\n",
    "                  dropout_p=0.2, num_classes=num_classes)\n",
    "    if pretrained is not None:\n",
    "        settings = pretrained_settings['senet154'][pretrained]\n",
    "        initialize_pretrained_model(model, num_classes, settings)\n",
    "    return model\n",
    "\n",
    "\n",
    "def se_resnet50(num_classes=1000, pretrained='imagenet'):\n",
    "    model = SENet(SEResNetBottleneck, [3, 4, 6, 3], groups=1, reduction=16,\n",
    "                  dropout_p=None, inplanes=64, input_3x3=False,\n",
    "                  downsample_kernel_size=1, downsample_padding=0,\n",
    "                  num_classes=num_classes)\n",
    "    if pretrained is not None:\n",
    "        settings = pretrained_settings['se_resnet50'][pretrained]\n",
    "        initialize_pretrained_model(model, num_classes, settings)\n",
    "    return model\n",
    "\n",
    "\n",
    "def se_resnet101(num_classes=1000, pretrained='imagenet'):\n",
    "    model = SENet(SEResNetBottleneck, [3, 4, 23, 3], groups=1, reduction=16,\n",
    "                  dropout_p=None, inplanes=64, input_3x3=False,\n",
    "                  downsample_kernel_size=1, downsample_padding=0,\n",
    "                  num_classes=num_classes)\n",
    "    if pretrained is not None:\n",
    "        settings = pretrained_settings['se_resnet101'][pretrained]\n",
    "        initialize_pretrained_model(model, num_classes, settings)\n",
    "    return model\n",
    "\n",
    "\n",
    "def se_resnet152(num_classes=1000, pretrained='imagenet'):\n",
    "    model = SENet(SEResNetBottleneck, [3, 8, 36, 3], groups=1, reduction=16,\n",
    "                  dropout_p=None, inplanes=64, input_3x3=False,\n",
    "                  downsample_kernel_size=1, downsample_padding=0,\n",
    "                  num_classes=num_classes)\n",
    "    if pretrained is not None:\n",
    "        settings = pretrained_settings['se_resnet152'][pretrained]\n",
    "        initialize_pretrained_model(model, num_classes, settings)\n",
    "    return model\n",
    "\n",
    "\n",
    "def se_resnext50_32x4d(num_classes=1000, pretrained='imagenet'):\n",
    "    model = SENet(SEResNeXtBottleneck, [3, 4, 6, 3], groups=32, reduction=16,\n",
    "                  dropout_p=None, inplanes=64, input_3x3=False,\n",
    "                  downsample_kernel_size=1, downsample_padding=0,\n",
    "                  num_classes=num_classes)\n",
    "    if pretrained is not None:\n",
    "        settings = pretrained_settings['se_resnext50_32x4d'][pretrained]\n",
    "        initialize_pretrained_model(model, num_classes, settings)\n",
    "    return model\n",
    "\n",
    "\n",
    "def se_resnext101_32x4d(num_classes=1000, pretrained='imagenet'):\n",
    "    model = SENet(SEResNeXtBottleneck, [3, 4, 23, 3], groups=32, reduction=16,\n",
    "                  dropout_p=None, inplanes=64, input_3x3=False,\n",
    "                  downsample_kernel_size=1, downsample_padding=0,\n",
    "                  num_classes=num_classes)\n",
    "    if pretrained is not None:\n",
    "        settings = pretrained_settings['se_resnext101_32x4d'][pretrained]\n",
    "        initialize_pretrained_model(model, num_classes, settings)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from shutil import copyfile\n",
    "# from os.path import isfile, join, abspath, exists, isdir, expanduser\n",
    "# from os import listdir, makedirs, getcwd, remove\n",
    "\n",
    "# cache_dir = expanduser(join('~', '.torch'))\n",
    "# if not exists(cache_dir):\n",
    "#     makedirs(cache_dir)\n",
    "# models_dir = join(cache_dir, 'models/')\n",
    "# if not exists(models_dir):\n",
    "#     makedirs(models_dir)\n",
    "    \n",
    "# copyfile(\"../input/pretrained-pytorch/densenet201-c1103571.pth\", models_dir+\"densenet201-c1103571.pth\")\n",
    "# copyfile(\"../input/pretrained-pytorch/resnet50-19c8e357.pth\", models_dir+\"resnet50-19c8e357.pth\")\n",
    "# copyfile(\"../input/pretrained-se-resnet/se_resnext101_32x4d-3b2fe3d8.pth\", models_dir+\"se_resnext101_32x4d-3b2fe3d8.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls ~/.torch/models  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SENet(\n",
       "  (layer0): Sequential(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu1): ReLU(inplace=True)\n",
       "    (pool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  )\n",
       "  (layer1): Sequential(\n",
       "    (0): SEResNeXtBottleneck(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): SEResNeXtBottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (2): SEResNeXtBottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): SEResNeXtBottleneck(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): SEResNeXtBottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (2): SEResNeXtBottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (3): SEResNeXtBottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): SEResNeXtBottleneck(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): SEResNeXtBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (2): SEResNeXtBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (3): SEResNeXtBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (4): SEResNeXtBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (5): SEResNeXtBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (6): SEResNeXtBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (7): SEResNeXtBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (8): SEResNeXtBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (9): SEResNeXtBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (10): SEResNeXtBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (11): SEResNeXtBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (12): SEResNeXtBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (13): SEResNeXtBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (14): SEResNeXtBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (15): SEResNeXtBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (16): SEResNeXtBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (17): SEResNeXtBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (18): SEResNeXtBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (19): SEResNeXtBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (20): SEResNeXtBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (21): SEResNeXtBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (22): SEResNeXtBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): SEResNeXtBottleneck(\n",
       "      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): SEResNeXtBottleneck(\n",
       "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (2): SEResNeXtBottleneck(\n",
       "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avg_pool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "  (last_linear): Linear(in_features=2048, out_features=1103, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Ensemble(nn.Module):\n",
    "    def __init__(self, modelA, modelB,input_length,output_length):\n",
    "        super(Ensemble, self).__init__()\n",
    "        self.modelA = modelA\n",
    "        self.modelB = modelB\n",
    "        self.classifier = nn.Linear(input_length, output_length)\n",
    "        \n",
    "    def forward(self, xin,xin2):\n",
    "        x1 = self.modelA(xin)\n",
    "        x2 = self.modelB(xin2)\n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "        x = self.classifier(F.relu(x))\n",
    "        return x\n",
    "\n",
    "    \n",
    "# efficientNet = EfficientNet.from_name('efficientnet-b7') \n",
    "# efficientNet._fc = nn.Linear(in_features=1280, out_features=lable_length)\n",
    "\n",
    "\n",
    "seresnext_model = se_resnext101_32x4d(pretrained='imagenet')\n",
    "seresnext_model.last_linear = nn.Linear(in_features=2048, out_features=lable_length, bias=True)\n",
    "\n",
    "#densenet_model = models.densenet201(pretrained=True)\n",
    "#densenet_model.load_state_dict(torch.load( models_dir+\"densenet201-c1103571.pth\"))\n",
    "#densenet_model.classifier= nn.Linear(in_features=1920,out_features=lable_length)\n",
    "\n",
    "#efficientNet = EfficientNet(width_coeff=2.0, depth_coeff=3.1,drop_connect_rate=0.5,num_classes = lable_length)\n",
    "\n",
    "resnet_model = models.resnet50(pretrained=True)\n",
    "#resnet_model.load_state_dict(torch.load(\"../models/resnet50.pth\"))\n",
    "resnet_model.fc= nn.Linear(in_features=2048, out_features=lable_length)\n",
    "\n",
    "#model = Ensemble(seresnext_model, resnet_model,lable_length*2,lable_length)\n",
    "#model.to(device)\n",
    "\n",
    "\n",
    "model = seresnext_model\n",
    "#model = nn.DataParallel(model)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    # device_ids has a default : all\n",
    "    model = torch.nn.DataParallel(model, device_ids=[0,1]) \n",
    "model.to(device)\n",
    "\n",
    "#model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch,fnum,dloader):\n",
    "    model.train()\n",
    "    for step, (x,y) in enumerate(dloader):\n",
    "        data = Variable(x).cuda(async=True)   # batch x\n",
    "        #data2 = Variable(x2).cuda()\n",
    "        target = Variable(y).cuda(async=True)   # batch y\n",
    "        #print(data.size())\n",
    "        #print(data2.size())\n",
    "        #print(target.size())\n",
    "        #output = model(data,data2)\n",
    "        #print(data.size())\n",
    "        output = model(data)\n",
    "        #print(\"out\",output.size())\n",
    "        #print(\"target\",target.size())\n",
    "\n",
    "        loss = loss_func(output, target.float())   # cross entropy loss\n",
    "        optimizer.zero_grad()           # clear gradients for this training step\n",
    "        loss.backward()                 # backpropagation, compute gradients\n",
    "        optimizer.step()                # apply gradients\n",
    "        if step==0:\n",
    "            start = time.time()\n",
    "            #break\n",
    "            ti = 0\n",
    "        elif step==100:\n",
    "            ti = time.time()-start #total time = ti*(length/100)\n",
    "            #print(ti)\n",
    "            ti = ti*(len(dloader)/100)\n",
    "        if step % 100 == 0:\n",
    "            second = ti*(((len(dloader)-step)/len(dloader)))#*(5-epoch)*(4-fnum)\n",
    "            print('Train Fold:{}/4  Ep: {}/5 [{}/{} ({:.0f}%)]\\t Loss: {:.6f}\\t Remain : {} '.\n",
    "                     format(fnum+1,\n",
    "                            epoch+1, \n",
    "                            step * len(data), \n",
    "                            len(dloader.dataset),\n",
    "                            100.*step/len(dloader), \n",
    "                            loss.data.item(),\n",
    "                            datetime.timedelta(seconds = int(second))))\n",
    "        #data.cpu()\n",
    "        #data2.cpu()\n",
    "        #target.cpu()\n",
    "        torch.cuda.empty_cache()\n",
    "    print(\"Finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(dloader):\n",
    "    model.eval()\n",
    "    los = []\n",
    "    for step, (x, y) in enumerate(dloader):\n",
    "        data = Variable(x).cuda(async=True)\n",
    "        #data2 = Variable(x2).cuda()\n",
    "        target = Variable(y).cuda(async=True)\n",
    "        \n",
    "        #output = model(data,data2)\n",
    "        with torch.no_grad():\n",
    "            output = model(data)\n",
    "        \n",
    "        loss = loss_func(output, target.float())\n",
    "        los.append(loss.item())\n",
    "        \n",
    "        \n",
    "        if step %100 == 0:\n",
    "            print('[{}/{} ({:.1f}%)]'.format(step * len(data), \n",
    "                                        len(dloader.dataset),\n",
    "                                        100.*step/len(dloader)))\n",
    "        #data.cpu()\n",
    "        #data2.cpu()\n",
    "        #arget.cpu()\n",
    "        torch.cuda.empty_cache()\n",
    "    los = np.array(los)\n",
    "    avg_val_loss = los.sum()/len(los)\n",
    "    print(\"Avg val loss:{}\".format(avg_val_loss))\n",
    "    #return ans,out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def forward(self, input, target):\n",
    "        # Inspired by the implementation of binary_cross_entropy_with_logits\n",
    "        if not (target.size() == input.size()):\n",
    "            raise ValueError(\"Target size ({}) must be the same as input size ({})\".format(target.size(), input.size()))\n",
    "\n",
    "        max_val = (-input).clamp(min=0)\n",
    "        loss = input - input * target + max_val + ((-max_val).exp() + (-input - max_val).exp()).log()\n",
    "\n",
    "        # This formula gives us the log sigmoid of 1-p if y is 0 and of p if y is 1\n",
    "        invprobs = F.logsigmoid(-input * (target * 2 - 1))\n",
    "        loss = (invprobs * self.gamma).exp() * loss\n",
    "        \n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = KFold(n_splits = 4, random_state = 10)\n",
    "for fold_num, (trn_idx, val_idx) in enumerate(fold.split(datafilter)):\n",
    "    Ftrain_dataloader = datafilter[trn_idx, :]\n",
    "    Fval_dataloader = datafilter[val_idx, :]\n",
    "    #print(trn_idx,val_idx)\n",
    "\n",
    "    val_dataloader = DataLoader(dataset_h5(\"all_data_109237v1.h5\", data_transforms2, val_idx),batch_size=100, shuffle=False,num_workers=2, pin_memory=True)\n",
    "    train_dataloader = DataLoader(dataset_h5(\"all_data_109237v1.h5\", data_transforms2, trn_idx),batch_size=100, shuffle=True,num_workers=2, pin_memory=True)\n",
    "    for epoch in range(5):\n",
    "        ###########################################\n",
    "        if epoch==0:\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=0.0001/(2**epoch))\n",
    "        else:\n",
    "            optimizer = torch.optim.SGD(model.parameters(), lr=0.00008,momentum=0.9, weight_decay=1e-4)\n",
    "        #optimizer = torch.optim.Adam(model.parameters(), lr=0.00002/(2**epoch))\n",
    "        #optimizer = torch.optim.SGD(net.parameters(), lr=args.lr, momentum=0.9, weight_decay=1e-4)\n",
    "        loss_func = FocalLoss(0.4)\n",
    "        #loss_func = torch.nn.MSELoss()\n",
    "        ###########################################\n",
    "        train(epoch,fold_num,train_dataloader) \n",
    "        val(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov 22 07:41:53 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.56       Driver Version: 418.56       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:01:00.0  On |                  N/A |\n",
      "| 66%   83C    P2    80W / 250W |   1813MiB / 11175MiB |      2%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:02:00.0 Off |                  N/A |\n",
      "| 52%   75C    P2    78W / 250W |    619MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0      1137      G   /usr/lib/xorg/Xorg                            80MiB |\n",
      "|    0      2214      G   /opt/teamviewer/tv_bin/TeamViewer              2MiB |\n",
      "|    0     12945      G   ...uest-channel-token=14083820793621432878    85MiB |\n",
      "|    0     22250      G   /usr/lib/xorg/Xorg                           172MiB |\n",
      "|    0     22494      G                                                  4MiB |\n",
      "|    0     22924      G   compiz                                       140MiB |\n",
      "|    0     23722      G   /usr/lib/firefox/firefox                       2MiB |\n",
      "|    0     25016      C   /home/user1/pytorch_g/bin/python            1189MiB |\n",
      "|    0     31156      G   ...uest-channel-token=12496746042476819744    88MiB |\n",
      "|    1     25016      C   /home/user1/pytorch_g/bin/python             607MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user1/pytorch_g/lib/python3.5/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DataParallel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/user1/pytorch_g/lib/python3.5/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type SENet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/user1/pytorch_g/lib/python3.5/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/user1/pytorch_g/lib/python3.5/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Conv2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/user1/pytorch_g/lib/python3.5/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BatchNorm2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/user1/pytorch_g/lib/python3.5/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ReLU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/user1/pytorch_g/lib/python3.5/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type MaxPool2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/user1/pytorch_g/lib/python3.5/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type SEResNeXtBottleneck. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/user1/pytorch_g/lib/python3.5/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type SEModule. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/user1/pytorch_g/lib/python3.5/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type AdaptiveAvgPool2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/user1/pytorch_g/lib/python3.5/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sigmoid. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/user1/pytorch_g/lib/python3.5/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type AvgPool2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/user1/pytorch_g/lib/python3.5/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model, 'net.pkl')\n",
    "#model = torch.load('net.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('ag_net_4k_5e.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findPre(output,gate):\n",
    "    a = ''\n",
    "    output = np.array(output)\n",
    "    m = np.max(output)\n",
    "\n",
    "    for i in range(len(output)):\n",
    "        #s = np.where(v[i] > 0.95, 1, 0)\n",
    "        if output[i]>gate:\n",
    "            #print(output[i])\n",
    "            a = a + format(i)+' '\n",
    "            \n",
    "    #print(a)\n",
    "    return a\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,dloader,threshold):\n",
    "    model = model.eval().cuda()\n",
    "    #lengthD = len(dloader.dataset)\n",
    "    ans = []\n",
    "    out = []\n",
    "    for step, (x,x2, y) in enumerate(dloader):\n",
    "        data = Variable(x).cuda()\n",
    "        #data2 = Variable(x2).cuda()\n",
    "        #data = Variable(x)\n",
    "        target = y\n",
    "        #output = model(data,data2)\n",
    "        with torch.no_grad():\n",
    "            output = model(data).detach()\n",
    "        \n",
    "        #data.cpu()   # batch x\n",
    "        #data2.cpu()   # batch x\n",
    "        #target.cpu()   # batch y\n",
    "        #torch.cuda.empty_cache()\n",
    "        \n",
    "        v = output.cpu()\n",
    "        v = torch.sigmoid(v)\n",
    "        \n",
    "        v = torch.sigmoid(v)\n",
    "        v = np.array(v)\n",
    "        v = preprocessing.minmax_scale(v, feature_range=(0,1),axis=1)\n",
    "        for i in range(len(v)):\n",
    "            out.append(np.where(v[i] > threshold, 1, 0))\n",
    "            s = findPre(v[i],threshold)\n",
    "            ans.append([target[i],s])\n",
    "        if step %10 == 0:\n",
    "            print('[{}/{} ({:.1f}%)]'.format(step * len(data), \n",
    "                                        len(dloader.dataset),\n",
    "                                        100.*step/len(dloader)))\n",
    "            \n",
    "        data.cpu()\n",
    "        #data2.detach()\n",
    "        #target.detach()\n",
    "        torch.cuda.empty_cache()\n",
    "    print(\"Finish\")\n",
    "    return ans,out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "def makeScore(pre,ans):\n",
    "    pre = np.array(pre)\n",
    "    va = fbeta_score(y_pred=pre, y_true=ans, beta=2, average=\"samples\")\n",
    "    print(\"Score : {:.5f}\".format(va))\n",
    "    return va\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findThreshold():\n",
    "    score = []\n",
    "    candidates = np.arange(0, 1.0, 0.01)\n",
    "    for th in candidates:\n",
    "        print(\"Threshold : {:.2f}\".format(th))\n",
    "        _,pre = test(model = model,dloader = score_dataloader,threshold = th)\n",
    "        #return pre\n",
    "        score.append(makeScore(np.array(pre),np.array(train_a[:1000,1].tolist())))\n",
    "        print(\"=============================\")\n",
    "    pm = np.array(score).argmax()\n",
    "    best_th, best_score = candidates[pm], score[pm]\n",
    "    return best_th, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold : 0.00\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.01485\n",
      "=============================\n",
      "Threshold : 0.01\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.26739\n",
      "=============================\n",
      "Threshold : 0.02\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.35817\n",
      "=============================\n",
      "Threshold : 0.03\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.42349\n",
      "=============================\n",
      "Threshold : 0.04\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.47302\n",
      "=============================\n",
      "Threshold : 0.05\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.50969\n",
      "=============================\n",
      "Threshold : 0.06\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.54215\n",
      "=============================\n",
      "Threshold : 0.07\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.56198\n",
      "=============================\n",
      "Threshold : 0.08\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.58430\n",
      "=============================\n",
      "Threshold : 0.09\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.60071\n",
      "=============================\n",
      "Threshold : 0.10\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.61466\n",
      "=============================\n",
      "Threshold : 0.11\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.62545\n",
      "=============================\n",
      "Threshold : 0.12\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.63513\n",
      "=============================\n",
      "Threshold : 0.13\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.64105\n",
      "=============================\n",
      "Threshold : 0.14\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.65070\n",
      "=============================\n",
      "Threshold : 0.15\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.65495\n",
      "=============================\n",
      "Threshold : 0.16\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.65725\n",
      "=============================\n",
      "Threshold : 0.17\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.66051\n",
      "=============================\n",
      "Threshold : 0.18\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.66598\n",
      "=============================\n",
      "Threshold : 0.19\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.66613\n",
      "=============================\n",
      "Threshold : 0.20\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.66525\n",
      "=============================\n",
      "Threshold : 0.21\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.66853\n",
      "=============================\n",
      "Threshold : 0.22\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.67215\n",
      "=============================\n",
      "Threshold : 0.23\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.67657\n",
      "=============================\n",
      "Threshold : 0.24\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.67874\n",
      "=============================\n",
      "Threshold : 0.25\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.67900\n",
      "=============================\n",
      "Threshold : 0.26\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.67547\n",
      "=============================\n",
      "Threshold : 0.27\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.67110\n",
      "=============================\n",
      "Threshold : 0.28\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.67388\n",
      "=============================\n",
      "Threshold : 0.29\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.67017\n",
      "=============================\n",
      "Threshold : 0.30\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.67153\n",
      "=============================\n",
      "Threshold : 0.31\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.66651\n",
      "=============================\n",
      "Threshold : 0.32\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.66907\n",
      "=============================\n",
      "Threshold : 0.33\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.66548\n",
      "=============================\n",
      "Threshold : 0.34\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.66851\n",
      "=============================\n",
      "Threshold : 0.35\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.66011\n",
      "=============================\n",
      "Threshold : 0.36\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.66087\n",
      "=============================\n",
      "Threshold : 0.37\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.66022\n",
      "=============================\n",
      "Threshold : 0.38\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.65694\n",
      "=============================\n",
      "Threshold : 0.39\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.65757\n",
      "=============================\n",
      "Threshold : 0.40\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.65588\n",
      "=============================\n",
      "Threshold : 0.41\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.64974\n",
      "=============================\n",
      "Threshold : 0.42\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.64063\n",
      "=============================\n",
      "Threshold : 0.43\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.63137\n",
      "=============================\n",
      "Threshold : 0.44\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.63948\n",
      "=============================\n",
      "Threshold : 0.45\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.62907\n",
      "=============================\n",
      "Threshold : 0.46\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.63170\n",
      "=============================\n",
      "Threshold : 0.47\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.62294\n",
      "=============================\n",
      "Threshold : 0.48\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.61683\n",
      "=============================\n",
      "Threshold : 0.49\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.62174\n",
      "=============================\n",
      "Threshold : 0.50\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.61883\n",
      "=============================\n",
      "Threshold : 0.51\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.61242\n",
      "=============================\n",
      "Threshold : 0.52\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.60240\n",
      "=============================\n",
      "Threshold : 0.53\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.59748\n",
      "=============================\n",
      "Threshold : 0.54\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.59112\n",
      "=============================\n",
      "Threshold : 0.55\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.59745\n",
      "=============================\n",
      "Threshold : 0.56\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.59848\n",
      "=============================\n",
      "Threshold : 0.57\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.59287\n",
      "=============================\n",
      "Threshold : 0.58\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.59069\n",
      "=============================\n",
      "Threshold : 0.59\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.58251\n",
      "=============================\n",
      "Threshold : 0.60\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.58646\n",
      "=============================\n",
      "Threshold : 0.61\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.57715\n",
      "=============================\n",
      "Threshold : 0.62\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.56666\n",
      "=============================\n",
      "Threshold : 0.63\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.56625\n",
      "=============================\n",
      "Threshold : 0.64\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.56532\n",
      "=============================\n",
      "Threshold : 0.65\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.55639\n",
      "=============================\n",
      "Threshold : 0.66\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.56219\n",
      "=============================\n",
      "Threshold : 0.67\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.56167\n",
      "=============================\n",
      "Threshold : 0.68\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.54543\n",
      "=============================\n",
      "Threshold : 0.69\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.54571\n",
      "=============================\n",
      "Threshold : 0.70\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.53811\n",
      "=============================\n",
      "Threshold : 0.71\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.53989\n",
      "=============================\n",
      "Threshold : 0.72\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.53536\n",
      "=============================\n",
      "Threshold : 0.73\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.52467\n",
      "=============================\n",
      "Threshold : 0.74\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.51751\n",
      "=============================\n",
      "Threshold : 0.75\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.52003\n",
      "=============================\n",
      "Threshold : 0.76\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.51937\n",
      "=============================\n",
      "Threshold : 0.77\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.50724\n",
      "=============================\n",
      "Threshold : 0.78\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.50691\n",
      "=============================\n",
      "Threshold : 0.79\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.49654\n",
      "=============================\n",
      "Threshold : 0.80\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.50539\n",
      "=============================\n",
      "Threshold : 0.81\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.49205\n",
      "=============================\n",
      "Threshold : 0.82\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.48559\n",
      "=============================\n",
      "Threshold : 0.83\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.47974\n",
      "=============================\n",
      "Threshold : 0.84\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.47620\n",
      "=============================\n",
      "Threshold : 0.85\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.46767\n",
      "=============================\n",
      "Threshold : 0.86\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.46845\n",
      "=============================\n",
      "Threshold : 0.87\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.46134\n",
      "=============================\n",
      "Threshold : 0.88\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.45142\n",
      "=============================\n",
      "Threshold : 0.89\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.44587\n",
      "=============================\n",
      "Threshold : 0.90\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.43968\n",
      "=============================\n",
      "Threshold : 0.91\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.43281\n",
      "=============================\n",
      "Threshold : 0.92\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.43084\n",
      "=============================\n",
      "Threshold : 0.93\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.42357\n",
      "=============================\n",
      "Threshold : 0.94\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.41901\n",
      "=============================\n",
      "Threshold : 0.95\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.40715\n",
      "=============================\n",
      "Threshold : 0.96\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.39934\n",
      "=============================\n",
      "Threshold : 0.97\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.39459\n",
      "=============================\n",
      "Threshold : 0.98\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.38638\n",
      "=============================\n",
      "Threshold : 0.99\n",
      "[0/1000 (0.0%)]\n",
      "Finish\n",
      "Score : 0.36602\n",
      "=============================\n",
      "Best Threshold : 0.25\n",
      "Best Score : 0.67900\n"
     ]
    }
   ],
   "source": [
    "bt, bs = findThreshold()\n",
    "print(\"Best Threshold : {:.2f}\".format(bt))\n",
    "print(\"Best Score : {:.5f}\".format(bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov 22 11:52:41 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.56       Driver Version: 418.56       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:01:00.0  On |                  N/A |\n",
      "| 55%   76C    P2    81W / 250W |   2007MiB / 11175MiB |      5%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:02:00.0 Off |                  N/A |\n",
      "| 42%   69C    P2    76W / 250W |    621MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0      1137      G   /usr/lib/xorg/Xorg                            80MiB |\n",
      "|    0      2214      G   /opt/teamviewer/tv_bin/TeamViewer              2MiB |\n",
      "|    0     12945      G   ...uest-channel-token=14083820793621432878    85MiB |\n",
      "|    0     22250      G   /usr/lib/xorg/Xorg                           172MiB |\n",
      "|    0     22494      G                                                  4MiB |\n",
      "|    0     22924      G   compiz                                       140MiB |\n",
      "|    0     23722      G   /usr/lib/firefox/firefox                       2MiB |\n",
      "|    0     25016      C   /home/user1/pytorch_g/bin/python            1381MiB |\n",
      "|    0     31156      G   ...uest-channel-token=12496746042476819744    88MiB |\n",
      "|    1     25016      C   /home/user1/pytorch_g/bin/python             607MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataFrame' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-63d2bacc5a25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msub\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'DataFrame' object is not callable"
     ]
    }
   ],
   "source": [
    "sub,_ = test(model = model,dloader = test_dataloader,threshold = bt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub =  pd.DataFrame(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = sub.rename(index=str, columns={0: \"id\", 1: \"attribute_ids\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
