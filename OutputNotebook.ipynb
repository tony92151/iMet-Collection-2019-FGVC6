{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## pytorch_seresnext101-32x4d+kfold+focal loss v3.0\n",
      "\n",
      "\n",
      "* fold = 4\n",
      "* epoch = 3\n",
      "* \u03b3=0.4"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!nvidia-smi"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Mon Nov 25 05:19:14 2019       \r\n",
        "+-----------------------------------------------------------------------------+\r\n",
        "| NVIDIA-SMI 410.104      Driver Version: 410.104      CUDA Version: 10.0     |\r\n",
        "|-------------------------------+----------------------+----------------------+\r\n",
        "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
        "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
        "|===============================+======================+======================|\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "|   0  Tesla V100-PCIE...  Off  | 00000000:1B:00.0 Off |                    0 |\r\n",
        "| N/A   35C    P0    41W / 250W |      0MiB / 32480MiB |      0%      Default |\r\n",
        "+-------------------------------+----------------------+----------------------+\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "|   1  Tesla V100-PCIE...  Off  | 00000000:1C:00.0 Off |                    0 |\r\n",
        "| N/A   34C    P0    40W / 250W |      0MiB / 32480MiB |      0%      Default |\r\n",
        "+-------------------------------+----------------------+----------------------+\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "|   2  Tesla V100-PCIE...  Off  | 00000000:1E:00.0 Off |                    0 |\r\n",
        "| N/A   36C    P0    35W / 250W |      0MiB / 32480MiB |      0%      Default |\r\n",
        "+-------------------------------+----------------------+----------------------+\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "|   3  Tesla V100-PCIE...  Off  | 00000000:DE:00.0 Off |                    0 |\r\n",
        "| N/A   33C    P0    28W / 250W |      0MiB / 32480MiB |      0%      Default |\r\n",
        "+-------------------------------+----------------------+----------------------+\r\n",
        "                                                                               \r\n",
        "+-----------------------------------------------------------------------------+\r\n",
        "| Processes:                                                       GPU Memory |\r\n",
        "|  GPU       PID   Type   Process name                             Usage      |\r\n",
        "|=============================================================================|\r\n",
        "|  No running processes found                                                 |\r\n",
        "+-----------------------------------------------------------------------------+\r\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import torch\n",
      "from torch import nn, optim\n",
      "import torch.nn.functional as F\n",
      "import matplotlib.pyplot as plt\n",
      "import sys\n",
      "import time\n",
      "import numpy as np\n",
      "import math\n",
      "import pandas as pd\n",
      "from PIL import Image, ImageOps, ImageFilter\n",
      "from datetime import datetime\n",
      "from torch.autograd import Variable\n",
      "from torch.utils.data import Dataset, DataLoader\n",
      "import torchvision.transforms as transforms\n",
      "from torchvision import datasets, models, transforms\n",
      "import random\n",
      "import datetime\n",
      "import os\n",
      "\n",
      "import cv2  \n",
      "from sklearn import preprocessing \n",
      "from sklearn.model_selection import KFold\n",
      "import h5py\n",
      "\n",
      "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
      "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
      "print(device)"
     ],
     "language": "python",
     "metadata": {
      "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
      "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "cuda:0\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from albumentations import (\n",
      "    HorizontalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
      "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
      "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, RandomBrightnessContrast, IAAPiecewiseAffine,\n",
      "    IAASharpen, IAAEmboss, Flip, OneOf, Compose,RandomContrast,RandomBrightness,Resize\n",
      ")\n",
      "import albumentations"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from torch.utils.data import DataLoader\n",
      "from prefetch_generator import BackgroundGenerator\n",
      "\n",
      "class DataLoaderX(DataLoader):\n",
      "\n",
      "    def __iter__(self):\n",
      "        return BackgroundGenerator(super().__iter__())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# os.chdir(\"../input/pretrained_PyTorch/\")\n",
      "path = os.getcwd()\n",
      "print(path)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/root/notebooks/imet/iMet-Collection-2019-FGVC6\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train = pd.read_csv(path+\"/train.csv\")\n",
      "lable = pd.read_csv(path+\"/labels.csv\")\n",
      "test = pd.read_csv(path+\"/sample_submission.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lable_length = len(lable)\n",
      "train_length = len(train)\n",
      "test_length = len(test)\n",
      "print(train_length)\n",
      "print(lable_length)\n",
      "print(test_length)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "109237\n",
        "1103\n",
        "38801\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(np.array(lable)[397])\n",
      "print(np.array(lable)[398])\n",
      "c_length = len(np.array(lable)[:398])\n",
      "t_length = len(np.array(lable)[398:])\n",
      "print(c_length)\n",
      "print(t_length)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[397 'culture::zurich']\n",
        "[398 'tag::abbies']\n",
        "398\n",
        "705\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#np.array(test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# test.head"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#np.array(train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def augment(p=.5):\n",
      "    return Compose([\n",
      "        HorizontalFlip(p=0.5),\n",
      "        OneOf([\n",
      "            RandomBrightness(0.1, p=1),\n",
      "            RandomContrast(0.1, p=1),\n",
      "        ], p=0.3),\n",
      "        ShiftScaleRotate(shift_limit=0.1, scale_limit=0.0, rotate_limit=15, p=0.3),\n",
      "        IAAAdditiveGaussianNoise(p=0.3),\n",
      "        Resize(100,100)\n",
      "    ], p=p)\n",
      "def strong_aug(p=.5):\n",
      "    return Compose([\n",
      "        RandomRotate90(),\n",
      "        Flip(),\n",
      "        Transpose(),\n",
      "        OneOf([\n",
      "            IAAAdditiveGaussianNoise(),\n",
      "            GaussNoise(),\n",
      "        ], p=0.2),\n",
      "        OneOf([\n",
      "            MotionBlur(p=.2),\n",
      "            MedianBlur(blur_limit=3, p=0.1),\n",
      "            Blur(blur_limit=3, p=0.1),\n",
      "        ], p=0.2),\n",
      "        ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=45, p=0.2),\n",
      "        OneOf([\n",
      "            OpticalDistortion(p=0.3),\n",
      "            GridDistortion(p=.1),\n",
      "            IAAPiecewiseAffine(p=0.3),\n",
      "        ], p=0.2),\n",
      "        OneOf([\n",
      "            CLAHE(clip_limit=2),\n",
      "            IAASharpen(),\n",
      "            IAAEmboss(),\n",
      "            RandomBrightnessContrast(),            \n",
      "        ], p=0.3),\n",
      "        HueSaturationValue(p=0.3),\n",
      "    ], p=p)\n",
      "\n",
      "aug = augment(0.2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def creatData(train,lable_length):\n",
      "    train = np.array(train)\n",
      "    trainA_data = []\n",
      "    lab_data = []\n",
      "    #trainC_data = []\n",
      "    #trainT_data = []\n",
      "    for t in range(train_length):\n",
      "        v = np.zeros(lable_length)\n",
      "        #print(train[t,1])\n",
      "        lab = []\n",
      "        for s in train[t,1].split(\" \"):\n",
      "            #print(s)\n",
      "            v[int(s)] = 1\n",
      "            lab.append(int(s))\n",
      "            \n",
      "#         img = Image.open(path+\"/train/\"+format(train[t,0])+'.png')  # PIL image\n",
      "#         img = cv2.cvtColor(np.asarray(img),cv2.COLOR_RGB2BGR)\n",
      "#         img = aug(image = img)['image']\n",
      "#         #openCV to PIL\n",
      "#         img = Image.fromarray(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\n",
      "        \n",
      "        trainA_data.append([train[t,0],v])\n",
      "        lab_data.append([train[t,0],np.array(lab)])\n",
      "\n",
      "        #trainC_data.append([train[t,0],v[:c_length]])\n",
      "        #trainT_data.append([train[t,0],v[c_length:]])\n",
      "    return np.array(trainA_data),np.array(lab_data)\n",
      "    #return np.array(trainA_data)#,np.array(trainC_data),np.array(trainT_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_a,train_lab = creatData(train,lable_length)\n",
      "#train_a,train_c,train_t = creatData(train,lable_length)\n",
      "#train_t.shape()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_lab[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "array(['1000483014d91860', array([147, 616, 813])], dtype=object)"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Remove the item that only have one feature (not work well)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def dfilter(data,th):\n",
      "    dfilter = []\n",
      "    for i in range(len(data)):\n",
      "        if train_a[i][1].sum()>th:\n",
      "            dfilter.append(train_a[i])\n",
      "    return np.array(dfilter)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "datafilter = dfilter(train_a,1) # remain feature great then 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(\"amount of image before: {}\".format(len(train_a)))\n",
      "\n",
      "print(\"amount of image after: {}\".format(len(datafilter)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "amount of image before: 109237\n",
        "amount of image after: 104913\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# not use\n",
      "datafilter = train_a"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "datafilter[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "array(['1000483014d91860', array([0., 0., 0., ..., 0., 0., 0.])],\n",
        "      dtype=object)"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "image_resize = 200\n",
      "data_transforms2 = transforms.Compose([\n",
      "    transforms.Resize((image_resize,image_resize)),\n",
      "    #transforms.RandomResizedCrop(250),\n",
      "    #transforms.RandomHorizontalFlip(),\n",
      "    transforms.ToTensor(),\n",
      "    transforms.Normalize(\n",
      "            [0.485, 0.456, 0.406], \n",
      "            [0.229, 0.224, 0.225])\n",
      "    ])\n",
      "\n",
      "\n",
      "data_transforms = transforms.Compose([\n",
      "    transforms.Resize((image_resize,image_resize)),\n",
      "    #transforms.RandomResizedCrop(250),\n",
      "    #transforms.RandomHorizontalFlip(),\n",
      "    transforms.ToTensor(),\n",
      "    #transforms.Normalize(\n",
      "    #        [0.485, 0.456, 0.406], \n",
      "    #        [0.229, 0.224, 0.225])\n",
      "    ])\n",
      "\n",
      "train_transformer = transforms.Compose([\n",
      "    transforms.Resize((128,128)),              # resize the image to \n",
      "    #transforms.RandomHorizontalFlip(),  # randomly flip image horizontally\n",
      "    #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
      "    transforms.ToTensor(),           # transform it into a PyTorch Tensor\n",
      "    #transforms.Normalize(mean = (0.5, 0.5, 0.5), std = (0.5, 0.5, 0.5))\n",
      "])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# top_transforms = transforms.Compose([\n",
      "#     augment()['image'],\n",
      "#     transforms.Resize((image_resize,image_resize)),\n",
      "#     HorizontalFlip(p=0.5),\n",
      "#     OneOf([\n",
      "#         RandomBrightness(0.1, p=1),\n",
      "#         RandomContrast(0.1, p=1),\n",
      "#     ], p=0.3),\n",
      "#     ShiftScaleRotate(shift_limit=0.1, scale_limit=0.0, rotate_limit=15, p=0.3),\n",
      "#     IAAAdditiveGaussianNoise(p=0.3),\n",
      "#     #transforms.RandomResizedCrop(250),\n",
      "#     #transforms.RandomHorizontalFlip(),\n",
      "#     transforms.ToTensor(),\n",
      "#     transforms.Normalize(\n",
      "#             [0.485, 0.456, 0.406], \n",
      "#             [0.229, 0.224, 0.225])\n",
      "#     ])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load2mem(in_file,transform):\n",
      "    print(\"Load data from .h5 file...\")\n",
      "    t = time.time()\n",
      "    prefile = h5py.File(in_file, 'r')\n",
      "    preloadimg = []\n",
      "    preloadleb = prefile['train_labels'][:,:]\n",
      "    #print(prefile['train_img'][0,:,:])\n",
      "    for i in range(len(preloadleb)):\n",
      "        img = Image.fromarray(prefile['train_img'][i,:,:])\n",
      "        preloadimg.append(img)\n",
      "    #preloadimg = prefile['train_img'][:,:,:]\n",
      "    \n",
      "    print(\"Done\")\n",
      "    print(\"Take\",datetime.timedelta(seconds = int(time.time()-t)),\"seconds\")\n",
      "    return preloadimg, preloadleb\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#a,b = load2mem(\"all_data_109237v1.h5\", data_transforms2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class dataset_h5(torch.utils.data.Dataset):\n",
      "    def __init__(self, in_file, transform, kdata):\n",
      "        super(dataset_h5, self).__init__()\n",
      "\n",
      "        self.file = h5py.File(in_file, 'r')\n",
      "        self.n_images = len(kdata)\n",
      "        self.kdata = kdata\n",
      "        self.transform = transform\n",
      "        print(\"Load data from .h5 file...\")\n",
      "        t = time.time()\n",
      "        self.preloadimg = self.file['train_img'][self.kdata,:,:]\n",
      "        self.preloadleb = self.file['train_labels'][self.kdata,:]\n",
      "        \n",
      "        #self.preloadimg = [a[i] for i in self.kdata]\n",
      "        #self.preloadleb = b[self.kdata]\n",
      "        print(\"Take\",datetime.timedelta(seconds = int(time.time()-t)),\"seconds\")\n",
      "\n",
      "    def __getitem__(self, index):\n",
      "        \n",
      "        input_img = Image.fromarray(self.preloadimg[index])\n",
      "        #input_img = self.preloadimg[index]\n",
      "        \n",
      "        input_img = self.transform(input_img)\n",
      "        \n",
      "        input_lab = self.preloadleb[index]\n",
      "        return input_img,input_lab\n",
      "\n",
      "    def __len__(self):\n",
      "        return self.n_images"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class trainDataset(Dataset):\n",
      "    def __init__(self, train_lib, transform,transform2):\n",
      "        self.filenames = train_lib[:,0]\n",
      "        self.labels = train_lib[:,1]\n",
      "        self.transform = transform\n",
      "        self.transform2 = transform2\n",
      "        #self.new_feature = \n",
      "\n",
      "    def __len__(self):\n",
      "        return len(self.filenames)\n",
      "\n",
      "    def __getitem__(self, idx):\n",
      "        img = Image.open(path+\"/train/\"+format(self.filenames[idx])+'.png')  # PIL image\n",
      "        \n",
      "        #PIL to openCV\n",
      "        imgv = cv2.cvtColor(np.asarray(img),cv2.COLOR_RGB2BGR)\n",
      "        imgv = aug(image = imgv)['image']\n",
      "        #openCV to PIL\n",
      "        img = Image.fromarray(cv2.cvtColor(imgv,cv2.COLOR_BGR2RGB))\n",
      "        \n",
      "        #image= image.filter(ImageFilter.EDGE_ENHANCE)\n",
      "        #image2 = image.filter(ImageFilter.FIND_EDGES)\n",
      "        image = self.transform(img)\n",
      "        image2 = self.transform2(img)\n",
      "        #return image, self.labels[idx]\n",
      "        return image,image2, self.labels[idx]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class testDataset(Dataset):\n",
      "    def __init__(self, test_lib, transform,transform2):\n",
      "        test_lib = np.array(test_lib)\n",
      "        self.filenames = test_lib[:,0]\n",
      "        #self.labels = test_lib[:,1]\n",
      "        self.transform = transform\n",
      "        self.transform2 = transform2\n",
      "\n",
      "    def __len__(self):\n",
      "        return len(self.filenames)\n",
      "\n",
      "    def __getitem__(self, idx):\n",
      "        img = Image.open(path+\"/test/\"+format(self.filenames[idx])+'.png')  # PIL image\n",
      "        #image= image.filter(ImageFilter.EDGE_ENHANCE)\n",
      "        #image2 = image.filter(ImageFilter.FIND_EDGES)\n",
      "        image = self.transform(img)\n",
      "        image2 = self.transform2(img)\n",
      "        #return image,self.filenames[idx]\n",
      "        return image,image2,self.filenames[idx]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#trainA_dataloader = DataLoader(dataset_h5(\"all_data_109237v1.h5\", data_transforms2),batch_size=128, shuffle=True,num_workers=2, pin_memory=True)\n",
      "#trainC_dataloader = DataLoader(trainDataset(train_c, data_transforms,data_transforms2),batch_size=32, shuffle=True,num_workers=2, pin_memory=True)\n",
      "#trainT_dataloader = DataLoader(trainDataset(train_t, data_transforms,data_transforms2),batch_size=32, shuffle=True,num_workers=2, pin_memory=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "score_dataloader = DataLoaderX(trainDataset(datafilter[:1000], data_transforms,data_transforms2),batch_size=128, shuffle=False,num_workers=2, pin_memory=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_dataloader = DataLoaderX(testDataset(test, data_transforms,data_transforms2),batch_size=128,shuffle=False,num_workers=2, pin_memory=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# plt.figure(figsize=(10,10))\n",
      "# plt.subplot(2,2,1)\n",
      "# plt.imshow(transforms.ToPILImage()(trainA_dataloader.dataset[15][0]).convert('RGB'))\n",
      "# plt.subplot(2,2,2)\n",
      "# plt.imshow(transforms.ToPILImage()(trainA_dataloader.dataset[15][1]).convert('RGB'))\n",
      "# plt.subplot(2,2,3)\n",
      "# plt.imshow(transforms.ToPILImage()(trainA_dataloader.dataset[29][0]).convert('RGB'))\n",
      "# plt.subplot(2,2,4)\n",
      "# plt.imshow(transforms.ToPILImage()(trainA_dataloader.dataset[29][1]).convert('RGB'))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#(np.array(trainC_dataloader.dataset[4][0]).shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# https://github.com/Cadene/pretrained-models.pytorch/blob/master/pretrainedmodels/models/senet.py\n",
      "\"\"\"\n",
      "ResNet code gently borrowed from\n",
      "https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py\n",
      "\"\"\"\n",
      "from __future__ import print_function, division, absolute_import\n",
      "from collections import OrderedDict\n",
      "import math\n",
      "\n",
      "import torch.nn as nn\n",
      "from torch.utils import model_zoo\n",
      "\n",
      "__all__ = ['SENet', 'senet154', 'se_resnet50', 'se_resnet101', 'se_resnet152',\n",
      "           'se_resnext50_32x4d', 'se_resnext101_32x4d']\n",
      "\n",
      "pretrained_settings = {\n",
      "    'senet154': {\n",
      "        'imagenet': {\n",
      "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/senet154-c7b49a05.pth',\n",
      "            'input_space': 'RGB',\n",
      "            'input_size': [3, 224, 224],\n",
      "            'input_range': [0, 1],\n",
      "            'mean': [0.485, 0.456, 0.406],\n",
      "            'std': [0.229, 0.224, 0.225],\n",
      "            'num_classes': 1000\n",
      "        }\n",
      "    },\n",
      "    'se_resnet50': {\n",
      "        'imagenet': {\n",
      "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnet50-ce0d4300.pth',\n",
      "            'input_space': 'RGB',\n",
      "            'input_size': [3, 224, 224],\n",
      "            'input_range': [0, 1],\n",
      "            'mean': [0.485, 0.456, 0.406],\n",
      "            'std': [0.229, 0.224, 0.225],\n",
      "            'num_classes': 1000\n",
      "        }\n",
      "    },\n",
      "    'se_resnet101': {\n",
      "        'imagenet': {\n",
      "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnet101-7e38fcc6.pth',\n",
      "            'input_space': 'RGB',\n",
      "            'input_size': [3, 224, 224],\n",
      "            'input_range': [0, 1],\n",
      "            'mean': [0.485, 0.456, 0.406],\n",
      "            'std': [0.229, 0.224, 0.225],\n",
      "            'num_classes': 1000\n",
      "        }\n",
      "    },\n",
      "    'se_resnet152': {\n",
      "        'imagenet': {\n",
      "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnet152-d17c99b7.pth',\n",
      "            'input_space': 'RGB',\n",
      "            'input_size': [3, 224, 224],\n",
      "            'input_range': [0, 1],\n",
      "            'mean': [0.485, 0.456, 0.406],\n",
      "            'std': [0.229, 0.224, 0.225],\n",
      "            'num_classes': 1000\n",
      "        }\n",
      "    },\n",
      "    'se_resnext50_32x4d': {\n",
      "        'imagenet': {\n",
      "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnext50_32x4d-a260b3a4.pth',\n",
      "            'input_space': 'RGB',\n",
      "            'input_size': [3, 224, 224],\n",
      "            'input_range': [0, 1],\n",
      "            'mean': [0.485, 0.456, 0.406],\n",
      "            'std': [0.229, 0.224, 0.225],\n",
      "            'num_classes': 1000\n",
      "        }\n",
      "    },\n",
      "    'se_resnext101_32x4d': {\n",
      "        'imagenet': {\n",
      "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnext101_32x4d-3b2fe3d8.pth',\n",
      "            'input_space': 'RGB',\n",
      "            'input_size': [3, 224, 224],\n",
      "            'input_range': [0, 1],\n",
      "            'mean': [0.485, 0.456, 0.406],\n",
      "            'std': [0.229, 0.224, 0.225],\n",
      "            'num_classes': 1000\n",
      "        }\n",
      "    },\n",
      "}\n",
      "\n",
      "\n",
      "class SEModule(nn.Module):\n",
      "\n",
      "    def __init__(self, channels, reduction):\n",
      "        super(SEModule, self).__init__()\n",
      "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
      "        self.fc1 = nn.Conv2d(channels, channels // reduction, kernel_size=1,\n",
      "                             padding=0)\n",
      "        self.relu = nn.ReLU(inplace=True)\n",
      "        self.fc2 = nn.Conv2d(channels // reduction, channels, kernel_size=1,\n",
      "                             padding=0)\n",
      "        self.sigmoid = nn.Sigmoid()\n",
      "\n",
      "    def forward(self, x):\n",
      "        module_input = x\n",
      "        x = self.avg_pool(x)\n",
      "        x = self.fc1(x)\n",
      "        x = self.relu(x)\n",
      "        x = self.fc2(x)\n",
      "        x = self.sigmoid(x)\n",
      "        return module_input * x\n",
      "\n",
      "\n",
      "class Bottleneck(nn.Module):\n",
      "    \"\"\"\n",
      "    Base class for bottlenecks that implements `forward()` method.\n",
      "    \"\"\"\n",
      "    def forward(self, x):\n",
      "        residual = x\n",
      "\n",
      "        out = self.conv1(x)\n",
      "        out = self.bn1(out)\n",
      "        out = self.relu(out)\n",
      "\n",
      "        out = self.conv2(out)\n",
      "        out = self.bn2(out)\n",
      "        out = self.relu(out)\n",
      "\n",
      "        out = self.conv3(out)\n",
      "        out = self.bn3(out)\n",
      "\n",
      "        if self.downsample is not None:\n",
      "            residual = self.downsample(x)\n",
      "\n",
      "        out = self.se_module(out) + residual\n",
      "        out = self.relu(out)\n",
      "\n",
      "        return out\n",
      "\n",
      "\n",
      "class SEBottleneck(Bottleneck):\n",
      "    \"\"\"\n",
      "    Bottleneck for SENet154.\n",
      "    \"\"\"\n",
      "    expansion = 4\n",
      "\n",
      "    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n",
      "                 downsample=None):\n",
      "        super(SEBottleneck, self).__init__()\n",
      "        self.conv1 = nn.Conv2d(inplanes, planes * 2, kernel_size=1, bias=False)\n",
      "        self.bn1 = nn.BatchNorm2d(planes * 2)\n",
      "        self.conv2 = nn.Conv2d(planes * 2, planes * 4, kernel_size=3,\n",
      "                               stride=stride, padding=1, groups=groups,\n",
      "                               bias=False)\n",
      "        self.bn2 = nn.BatchNorm2d(planes * 4)\n",
      "        self.conv3 = nn.Conv2d(planes * 4, planes * 4, kernel_size=1,\n",
      "                               bias=False)\n",
      "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
      "        self.relu = nn.ReLU(inplace=True)\n",
      "        self.se_module = SEModule(planes * 4, reduction=reduction)\n",
      "        self.downsample = downsample\n",
      "        self.stride = stride\n",
      "\n",
      "\n",
      "class SEResNetBottleneck(Bottleneck):\n",
      "    \"\"\"\n",
      "    ResNet bottleneck with a Squeeze-and-Excitation module. It follows Caffe\n",
      "    implementation and uses `stride=stride` in `conv1` and not in `conv2`\n",
      "    (the latter is used in the torchvision implementation of ResNet).\n",
      "    \"\"\"\n",
      "    expansion = 4\n",
      "\n",
      "    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n",
      "                 downsample=None):\n",
      "        super(SEResNetBottleneck, self).__init__()\n",
      "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False,\n",
      "                               stride=stride)\n",
      "        self.bn1 = nn.BatchNorm2d(planes)\n",
      "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, padding=1,\n",
      "                               groups=groups, bias=False)\n",
      "        self.bn2 = nn.BatchNorm2d(planes)\n",
      "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
      "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
      "        self.relu = nn.ReLU(inplace=True)\n",
      "        self.se_module = SEModule(planes * 4, reduction=reduction)\n",
      "        self.downsample = downsample\n",
      "        self.stride = stride\n",
      "\n",
      "\n",
      "class SEResNeXtBottleneck(Bottleneck):\n",
      "    \"\"\"\n",
      "    ResNeXt bottleneck type C with a Squeeze-and-Excitation module.\n",
      "    \"\"\"\n",
      "    expansion = 4\n",
      "\n",
      "    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n",
      "                 downsample=None, base_width=4):\n",
      "        super(SEResNeXtBottleneck, self).__init__()\n",
      "        width = math.floor(planes * (base_width / 64)) * groups\n",
      "        self.conv1 = nn.Conv2d(inplanes, width, kernel_size=1, bias=False,\n",
      "                               stride=1)\n",
      "        self.bn1 = nn.BatchNorm2d(width)\n",
      "        self.conv2 = nn.Conv2d(width, width, kernel_size=3, stride=stride,\n",
      "                               padding=1, groups=groups, bias=False)\n",
      "        self.bn2 = nn.BatchNorm2d(width)\n",
      "        self.conv3 = nn.Conv2d(width, planes * 4, kernel_size=1, bias=False)\n",
      "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
      "        self.relu = nn.ReLU(inplace=True)\n",
      "        self.se_module = SEModule(planes * 4, reduction=reduction)\n",
      "        self.downsample = downsample\n",
      "        self.stride = stride\n",
      "\n",
      "\n",
      "class SENet(nn.Module):\n",
      "\n",
      "    def __init__(self, block, layers, groups, reduction, dropout_p=0.2,\n",
      "                 inplanes=128, input_3x3=True, downsample_kernel_size=3,\n",
      "                 downsample_padding=1, num_classes=1000):\n",
      "        \"\"\"\n",
      "        Parameters\n",
      "        ----------\n",
      "        block (nn.Module): Bottleneck class.\n",
      "            - For SENet154: SEBottleneck\n",
      "            - For SE-ResNet models: SEResNetBottleneck\n",
      "            - For SE-ResNeXt models:  SEResNeXtBottleneck\n",
      "        layers (list of ints): Number of residual blocks for 4 layers of the\n",
      "            network (layer1...layer4).\n",
      "        groups (int): Number of groups for the 3x3 convolution in each\n",
      "            bottleneck block.\n",
      "            - For SENet154: 64\n",
      "            - For SE-ResNet models: 1\n",
      "            - For SE-ResNeXt models:  32\n",
      "        reduction (int): Reduction ratio for Squeeze-and-Excitation modules.\n",
      "            - For all models: 16\n",
      "        dropout_p (float or None): Drop probability for the Dropout layer.\n",
      "            If `None` the Dropout layer is not used.\n",
      "            - For SENet154: 0.2\n",
      "            - For SE-ResNet models: None\n",
      "            - For SE-ResNeXt models: None\n",
      "        inplanes (int):  Number of input channels for layer1.\n",
      "            - For SENet154: 128\n",
      "            - For SE-ResNet models: 64\n",
      "            - For SE-ResNeXt models: 64\n",
      "        input_3x3 (bool): If `True`, use three 3x3 convolutions instead of\n",
      "            a single 7x7 convolution in layer0.\n",
      "            - For SENet154: True\n",
      "            - For SE-ResNet models: False\n",
      "            - For SE-ResNeXt models: False\n",
      "        downsample_kernel_size (int): Kernel size for downsampling convolutions\n",
      "            in layer2, layer3 and layer4.\n",
      "            - For SENet154: 3\n",
      "            - For SE-ResNet models: 1\n",
      "            - For SE-ResNeXt models: 1\n",
      "        downsample_padding (int): Padding for downsampling convolutions in\n",
      "            layer2, layer3 and layer4.\n",
      "            - For SENet154: 1\n",
      "            - For SE-ResNet models: 0\n",
      "            - For SE-ResNeXt models: 0\n",
      "        num_classes (int): Number of outputs in `last_linear` layer.\n",
      "            - For all models: 1000\n",
      "        \"\"\"\n",
      "        super(SENet, self).__init__()\n",
      "        self.inplanes = inplanes\n",
      "        if input_3x3:\n",
      "            layer0_modules = [\n",
      "                ('conv1', nn.Conv2d(3, 64, 3, stride=2, padding=1,\n",
      "                                    bias=False)),\n",
      "                ('bn1', nn.BatchNorm2d(64)),\n",
      "                ('relu1', nn.ReLU(inplace=True)),\n",
      "                ('conv2', nn.Conv2d(64, 64, 3, stride=1, padding=1,\n",
      "                                    bias=False)),\n",
      "                ('bn2', nn.BatchNorm2d(64)),\n",
      "                ('relu2', nn.ReLU(inplace=True)),\n",
      "                ('conv3', nn.Conv2d(64, inplanes, 3, stride=1, padding=1,\n",
      "                                    bias=False)),\n",
      "                ('bn3', nn.BatchNorm2d(inplanes)),\n",
      "                ('relu3', nn.ReLU(inplace=True)),\n",
      "            ]\n",
      "        else:\n",
      "            layer0_modules = [\n",
      "                ('conv1', nn.Conv2d(3, inplanes, kernel_size=7, stride=2,\n",
      "                                    padding=3, bias=False)),\n",
      "                ('bn1', nn.BatchNorm2d(inplanes)),\n",
      "                ('relu1', nn.ReLU(inplace=True)),\n",
      "            ]\n",
      "        # To preserve compatibility with Caffe weights `ceil_mode=True`\n",
      "        # is used instead of `padding=1`.\n",
      "        layer0_modules.append(('pool', nn.MaxPool2d(3, stride=2,\n",
      "                                                    ceil_mode=True)))\n",
      "        self.layer0 = nn.Sequential(OrderedDict(layer0_modules))\n",
      "        self.layer1 = self._make_layer(\n",
      "            block,\n",
      "            planes=64,\n",
      "            blocks=layers[0],\n",
      "            groups=groups,\n",
      "            reduction=reduction,\n",
      "            downsample_kernel_size=1,\n",
      "            downsample_padding=0\n",
      "        )\n",
      "        self.layer2 = self._make_layer(\n",
      "            block,\n",
      "            planes=128,\n",
      "            blocks=layers[1],\n",
      "            stride=2,\n",
      "            groups=groups,\n",
      "            reduction=reduction,\n",
      "            downsample_kernel_size=downsample_kernel_size,\n",
      "            downsample_padding=downsample_padding\n",
      "        )\n",
      "        self.layer3 = self._make_layer(\n",
      "            block,\n",
      "            planes=256,\n",
      "            blocks=layers[2],\n",
      "            stride=2,\n",
      "            groups=groups,\n",
      "            reduction=reduction,\n",
      "            downsample_kernel_size=downsample_kernel_size,\n",
      "            downsample_padding=downsample_padding\n",
      "        )\n",
      "        self.layer4 = self._make_layer(\n",
      "            block,\n",
      "            planes=512,\n",
      "            blocks=layers[3],\n",
      "            stride=2,\n",
      "            groups=groups,\n",
      "            reduction=reduction,\n",
      "            downsample_kernel_size=downsample_kernel_size,\n",
      "            downsample_padding=downsample_padding\n",
      "        )\n",
      "        self.avg_pool = nn.AvgPool2d(7, stride=1)\n",
      "        self.dropout = nn.Dropout(dropout_p) if dropout_p is not None else None\n",
      "        self.last_linear = nn.Linear(512 * block.expansion, num_classes)\n",
      "\n",
      "    def _make_layer(self, block, planes, blocks, groups, reduction, stride=1,\n",
      "                    downsample_kernel_size=1, downsample_padding=0):\n",
      "        downsample = None\n",
      "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
      "            downsample = nn.Sequential(\n",
      "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
      "                          kernel_size=downsample_kernel_size, stride=stride,\n",
      "                          padding=downsample_padding, bias=False),\n",
      "                nn.BatchNorm2d(planes * block.expansion),\n",
      "            )\n",
      "\n",
      "        layers = []\n",
      "        layers.append(block(self.inplanes, planes, groups, reduction, stride,\n",
      "                            downsample))\n",
      "        self.inplanes = planes * block.expansion\n",
      "        for i in range(1, blocks):\n",
      "            layers.append(block(self.inplanes, planes, groups, reduction))\n",
      "\n",
      "        return nn.Sequential(*layers)\n",
      "\n",
      "    def features(self, x):\n",
      "        x = self.layer0(x)\n",
      "        x = self.layer1(x)\n",
      "        x = self.layer2(x)\n",
      "        x = self.layer3(x)\n",
      "        x = self.layer4(x)\n",
      "        return x\n",
      "\n",
      "    def logits(self, x):\n",
      "        x = self.avg_pool(x)\n",
      "        if self.dropout is not None:\n",
      "            x = self.dropout(x)\n",
      "        x = x.view(x.size(0), -1)\n",
      "        x = self.last_linear(x)\n",
      "        return x\n",
      "\n",
      "    def forward(self, x):\n",
      "        x = self.features(x)\n",
      "        x = self.logits(x)\n",
      "        return x\n",
      "\n",
      "\n",
      "def initialize_pretrained_model(model, num_classes, settings):\n",
      "    assert num_classes == settings['num_classes'], \\\n",
      "        'num_classes should be {}, but is {}'.format(\n",
      "            settings['num_classes'], num_classes)\n",
      "    model.load_state_dict(model_zoo.load_url(settings['url']))\n",
      "    model.input_space = settings['input_space']\n",
      "    model.input_size = settings['input_size']\n",
      "    model.input_range = settings['input_range']\n",
      "    model.mean = settings['mean']\n",
      "    model.std = settings['std']\n",
      "\n",
      "\n",
      "def senet154(num_classes=1000, pretrained='imagenet'):\n",
      "    model = SENet(SEBottleneck, [3, 8, 36, 3], groups=64, reduction=16,\n",
      "                  dropout_p=0.2, num_classes=num_classes)\n",
      "    if pretrained is not None:\n",
      "        settings = pretrained_settings['senet154'][pretrained]\n",
      "        initialize_pretrained_model(model, num_classes, settings)\n",
      "    return model\n",
      "\n",
      "\n",
      "def se_resnet50(num_classes=1000, pretrained='imagenet'):\n",
      "    model = SENet(SEResNetBottleneck, [3, 4, 6, 3], groups=1, reduction=16,\n",
      "                  dropout_p=None, inplanes=64, input_3x3=False,\n",
      "                  downsample_kernel_size=1, downsample_padding=0,\n",
      "                  num_classes=num_classes)\n",
      "    if pretrained is not None:\n",
      "        settings = pretrained_settings['se_resnet50'][pretrained]\n",
      "        initialize_pretrained_model(model, num_classes, settings)\n",
      "    return model\n",
      "\n",
      "\n",
      "def se_resnet101(num_classes=1000, pretrained='imagenet'):\n",
      "    model = SENet(SEResNetBottleneck, [3, 4, 23, 3], groups=1, reduction=16,\n",
      "                  dropout_p=None, inplanes=64, input_3x3=False,\n",
      "                  downsample_kernel_size=1, downsample_padding=0,\n",
      "                  num_classes=num_classes)\n",
      "    if pretrained is not None:\n",
      "        settings = pretrained_settings['se_resnet101'][pretrained]\n",
      "        initialize_pretrained_model(model, num_classes, settings)\n",
      "    return model\n",
      "\n",
      "\n",
      "def se_resnet152(num_classes=1000, pretrained='imagenet'):\n",
      "    model = SENet(SEResNetBottleneck, [3, 8, 36, 3], groups=1, reduction=16,\n",
      "                  dropout_p=None, inplanes=64, input_3x3=False,\n",
      "                  downsample_kernel_size=1, downsample_padding=0,\n",
      "                  num_classes=num_classes)\n",
      "    if pretrained is not None:\n",
      "        settings = pretrained_settings['se_resnet152'][pretrained]\n",
      "        initialize_pretrained_model(model, num_classes, settings)\n",
      "    return model\n",
      "\n",
      "\n",
      "def se_resnext50_32x4d(num_classes=1000, pretrained='imagenet'):\n",
      "    model = SENet(SEResNeXtBottleneck, [3, 4, 6, 3], groups=32, reduction=16,\n",
      "                  dropout_p=None, inplanes=64, input_3x3=False,\n",
      "                  downsample_kernel_size=1, downsample_padding=0,\n",
      "                  num_classes=num_classes)\n",
      "    if pretrained is not None:\n",
      "        settings = pretrained_settings['se_resnext50_32x4d'][pretrained]\n",
      "        initialize_pretrained_model(model, num_classes, settings)\n",
      "    return model\n",
      "\n",
      "\n",
      "def se_resnext101_32x4d(num_classes=1000, pretrained='imagenet'):\n",
      "    model = SENet(SEResNeXtBottleneck, [3, 4, 23, 3], groups=32, reduction=16,\n",
      "                  dropout_p=None, inplanes=64, input_3x3=False,\n",
      "                  downsample_kernel_size=1, downsample_padding=0,\n",
      "                  num_classes=num_classes)\n",
      "    if pretrained is not None:\n",
      "        settings = pretrained_settings['se_resnext101_32x4d'][pretrained]\n",
      "        initialize_pretrained_model(model, num_classes, settings)\n",
      "    return model"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# from shutil import copyfile\n",
      "# from os.path import isfile, join, abspath, exists, isdir, expanduser\n",
      "# from os import listdir, makedirs, getcwd, remove\n",
      "\n",
      "# cache_dir = expanduser(join('~', '.torch'))\n",
      "# if not exists(cache_dir):\n",
      "#     makedirs(cache_dir)\n",
      "# models_dir = join(cache_dir, 'models/')\n",
      "# if not exists(models_dir):\n",
      "#     makedirs(models_dir)\n",
      "    \n",
      "# copyfile(\"../input/pretrained-pytorch/densenet201-c1103571.pth\", models_dir+\"densenet201-c1103571.pth\")\n",
      "# copyfile(\"../input/pretrained-pytorch/resnet50-19c8e357.pth\", models_dir+\"resnet50-19c8e357.pth\")\n",
      "# copyfile(\"../input/pretrained-se-resnet/se_resnext101_32x4d-3b2fe3d8.pth\", models_dir+\"se_resnext101_32x4d-3b2fe3d8.pth\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# !ls ~/.torch/models  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Ensemble(nn.Module):\n",
      "    def __init__(self, modelA, modelB,input_length,output_length):\n",
      "        super(Ensemble, self).__init__()\n",
      "        self.modelA = modelA\n",
      "        self.modelB = modelB\n",
      "        self.classifier = nn.Linear(input_length, output_length)\n",
      "        \n",
      "    def forward(self, xin,xin2):\n",
      "        x1 = self.modelA(xin)\n",
      "        x2 = self.modelB(xin2)\n",
      "        x = torch.cat((x1, x2), dim=1)\n",
      "        x = self.classifier(F.relu(x))\n",
      "        return x\n",
      "\n",
      "    \n",
      "# efficientNet = EfficientNet.from_name('efficientnet-b7') \n",
      "# efficientNet._fc = nn.Linear(in_features=1280, out_features=lable_length)\n",
      "\n",
      "\n",
      "seresnext_model = se_resnext101_32x4d(pretrained='imagenet')\n",
      "seresnext_model.last_linear = nn.Linear(in_features=2048, out_features=lable_length, bias=True)\n",
      "\n",
      "#densenet_model = models.densenet201(pretrained=True)\n",
      "#densenet_model.load_state_dict(torch.load( models_dir+\"densenet201-c1103571.pth\"))\n",
      "#densenet_model.classifier= nn.Linear(in_features=1920,out_features=lable_length)\n",
      "\n",
      "#efficientNet = EfficientNet(width_coeff=2.0, depth_coeff=3.1,drop_connect_rate=0.5,num_classes = lable_length)\n",
      "\n",
      "resnet_model = models.resnet50(pretrained=True)\n",
      "#resnet_model.load_state_dict(torch.load(\"../models/resnet50.pth\"))\n",
      "resnet_model.fc= nn.Linear(in_features=2048, out_features=lable_length)\n",
      "\n",
      "#model = Ensemble(seresnext_model, resnet_model,lable_length*2,lable_length)\n",
      "#model.to(device)\n",
      "\n",
      "\n",
      "model = seresnext_model\n",
      "#model = nn.DataParallel(model)\n",
      "\n",
      "if torch.cuda.device_count() > 1:\n",
      "    # device_ids has a default : all\n",
      "    model = torch.nn.DataParallel(model, device_ids=[0,1,2,3]) \n",
      "model.to(device)\n",
      "\n",
      "#model.to(device)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 36,
       "text": [
        "DataParallel(\n",
        "  (module): SENet(\n",
        "    (layer0): Sequential(\n",
        "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      (relu1): ReLU(inplace=True)\n",
        "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
        "    )\n",
        "    (layer1): Sequential(\n",
        "      (0): SEResNeXtBottleneck(\n",
        "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
        "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu): ReLU(inplace=True)\n",
        "        (se_module): SEModule(\n",
        "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
        "          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (relu): ReLU(inplace=True)\n",
        "          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (sigmoid): Sigmoid()\n",
        "        )\n",
        "        (downsample): Sequential(\n",
        "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        )\n",
        "      )\n",
        "      (1): SEResNeXtBottleneck(\n",
        "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
        "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu): ReLU(inplace=True)\n",
        "        (se_module): SEModule(\n",
        "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
        "          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (relu): ReLU(inplace=True)\n",
        "          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (sigmoid): Sigmoid()\n",
        "        )\n",
        "      )\n",
        "      (2): SEResNeXtBottleneck(\n",
        "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
        "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu): ReLU(inplace=True)\n",
        "        (se_module): SEModule(\n",
        "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
        "          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (relu): ReLU(inplace=True)\n",
        "          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (sigmoid): Sigmoid()\n",
        "        )\n",
        "      )\n",
        "    )\n",
        "    (layer2): Sequential(\n",
        "      (0): SEResNeXtBottleneck(\n",
        "        (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
        "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu): ReLU(inplace=True)\n",
        "        (se_module): SEModule(\n",
        "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
        "          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (relu): ReLU(inplace=True)\n",
        "          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (sigmoid): Sigmoid()\n",
        "        )\n",
        "        (downsample): Sequential(\n",
        "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
        "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        )\n",
        "      )\n",
        "      (1): SEResNeXtBottleneck(\n",
        "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
        "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu): ReLU(inplace=True)\n",
        "        (se_module): SEModule(\n",
        "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
        "          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (relu): ReLU(inplace=True)\n",
        "          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (sigmoid): Sigmoid()\n",
        "        )\n",
        "      )\n",
        "      (2): SEResNeXtBottleneck(\n",
        "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
        "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu): ReLU(inplace=True)\n",
        "        (se_module): SEModule(\n",
        "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
        "          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (relu): ReLU(inplace=True)\n",
        "          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (sigmoid): Sigmoid()\n",
        "        )\n",
        "      )\n",
        "      (3): SEResNeXtBottleneck(\n",
        "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
        "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu): ReLU(inplace=True)\n",
        "        (se_module): SEModule(\n",
        "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
        "          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (relu): ReLU(inplace=True)\n",
        "          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (sigmoid): Sigmoid()\n",
        "        )\n",
        "      )\n",
        "    )\n",
        "    (layer3): Sequential(\n",
        "      (0): SEResNeXtBottleneck(\n",
        "        (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
        "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu): ReLU(inplace=True)\n",
        "        (se_module): SEModule(\n",
        "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
        "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (relu): ReLU(inplace=True)\n",
        "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (sigmoid): Sigmoid()\n",
        "        )\n",
        "        (downsample): Sequential(\n",
        "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
        "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        )\n",
        "      )\n",
        "      (1): SEResNeXtBottleneck(\n",
        "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
        "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu): ReLU(inplace=True)\n",
        "        (se_module): SEModule(\n",
        "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
        "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (relu): ReLU(inplace=True)\n",
        "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (sigmoid): Sigmoid()\n",
        "        )\n",
        "      )\n",
        "      (2): SEResNeXtBottleneck(\n",
        "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
        "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu): ReLU(inplace=True)\n",
        "        (se_module): SEModule(\n",
        "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
        "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (relu): ReLU(inplace=True)\n",
        "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (sigmoid): Sigmoid()\n",
        "        )\n",
        "      )\n",
        "      (3): SEResNeXtBottleneck(\n",
        "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
        "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu): ReLU(inplace=True)\n",
        "        (se_module): SEModule(\n",
        "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
        "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (relu): ReLU(inplace=True)\n",
        "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (sigmoid): Sigmoid()\n",
        "        )\n",
        "      )\n",
        "      (4): SEResNeXtBottleneck(\n",
        "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
        "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu): ReLU(inplace=True)\n",
        "        (se_module): SEModule(\n",
        "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
        "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (relu): ReLU(inplace=True)\n",
        "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (sigmoid): Sigmoid()\n",
        "        )\n",
        "      )\n",
        "      (5): SEResNeXtBottleneck(\n",
        "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
        "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu): ReLU(inplace=True)\n",
        "        (se_module): SEModule(\n",
        "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
        "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (relu): ReLU(inplace=True)\n",
        "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (sigmoid): Sigmoid()\n",
        "        )\n",
        "      )\n",
        "      (6): SEResNeXtBottleneck(\n",
        "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
        "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu): ReLU(inplace=True)\n",
        "        (se_module): SEModule(\n",
        "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
        "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (relu): ReLU(inplace=True)\n",
        "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (sigmoid): Sigmoid()\n",
        "        )\n",
        "      )\n",
        "      (7): SEResNeXtBottleneck(\n",
        "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
        "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu): ReLU(inplace=True)\n",
        "        (se_module): SEModule(\n",
        "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
        "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (relu): ReLU(inplace=True)\n",
        "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (sigmoid): Sigmoid()\n",
        "        )\n",
        "      )\n",
        "      (8): SEResNeXtBottleneck(\n",
        "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
        "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu): ReLU(inplace=True)\n",
        "        (se_module): SEModule(\n",
        "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
        "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (relu): ReLU(inplace=True)\n",
        "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (sigmoid): Sigmoid()\n",
        "        )\n",
        "      )\n",
        "      (9): SEResNeXtBottleneck(\n",
        "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
        "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu): ReLU(inplace=True)\n",
        "        (se_module): SEModule(\n",
        "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
        "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (relu): ReLU(inplace=True)\n",
        "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (sigmoid): Sigmoid()\n",
        "        )\n",
        "      )\n",
        "      (10): SEResNeXtBottleneck(\n",
        "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
        "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu): ReLU(inplace=True)\n",
        "        (se_module): SEModule(\n",
        "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
        "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (relu): ReLU(inplace=True)\n",
        "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (sigmoid): Sigmoid()\n",
        "        )\n",
        "      )\n",
        "      (11): SEResNeXtBottleneck(\n",
        "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
        "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu): ReLU(inplace=True)\n",
        "        (se_module): SEModule(\n",
        "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
        "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (relu): ReLU(inplace=True)\n",
        "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (sigmoid): Sigmoid()\n",
        "        )\n",
        "      )\n",
        "      (12): SEResNeXtBottleneck(\n",
        "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
        "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu): ReLU(inplace=True)\n",
        "        (se_module): SEModule(\n",
        "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
        "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (relu): ReLU(inplace=True)\n",
        "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (sigmoid): Sigmoid()\n",
        "        )\n",
        "      )\n",
        "      (13): SEResNeXtBottleneck(\n",
        "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
        "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu): ReLU(inplace=True)\n",
        "        (se_module): SEModule(\n",
        "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
        "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (relu): ReLU(inplace=True)\n",
        "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (sigmoid): Sigmoid()\n",
        "        )\n",
        "      )\n",
        "      (14): SEResNeXtBottleneck(\n",
        "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
        "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu): ReLU(inplace=True)\n",
        "        (se_module): SEModule(\n",
        "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
        "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (relu): ReLU(inplace=True)\n",
        "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (sigmoid): Sigmoid()\n",
        "        )\n",
        "      )\n",
        "      (15): SEResNeXtBottleneck(\n",
        "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
        "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu): ReLU(inplace=True)\n",
        "        (se_module): SEModule(\n",
        "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
        "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (relu): ReLU(inplace=True)\n",
        "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (sigmoid): Sigmoid()\n",
        "        )\n",
        "      )\n",
        "      (16): SEResNeXtBottleneck(\n",
        "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
        "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu): ReLU(inplace=True)\n",
        "        (se_module): SEModule(\n",
        "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
        "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (relu): ReLU(inplace=True)\n",
        "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (sigmoid): Sigmoid()\n",
        "        )\n",
        "      )\n",
        "      (17): SEResNeXtBottleneck(\n",
        "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
        "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu): ReLU(inplace=True)\n",
        "        (se_module): SEModule(\n",
        "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
        "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (relu): ReLU(inplace=True)\n",
        "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (sigmoid): Sigmoid()\n",
        "        )\n",
        "      )\n",
        "      (18): SEResNeXtBottleneck(\n",
        "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
        "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu): ReLU(inplace=True)\n",
        "        (se_module): SEModule(\n",
        "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
        "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (relu): ReLU(inplace=True)\n",
        "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (sigmoid): Sigmoid()\n",
        "        )\n",
        "      )\n",
        "      (19): SEResNeXtBottleneck(\n",
        "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
        "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu): ReLU(inplace=True)\n",
        "        (se_module): SEModule(\n",
        "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
        "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (relu): ReLU(inplace=True)\n",
        "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (sigmoid): Sigmoid()\n",
        "        )\n",
        "      )\n",
        "      (20): SEResNeXtBottleneck(\n",
        "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
        "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu): ReLU(inplace=True)\n",
        "        (se_module): SEModule(\n",
        "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
        "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (relu): ReLU(inplace=True)\n",
        "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (sigmoid): Sigmoid()\n",
        "        )\n",
        "      )\n",
        "      (21): SEResNeXtBottleneck(\n",
        "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
        "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu): ReLU(inplace=True)\n",
        "        (se_module): SEModule(\n",
        "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
        "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (relu): ReLU(inplace=True)\n",
        "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (sigmoid): Sigmoid()\n",
        "        )\n",
        "      )\n",
        "      (22): SEResNeXtBottleneck(\n",
        "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
        "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu): ReLU(inplace=True)\n",
        "        (se_module): SEModule(\n",
        "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
        "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (relu): ReLU(inplace=True)\n",
        "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (sigmoid): Sigmoid()\n",
        "        )\n",
        "      )\n",
        "    )\n",
        "    (layer4): Sequential(\n",
        "      (0): SEResNeXtBottleneck(\n",
        "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
        "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu): ReLU(inplace=True)\n",
        "        (se_module): SEModule(\n",
        "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
        "          (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (relu): ReLU(inplace=True)\n",
        "          (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (sigmoid): Sigmoid()\n",
        "        )\n",
        "        (downsample): Sequential(\n",
        "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
        "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        )\n",
        "      )\n",
        "      (1): SEResNeXtBottleneck(\n",
        "        (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
        "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu): ReLU(inplace=True)\n",
        "        (se_module): SEModule(\n",
        "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
        "          (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (relu): ReLU(inplace=True)\n",
        "          (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (sigmoid): Sigmoid()\n",
        "        )\n",
        "      )\n",
        "      (2): SEResNeXtBottleneck(\n",
        "        (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
        "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        (relu): ReLU(inplace=True)\n",
        "        (se_module): SEModule(\n",
        "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
        "          (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (relu): ReLU(inplace=True)\n",
        "          (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
        "          (sigmoid): Sigmoid()\n",
        "        )\n",
        "      )\n",
        "    )\n",
        "    (avg_pool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
        "    (last_linear): Linear(in_features=2048, out_features=1103, bias=True)\n",
        "  )\n",
        ")"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def train(epoch,fnum,dloader):\n",
      "    model.train()\n",
      "    for step, (x,y) in enumerate(dloader):\n",
      "        data = Variable(x).cuda(async=True)   # batch x\n",
      "        #data2 = Variable(x2).cuda()\n",
      "        target = Variable(y).cuda(async=True)   # batch y\n",
      "        #print(data.size())\n",
      "        #print(data2.size())\n",
      "        #print(target.size())\n",
      "        #output = model(data,data2)\n",
      "        #print(data.size())\n",
      "        output = model(data)\n",
      "        #print(\"out\",output.size())\n",
      "        #print(\"target\",target.size())\n",
      "\n",
      "        loss = loss_func(output, target.float())   # cross entropy loss\n",
      "        optimizer.zero_grad()           # clear gradients for this training step\n",
      "        loss.backward()                 # backpropagation, compute gradients\n",
      "        optimizer.step()                # apply gradients\n",
      "        if step==0:\n",
      "            start = time.time()\n",
      "            #break\n",
      "            ti = 0\n",
      "        elif step==100:\n",
      "            ti = time.time()-start #total time = ti*(length/100)\n",
      "            #print(ti)\n",
      "            ti = ti*(len(dloader)/100)\n",
      "        if step % 100 == 0:\n",
      "            second = ti*(((len(dloader)-step)/len(dloader)))#*(5-epoch)*(4-fnum)\n",
      "            print('Train Fold:{}/4  Ep: {}/5 [{}/{} ({:.0f}%)]\\t Loss: {:.6f}\\t Remain : {} '.\n",
      "                     format(fnum+1,\n",
      "                            epoch+1, \n",
      "                            step * len(data), \n",
      "                            len(dloader.dataset),\n",
      "                            100.*step/len(dloader), \n",
      "                            loss.data.item(),\n",
      "                            datetime.timedelta(seconds = int(second))))\n",
      "        #data.cpu()\n",
      "        #data2.cpu()\n",
      "        #target.cpu()\n",
      "        torch.cuda.empty_cache()\n",
      "    print(\"Finish\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def val(dloader):\n",
      "    model.eval()\n",
      "    los = []\n",
      "    for step, (x, y) in enumerate(dloader):\n",
      "        data = Variable(x).cuda(async=True)\n",
      "        #data2 = Variable(x2).cuda()\n",
      "        target = Variable(y).cuda(async=True)\n",
      "        \n",
      "        #output = model(data,data2)\n",
      "        with torch.no_grad():\n",
      "            output = model(data)\n",
      "        \n",
      "        loss = loss_func(output, target.float())\n",
      "        los.append(loss.item())\n",
      "        \n",
      "        \n",
      "        if step %100 == 0:\n",
      "            print('[{}/{} ({:.1f}%)]'.format(step * len(data), \n",
      "                                        len(dloader.dataset),\n",
      "                                        100.*step/len(dloader)))\n",
      "        #data.cpu()\n",
      "        #data2.cpu()\n",
      "        #arget.cpu()\n",
      "        torch.cuda.empty_cache()\n",
      "    los = np.array(los)\n",
      "    avg_val_loss = los.sum()/len(los)\n",
      "    print(\"Avg val loss:{}\".format(avg_val_loss))\n",
      "    #return ans,out\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class FocalLoss(nn.Module):\n",
      "    def __init__(self, gamma):\n",
      "        super().__init__()\n",
      "        self.gamma = gamma\n",
      "        \n",
      "    def forward(self, input, target):\n",
      "        # Inspired by the implementation of binary_cross_entropy_with_logits\n",
      "        if not (target.size() == input.size()):\n",
      "            raise ValueError(\"Target size ({}) must be the same as input size ({})\".format(target.size(), input.size()))\n",
      "\n",
      "        max_val = (-input).clamp(min=0)\n",
      "        loss = input - input * target + max_val + ((-max_val).exp() + (-input - max_val).exp()).log()\n",
      "\n",
      "        # This formula gives us the log sigmoid of 1-p if y is 0 and of p if y is 1\n",
      "        invprobs = F.logsigmoid(-input * (target * 2 - 1))\n",
      "        loss = (invprobs * self.gamma).exp() * loss\n",
      "        \n",
      "        return loss.mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fold = KFold(n_splits = 4, random_state = 10)\n",
      "for fold_num, (trn_idx, val_idx) in enumerate(fold.split(datafilter)):\n",
      "    Ftrain_dataloader = datafilter[trn_idx, :]\n",
      "    Fval_dataloader = datafilter[val_idx, :]\n",
      "    #print(trn_idx,val_idx)\n",
      "\n",
      "    val_dataloader = DataLoaderX(dataset_h5(\"all_data_109237v1.h5\", data_transforms2, val_idx),batch_size=100, shuffle=False,num_workers=0, pin_memory=True)\n",
      "    train_dataloader = DataLoaderX(dataset_h5(\"all_data_109237v1.h5\", data_transforms2, trn_idx),batch_size=100, shuffle=True,num_workers=0, pin_memory=True)\n",
      "    for epoch in range(5):\n",
      "        ###########################################\n",
      "        if epoch==0:\n",
      "            optimizer = torch.optim.Adam(model.parameters(), lr=0.0001/(2**epoch))\n",
      "        else:\n",
      "            optimizer = torch.optim.SGD(model.parameters(), lr=0.00008,momentum=0.9, weight_decay=1e-4)\n",
      "        #optimizer = torch.optim.Adam(model.parameters(), lr=0.00002/(2**epoch))\n",
      "        #optimizer = torch.optim.SGD(net.parameters(), lr=args.lr, momentum=0.9, weight_decay=1e-4)\n",
      "        loss_func = FocalLoss(0.4)\n",
      "        #loss_func = torch.nn.MSELoss()\n",
      "        ###########################################\n",
      "        train(epoch,fold_num,train_dataloader) \n",
      "        val(val_dataloader)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Load data from .h5 file...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Take 0:00:02 seconds\n",
        "Load data from .h5 file...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Take 0:00:07 seconds\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:1/4  Ep: 1/5 [0/81927 (0%)]\t Loss: 0.535908\t Remain : 0:00:00 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:1/4  Ep: 1/5 [10000/81927 (12%)]\t Loss: 0.010507\t Remain : 1:14:16 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:1/4  Ep: 1/5 [20000/81927 (24%)]\t Loss: 0.010145\t Remain : 1:03:57 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:1/4  Ep: 1/5 [30000/81927 (37%)]\t Loss: 0.009082\t Remain : 0:53:38 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:1/4  Ep: 1/5 [40000/81927 (49%)]\t Loss: 0.009573\t Remain : 0:43:19 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:1/4  Ep: 1/5 [50000/81927 (61%)]\t Loss: 0.008276\t Remain : 0:33:00 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:1/4  Ep: 1/5 [60000/81927 (73%)]\t Loss: 0.008516\t Remain : 0:22:41 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:1/4  Ep: 1/5 [70000/81927 (85%)]\t Loss: 0.008201\t Remain : 0:12:22 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:1/4  Ep: 1/5 [80000/81927 (98%)]\t Loss: 0.008835\t Remain : 0:02:03 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Finish\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0/27310 (0.0%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[10000/27310 (36.5%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[20000/27310 (73.0%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Avg val loss:0.007776613508684248\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:1/4  Ep: 2/5 [0/81927 (0%)]\t Loss: 0.008014\t Remain : 0:00:00 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:1/4  Ep: 2/5 [10000/81927 (12%)]\t Loss: 0.008096\t Remain : 1:14:12 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:1/4  Ep: 2/5 [20000/81927 (24%)]\t Loss: 0.007347\t Remain : 1:03:54 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:1/4  Ep: 2/5 [30000/81927 (37%)]\t Loss: 0.008902\t Remain : 0:53:35 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:1/4  Ep: 2/5 [40000/81927 (49%)]\t Loss: 0.008124\t Remain : 0:43:17 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:1/4  Ep: 2/5 [50000/81927 (61%)]\t Loss: 0.007473\t Remain : 0:32:58 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:1/4  Ep: 2/5 [60000/81927 (73%)]\t Loss: 0.007807\t Remain : 0:22:40 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:1/4  Ep: 2/5 [70000/81927 (85%)]\t Loss: 0.007212\t Remain : 0:12:22 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:1/4  Ep: 2/5 [80000/81927 (98%)]\t Loss: 0.007064\t Remain : 0:02:03 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Finish\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0/27310 (0.0%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[10000/27310 (36.5%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[20000/27310 (73.0%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Avg val loss:0.007743165998236976\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:1/4  Ep: 3/5 [0/81927 (0%)]\t Loss: 0.008009\t Remain : 0:00:00 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:1/4  Ep: 3/5 [10000/81927 (12%)]\t Loss: 0.007761\t Remain : 1:14:43 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:1/4  Ep: 3/5 [20000/81927 (24%)]\t Loss: 0.007913\t Remain : 1:04:21 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:1/4  Ep: 3/5 [30000/81927 (37%)]\t Loss: 0.008163\t Remain : 0:53:58 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:1/4  Ep: 3/5 [40000/81927 (49%)]\t Loss: 0.006966\t Remain : 0:43:35 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:1/4  Ep: 3/5 [50000/81927 (61%)]\t Loss: 0.008214\t Remain : 0:33:12 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:1/4  Ep: 3/5 [60000/81927 (73%)]\t Loss: 0.007648\t Remain : 0:22:50 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:1/4  Ep: 3/5 [70000/81927 (85%)]\t Loss: 0.008288\t Remain : 0:12:27 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:1/4  Ep: 3/5 [80000/81927 (98%)]\t Loss: 0.008372\t Remain : 0:02:04 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Finish\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0/27310 (0.0%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[10000/27310 (36.5%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[20000/27310 (73.0%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Avg val loss:0.007734520467895552\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:1/4  Ep: 4/5 [0/81927 (0%)]\t Loss: 0.008663\t Remain : 0:00:00 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:1/4  Ep: 4/5 [10000/81927 (12%)]\t Loss: 0.007988\t Remain : 1:20:04 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:1/4  Ep: 4/5 [20000/81927 (24%)]\t Loss: 0.007845\t Remain : 1:08:56 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:1/4  Ep: 4/5 [30000/81927 (37%)]\t Loss: 0.007601\t Remain : 0:57:49 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:1/4  Ep: 4/5 [40000/81927 (49%)]\t Loss: 0.007694\t Remain : 0:46:42 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:1/4  Ep: 4/5 [50000/81927 (61%)]\t Loss: 0.007615\t Remain : 0:35:35 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:1/4  Ep: 4/5 [60000/81927 (73%)]\t Loss: 0.007166\t Remain : 0:24:27 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:1/4  Ep: 4/5 [70000/81927 (85%)]\t Loss: 0.006822\t Remain : 0:13:20 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:1/4  Ep: 4/5 [80000/81927 (98%)]\t Loss: 0.007956\t Remain : 0:02:13 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Finish\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0/27310 (0.0%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[10000/27310 (36.5%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[20000/27310 (73.0%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Avg val loss:0.007727276702091968\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:1/4  Ep: 5/5 [0/81927 (0%)]\t Loss: 0.007667\t Remain : 0:00:00 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:1/4  Ep: 5/5 [10000/81927 (12%)]\t Loss: 0.007359\t Remain : 1:18:50 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:1/4  Ep: 5/5 [20000/81927 (24%)]\t Loss: 0.007616\t Remain : 1:07:53 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:1/4  Ep: 5/5 [30000/81927 (37%)]\t Loss: 0.007738\t Remain : 0:56:56 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:1/4  Ep: 5/5 [40000/81927 (49%)]\t Loss: 0.007261\t Remain : 0:45:59 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:1/4  Ep: 5/5 [50000/81927 (61%)]\t Loss: 0.007325\t Remain : 0:35:02 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:1/4  Ep: 5/5 [60000/81927 (73%)]\t Loss: 0.006786\t Remain : 0:24:05 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:1/4  Ep: 5/5 [70000/81927 (85%)]\t Loss: 0.007417\t Remain : 0:13:08 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:1/4  Ep: 5/5 [80000/81927 (98%)]\t Loss: 0.007771\t Remain : 0:02:11 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Finish\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0/27310 (0.0%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[10000/27310 (36.5%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[20000/27310 (73.0%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Avg val loss:0.007723064381071795\n",
        "Load data from .h5 file...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Take 0:00:02 seconds\n",
        "Load data from .h5 file...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Take 0:01:17 seconds\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:2/4  Ep: 1/5 [0/81928 (0%)]\t Loss: 0.007203\t Remain : 0:00:00 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:2/4  Ep: 1/5 [10000/81928 (12%)]\t Loss: 0.007356\t Remain : 1:17:45 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:2/4  Ep: 1/5 [20000/81928 (24%)]\t Loss: 0.007518\t Remain : 1:06:57 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:2/4  Ep: 1/5 [30000/81928 (37%)]\t Loss: 0.007941\t Remain : 0:56:09 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:2/4  Ep: 1/5 [40000/81928 (49%)]\t Loss: 0.007677\t Remain : 0:45:21 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:2/4  Ep: 1/5 [50000/81928 (61%)]\t Loss: 0.006623\t Remain : 0:34:33 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:2/4  Ep: 1/5 [60000/81928 (73%)]\t Loss: 0.007216\t Remain : 0:23:45 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:2/4  Ep: 1/5 [70000/81928 (85%)]\t Loss: 0.006984\t Remain : 0:12:57 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:2/4  Ep: 1/5 [80000/81928 (98%)]\t Loss: 0.006859\t Remain : 0:02:09 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Finish\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0/27309 (0.0%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[10000/27309 (36.5%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[20000/27309 (73.0%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Avg val loss:0.006580399779303774\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:2/4  Ep: 2/5 [0/81928 (0%)]\t Loss: 0.006047\t Remain : 0:00:00 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:2/4  Ep: 2/5 [10000/81928 (12%)]\t Loss: 0.005725\t Remain : 1:18:12 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:2/4  Ep: 2/5 [20000/81928 (24%)]\t Loss: 0.007087\t Remain : 1:07:21 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:2/4  Ep: 2/5 [30000/81928 (37%)]\t Loss: 0.005469\t Remain : 0:56:29 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:2/4  Ep: 2/5 [40000/81928 (49%)]\t Loss: 0.006121\t Remain : 0:45:37 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:2/4  Ep: 2/5 [50000/81928 (61%)]\t Loss: 0.006702\t Remain : 0:34:45 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:2/4  Ep: 2/5 [60000/81928 (73%)]\t Loss: 0.006212\t Remain : 0:23:53 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:2/4  Ep: 2/5 [70000/81928 (85%)]\t Loss: 0.006230\t Remain : 0:13:02 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:2/4  Ep: 2/5 [80000/81928 (98%)]\t Loss: 0.005820\t Remain : 0:02:10 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Finish\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0/27309 (0.0%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[10000/27309 (36.5%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[20000/27309 (73.0%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Avg val loss:0.006574950255725505\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:2/4  Ep: 3/5 [0/81928 (0%)]\t Loss: 0.006630\t Remain : 0:00:00 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:2/4  Ep: 3/5 [10000/81928 (12%)]\t Loss: 0.006031\t Remain : 1:18:16 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:2/4  Ep: 3/5 [20000/81928 (24%)]\t Loss: 0.005883\t Remain : 1:07:24 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:2/4  Ep: 3/5 [30000/81928 (37%)]\t Loss: 0.005955\t Remain : 0:56:32 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:2/4  Ep: 3/5 [40000/81928 (49%)]\t Loss: 0.006161\t Remain : 0:45:39 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:2/4  Ep: 3/5 [50000/81928 (61%)]\t Loss: 0.005672\t Remain : 0:34:47 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:2/4  Ep: 3/5 [60000/81928 (73%)]\t Loss: 0.006057\t Remain : 0:23:55 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:2/4  Ep: 3/5 [70000/81928 (85%)]\t Loss: 0.007018\t Remain : 0:13:02 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:2/4  Ep: 3/5 [80000/81928 (98%)]\t Loss: 0.006000\t Remain : 0:02:10 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Finish\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0/27309 (0.0%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[10000/27309 (36.5%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[20000/27309 (73.0%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Avg val loss:0.006573045393452048\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:2/4  Ep: 4/5 [0/81928 (0%)]\t Loss: 0.006260\t Remain : 0:00:00 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:2/4  Ep: 4/5 [10000/81928 (12%)]\t Loss: 0.006172\t Remain : 1:18:28 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:2/4  Ep: 4/5 [20000/81928 (24%)]\t Loss: 0.006502\t Remain : 1:07:34 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:2/4  Ep: 4/5 [30000/81928 (37%)]\t Loss: 0.006277\t Remain : 0:56:40 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:2/4  Ep: 4/5 [40000/81928 (49%)]\t Loss: 0.005684\t Remain : 0:45:46 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:2/4  Ep: 4/5 [50000/81928 (61%)]\t Loss: 0.005902\t Remain : 0:34:52 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:2/4  Ep: 4/5 [60000/81928 (73%)]\t Loss: 0.005533\t Remain : 0:23:58 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:2/4  Ep: 4/5 [70000/81928 (85%)]\t Loss: 0.006609\t Remain : 0:13:04 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:2/4  Ep: 4/5 [80000/81928 (98%)]\t Loss: 0.006445\t Remain : 0:02:10 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Finish\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0/27309 (0.0%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[10000/27309 (36.5%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[20000/27309 (73.0%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Avg val loss:0.006563957506981101\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:2/4  Ep: 5/5 [0/81928 (0%)]\t Loss: 0.006208\t Remain : 0:00:00 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:2/4  Ep: 5/5 [10000/81928 (12%)]\t Loss: 0.005893\t Remain : 1:19:11 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:2/4  Ep: 5/5 [20000/81928 (24%)]\t Loss: 0.006416\t Remain : 1:08:11 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:2/4  Ep: 5/5 [30000/81928 (37%)]\t Loss: 0.006689\t Remain : 0:57:11 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:2/4  Ep: 5/5 [40000/81928 (49%)]\t Loss: 0.005663\t Remain : 0:46:11 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:2/4  Ep: 5/5 [50000/81928 (61%)]\t Loss: 0.006165\t Remain : 0:35:11 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:2/4  Ep: 5/5 [60000/81928 (73%)]\t Loss: 0.006621\t Remain : 0:24:11 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:2/4  Ep: 5/5 [70000/81928 (85%)]\t Loss: 0.006159\t Remain : 0:13:11 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:2/4  Ep: 5/5 [80000/81928 (98%)]\t Loss: 0.006379\t Remain : 0:02:11 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Finish\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0/27309 (0.0%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[10000/27309 (36.5%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[20000/27309 (73.0%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Avg val loss:0.006566792910062048\n",
        "Load data from .h5 file...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Take 0:00:02 seconds\n",
        "Load data from .h5 file...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Take 0:01:18 seconds\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:3/4  Ep: 1/5 [0/81928 (0%)]\t Loss: 0.005940\t Remain : 0:00:00 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:3/4  Ep: 1/5 [10000/81928 (12%)]\t Loss: 0.006197\t Remain : 1:18:57 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:3/4  Ep: 1/5 [20000/81928 (24%)]\t Loss: 0.006089\t Remain : 1:07:59 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:3/4  Ep: 1/5 [30000/81928 (37%)]\t Loss: 0.006324\t Remain : 0:57:01 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:3/4  Ep: 1/5 [40000/81928 (49%)]\t Loss: 0.006282\t Remain : 0:46:03 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:3/4  Ep: 1/5 [50000/81928 (61%)]\t Loss: 0.005898\t Remain : 0:35:05 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:3/4  Ep: 1/5 [60000/81928 (73%)]\t Loss: 0.006150\t Remain : 0:24:07 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:3/4  Ep: 1/5 [70000/81928 (85%)]\t Loss: 0.006697\t Remain : 0:13:09 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:3/4  Ep: 1/5 [80000/81928 (98%)]\t Loss: 0.006129\t Remain : 0:02:11 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Finish\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0/27309 (0.0%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[10000/27309 (36.5%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[20000/27309 (73.0%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Avg val loss:0.00582116320355367\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:3/4  Ep: 2/5 [0/81928 (0%)]\t Loss: 0.005388\t Remain : 0:00:00 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:3/4  Ep: 2/5 [10000/81928 (12%)]\t Loss: 0.005155\t Remain : 1:19:10 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:3/4  Ep: 2/5 [20000/81928 (24%)]\t Loss: 0.006063\t Remain : 1:08:10 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:3/4  Ep: 2/5 [30000/81928 (37%)]\t Loss: 0.005219\t Remain : 0:57:10 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:3/4  Ep: 2/5 [40000/81928 (49%)]\t Loss: 0.004940\t Remain : 0:46:10 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:3/4  Ep: 2/5 [50000/81928 (61%)]\t Loss: 0.005349\t Remain : 0:35:11 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:3/4  Ep: 2/5 [60000/81928 (73%)]\t Loss: 0.005787\t Remain : 0:24:11 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:3/4  Ep: 2/5 [70000/81928 (85%)]\t Loss: 0.004758\t Remain : 0:13:11 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:3/4  Ep: 2/5 [80000/81928 (98%)]\t Loss: 0.005690\t Remain : 0:02:11 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Finish\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0/27309 (0.0%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[10000/27309 (36.5%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[20000/27309 (73.0%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Avg val loss:0.0057948327429565415\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:3/4  Ep: 3/5 [0/81928 (0%)]\t Loss: 0.005400\t Remain : 0:00:00 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:3/4  Ep: 3/5 [10000/81928 (12%)]\t Loss: 0.005143\t Remain : 1:18:39 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:3/4  Ep: 3/5 [20000/81928 (24%)]\t Loss: 0.006058\t Remain : 1:07:44 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:3/4  Ep: 3/5 [30000/81928 (37%)]\t Loss: 0.005266\t Remain : 0:56:48 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:3/4  Ep: 3/5 [40000/81928 (49%)]\t Loss: 0.005219\t Remain : 0:45:53 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:3/4  Ep: 3/5 [50000/81928 (61%)]\t Loss: 0.005034\t Remain : 0:34:57 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:3/4  Ep: 3/5 [60000/81928 (73%)]\t Loss: 0.005431\t Remain : 0:24:02 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:3/4  Ep: 3/5 [70000/81928 (85%)]\t Loss: 0.005350\t Remain : 0:13:06 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:3/4  Ep: 3/5 [80000/81928 (98%)]\t Loss: 0.005173\t Remain : 0:02:11 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Finish\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0/27309 (0.0%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[10000/27309 (36.5%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[20000/27309 (73.0%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Avg val loss:0.005786445187268792\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:3/4  Ep: 4/5 [0/81928 (0%)]\t Loss: 0.005874\t Remain : 0:00:00 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:3/4  Ep: 4/5 [10000/81928 (12%)]\t Loss: 0.004764\t Remain : 1:20:01 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:3/4  Ep: 4/5 [20000/81928 (24%)]\t Loss: 0.005031\t Remain : 1:08:54 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:3/4  Ep: 4/5 [30000/81928 (37%)]\t Loss: 0.005536\t Remain : 0:57:47 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:3/4  Ep: 4/5 [40000/81928 (49%)]\t Loss: 0.005721\t Remain : 0:46:40 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:3/4  Ep: 4/5 [50000/81928 (61%)]\t Loss: 0.005331\t Remain : 0:35:33 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:3/4  Ep: 4/5 [60000/81928 (73%)]\t Loss: 0.004826\t Remain : 0:24:27 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:3/4  Ep: 4/5 [70000/81928 (85%)]\t Loss: 0.005134\t Remain : 0:13:20 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:3/4  Ep: 4/5 [80000/81928 (98%)]\t Loss: 0.005391\t Remain : 0:02:13 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Finish\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0/27309 (0.0%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[10000/27309 (36.5%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[20000/27309 (73.0%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Avg val loss:0.005790261601023104\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:3/4  Ep: 5/5 [0/81928 (0%)]\t Loss: 0.005454\t Remain : 0:00:00 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:3/4  Ep: 5/5 [10000/81928 (12%)]\t Loss: 0.005059\t Remain : 1:19:53 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:3/4  Ep: 5/5 [20000/81928 (24%)]\t Loss: 0.005266\t Remain : 1:08:47 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:3/4  Ep: 5/5 [30000/81928 (37%)]\t Loss: 0.005574\t Remain : 0:57:42 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:3/4  Ep: 5/5 [40000/81928 (49%)]\t Loss: 0.005295\t Remain : 0:46:36 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:3/4  Ep: 5/5 [50000/81928 (61%)]\t Loss: 0.005155\t Remain : 0:35:30 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:3/4  Ep: 5/5 [60000/81928 (73%)]\t Loss: 0.005100\t Remain : 0:24:24 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:3/4  Ep: 5/5 [70000/81928 (85%)]\t Loss: 0.005361\t Remain : 0:13:18 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:3/4  Ep: 5/5 [80000/81928 (98%)]\t Loss: 0.004871\t Remain : 0:02:13 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Finish\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0/27309 (0.0%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[10000/27309 (36.5%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[20000/27309 (73.0%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Avg val loss:0.005793478370501395\n",
        "Load data from .h5 file...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Take 0:00:02 seconds\n",
        "Load data from .h5 file...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Take 0:00:07 seconds\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:4/4  Ep: 1/5 [0/81928 (0%)]\t Loss: 0.005526\t Remain : 0:00:00 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:4/4  Ep: 1/5 [10000/81928 (12%)]\t Loss: 0.006194\t Remain : 1:19:25 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:4/4  Ep: 1/5 [20000/81928 (24%)]\t Loss: 0.006144\t Remain : 1:08:23 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:4/4  Ep: 1/5 [30000/81928 (37%)]\t Loss: 0.005949\t Remain : 0:57:21 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:4/4  Ep: 1/5 [40000/81928 (49%)]\t Loss: 0.005632\t Remain : 0:46:19 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:4/4  Ep: 1/5 [50000/81928 (61%)]\t Loss: 0.005713\t Remain : 0:35:17 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:4/4  Ep: 1/5 [60000/81928 (73%)]\t Loss: 0.005023\t Remain : 0:24:15 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:4/4  Ep: 1/5 [70000/81928 (85%)]\t Loss: 0.005616\t Remain : 0:13:14 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:4/4  Ep: 1/5 [80000/81928 (98%)]\t Loss: 0.006079\t Remain : 0:02:12 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Finish\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0/27309 (0.0%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[10000/27309 (36.5%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[20000/27309 (73.0%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Avg val loss:0.005039506369222798\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:4/4  Ep: 2/5 [0/81928 (0%)]\t Loss: 0.004784\t Remain : 0:00:00 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:4/4  Ep: 2/5 [10000/81928 (12%)]\t Loss: 0.005094\t Remain : 1:19:10 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:4/4  Ep: 2/5 [20000/81928 (24%)]\t Loss: 0.004781\t Remain : 1:08:10 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:4/4  Ep: 2/5 [30000/81928 (37%)]\t Loss: 0.004486\t Remain : 0:57:11 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:4/4  Ep: 2/5 [40000/81928 (49%)]\t Loss: 0.004922\t Remain : 0:46:11 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:4/4  Ep: 2/5 [50000/81928 (61%)]\t Loss: 0.004385\t Remain : 0:35:11 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:4/4  Ep: 2/5 [60000/81928 (73%)]\t Loss: 0.004503\t Remain : 0:24:11 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:4/4  Ep: 2/5 [70000/81928 (85%)]\t Loss: 0.004223\t Remain : 0:13:11 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:4/4  Ep: 2/5 [80000/81928 (98%)]\t Loss: 0.004268\t Remain : 0:02:11 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Finish\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0/27309 (0.0%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[10000/27309 (36.5%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[20000/27309 (73.0%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Avg val loss:0.005028888513504044\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:4/4  Ep: 3/5 [0/81928 (0%)]\t Loss: 0.004071\t Remain : 0:00:00 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:4/4  Ep: 3/5 [10000/81928 (12%)]\t Loss: 0.004309\t Remain : 1:19:27 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:4/4  Ep: 3/5 [20000/81928 (24%)]\t Loss: 0.004151\t Remain : 1:08:25 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:4/4  Ep: 3/5 [30000/81928 (37%)]\t Loss: 0.004583\t Remain : 0:57:23 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:4/4  Ep: 3/5 [40000/81928 (49%)]\t Loss: 0.004549\t Remain : 0:46:21 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:4/4  Ep: 3/5 [50000/81928 (61%)]\t Loss: 0.004503\t Remain : 0:35:18 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:4/4  Ep: 3/5 [60000/81928 (73%)]\t Loss: 0.004520\t Remain : 0:24:16 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:4/4  Ep: 3/5 [70000/81928 (85%)]\t Loss: 0.004678\t Remain : 0:13:14 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:4/4  Ep: 3/5 [80000/81928 (98%)]\t Loss: 0.004722\t Remain : 0:02:12 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Finish\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0/27309 (0.0%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[10000/27309 (36.5%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[20000/27309 (73.0%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Avg val loss:0.00502500968584179\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:4/4  Ep: 4/5 [0/81928 (0%)]\t Loss: 0.004880\t Remain : 0:00:00 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:4/4  Ep: 4/5 [10000/81928 (12%)]\t Loss: 0.004506\t Remain : 1:19:41 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:4/4  Ep: 4/5 [20000/81928 (24%)]\t Loss: 0.004911\t Remain : 1:08:36 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:4/4  Ep: 4/5 [30000/81928 (37%)]\t Loss: 0.004993\t Remain : 0:57:32 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:4/4  Ep: 4/5 [40000/81928 (49%)]\t Loss: 0.004472\t Remain : 0:46:28 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:4/4  Ep: 4/5 [50000/81928 (61%)]\t Loss: 0.004571\t Remain : 0:35:24 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:4/4  Ep: 4/5 [60000/81928 (73%)]\t Loss: 0.004075\t Remain : 0:24:20 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:4/4  Ep: 4/5 [70000/81928 (85%)]\t Loss: 0.004537\t Remain : 0:13:16 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:4/4  Ep: 4/5 [80000/81928 (98%)]\t Loss: 0.004812\t Remain : 0:02:12 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Finish\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0/27309 (0.0%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[10000/27309 (36.5%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[20000/27309 (73.0%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Avg val loss:0.005017357856293555\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:4/4  Ep: 5/5 [0/81928 (0%)]\t Loss: 0.004916\t Remain : 0:00:00 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:4/4  Ep: 5/5 [10000/81928 (12%)]\t Loss: 0.004719\t Remain : 1:17:42 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:4/4  Ep: 5/5 [20000/81928 (24%)]\t Loss: 0.004458\t Remain : 1:06:54 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:4/4  Ep: 5/5 [30000/81928 (37%)]\t Loss: 0.004494\t Remain : 0:56:07 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:4/4  Ep: 5/5 [40000/81928 (49%)]\t Loss: 0.004567\t Remain : 0:45:19 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:4/4  Ep: 5/5 [50000/81928 (61%)]\t Loss: 0.004948\t Remain : 0:34:32 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:4/4  Ep: 5/5 [60000/81928 (73%)]\t Loss: 0.004279\t Remain : 0:23:44 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:4/4  Ep: 5/5 [70000/81928 (85%)]\t Loss: 0.004478\t Remain : 0:12:57 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Fold:4/4  Ep: 5/5 [80000/81928 (98%)]\t Loss: 0.004198\t Remain : 0:02:09 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Finish\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0/27309 (0.0%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[10000/27309 (36.5%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[20000/27309 (73.0%)]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Avg val loss:0.005020938285143815\n"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "torch.cuda.empty_cache()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "torch.save(model, 'net.pkl')\n",
      "#model = torch.load('net.pkl')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/opt/conda/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type SENet. It won't be checked for correctness upon loading.\n",
        "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
        "/opt/conda/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type SEResNeXtBottleneck. It won't be checked for correctness upon loading.\n",
        "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
        "/opt/conda/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type SEModule. It won't be checked for correctness upon loading.\n",
        "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = torch.load('ag_net_4k_5e.pkl')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "FileNotFoundError",
       "evalue": "[Errno 2] No such file or directory: 'ag_net_4k_5e.pkl'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
        "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-43-0864ba299479>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ag_net_4k_5e.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    379\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ag_net_4k_5e.pkl'"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def findPre(output,gate):\n",
      "    a = ''\n",
      "    output = np.array(output)\n",
      "    m = np.max(output)\n",
      "\n",
      "    for i in range(len(output)):\n",
      "        #s = np.where(v[i] > 0.95, 1, 0)\n",
      "        if output[i]>gate:\n",
      "            #print(output[i])\n",
      "            a = a + format(i)+' '\n",
      "            \n",
      "    #print(a)\n",
      "    return a\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def test(model,dloader,threshold):\n",
      "    model = model.eval().cuda()\n",
      "    #lengthD = len(dloader.dataset)\n",
      "    ans = []\n",
      "    out = []\n",
      "    for step, (x,x2, y) in enumerate(dloader):\n",
      "        data = Variable(x).cuda()\n",
      "        #data2 = Variable(x2).cuda()\n",
      "        #data = Variable(x)\n",
      "        target = y\n",
      "        #output = model(data,data2)\n",
      "        with torch.no_grad():\n",
      "            output = model(data).detach()\n",
      "        \n",
      "        #data.cpu()   # batch x\n",
      "        #data2.cpu()   # batch x\n",
      "        #target.cpu()   # batch y\n",
      "        #torch.cuda.empty_cache()\n",
      "        \n",
      "        v = output.cpu()\n",
      "        v = torch.sigmoid(v)\n",
      "        \n",
      "        v = torch.sigmoid(v)\n",
      "        v = np.array(v)\n",
      "        v = preprocessing.minmax_scale(v, feature_range=(0,1),axis=1)\n",
      "        for i in range(len(v)):\n",
      "            out.append(np.where(v[i] > threshold, 1, 0))\n",
      "            s = findPre(v[i],threshold)\n",
      "            ans.append([target[i],s])\n",
      "        if step %10 == 0:\n",
      "            print('[{}/{} ({:.1f}%)]'.format(step * len(data), \n",
      "                                        len(dloader.dataset),\n",
      "                                        100.*step/len(dloader)))\n",
      "            \n",
      "        data.cpu()\n",
      "        #data2.detach()\n",
      "        #target.detach()\n",
      "        torch.cuda.empty_cache()\n",
      "    print(\"Finish\")\n",
      "    return ans,out\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import fbeta_score\n",
      "\n",
      "def makeScore(pre,ans):\n",
      "    pre = np.array(pre)\n",
      "    va = fbeta_score(y_pred=pre, y_true=ans, beta=2, average=\"samples\")\n",
      "    print(\"Score : {:.5f}\".format(va))\n",
      "    return va\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def findThreshold():\n",
      "    score = []\n",
      "    candidates = np.arange(0, 1.0, 0.01)\n",
      "    for th in candidates:\n",
      "        print(\"Threshold : {:.2f}\".format(th))\n",
      "        _,pre = test(model = model,dloader = score_dataloader,threshold = th)\n",
      "        #return pre\n",
      "        score.append(makeScore(np.array(pre),np.array(train_a[:1000,1].tolist())))\n",
      "        print(\"=============================\")\n",
      "    pm = np.array(score).argmax()\n",
      "    best_th, best_score = candidates[pm], score[pm]\n",
      "    return best_th, best_score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bt, bs = findThreshold()\n",
      "print(\"Best Threshold : {:.2f}\".format(bt))\n",
      "print(\"Best Score : {:.5f}\".format(bs))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Threshold : 0.00\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.01485\n",
        "=============================\n",
        "Threshold : 0.01\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.26739\n",
        "=============================\n",
        "Threshold : 0.02\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.35817\n",
        "=============================\n",
        "Threshold : 0.03\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.42349\n",
        "=============================\n",
        "Threshold : 0.04\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.47302\n",
        "=============================\n",
        "Threshold : 0.05\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.50969\n",
        "=============================\n",
        "Threshold : 0.06\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.54215\n",
        "=============================\n",
        "Threshold : 0.07\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.56198\n",
        "=============================\n",
        "Threshold : 0.08\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.58430\n",
        "=============================\n",
        "Threshold : 0.09\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.60071\n",
        "=============================\n",
        "Threshold : 0.10\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.61466\n",
        "=============================\n",
        "Threshold : 0.11\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.62545\n",
        "=============================\n",
        "Threshold : 0.12\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.63513\n",
        "=============================\n",
        "Threshold : 0.13\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.64105\n",
        "=============================\n",
        "Threshold : 0.14\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.65070\n",
        "=============================\n",
        "Threshold : 0.15\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.65495\n",
        "=============================\n",
        "Threshold : 0.16\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.65725\n",
        "=============================\n",
        "Threshold : 0.17\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.66051\n",
        "=============================\n",
        "Threshold : 0.18\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.66598\n",
        "=============================\n",
        "Threshold : 0.19\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.66613\n",
        "=============================\n",
        "Threshold : 0.20\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.66525\n",
        "=============================\n",
        "Threshold : 0.21\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.66853\n",
        "=============================\n",
        "Threshold : 0.22\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.67215\n",
        "=============================\n",
        "Threshold : 0.23\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.67657\n",
        "=============================\n",
        "Threshold : 0.24\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.67874\n",
        "=============================\n",
        "Threshold : 0.25\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.67900\n",
        "=============================\n",
        "Threshold : 0.26\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.67547\n",
        "=============================\n",
        "Threshold : 0.27\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.67110\n",
        "=============================\n",
        "Threshold : 0.28\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.67388\n",
        "=============================\n",
        "Threshold : 0.29\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.67017\n",
        "=============================\n",
        "Threshold : 0.30\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.67153\n",
        "=============================\n",
        "Threshold : 0.31\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.66651\n",
        "=============================\n",
        "Threshold : 0.32\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.66907\n",
        "=============================\n",
        "Threshold : 0.33\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.66548\n",
        "=============================\n",
        "Threshold : 0.34\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.66851\n",
        "=============================\n",
        "Threshold : 0.35\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.66011\n",
        "=============================\n",
        "Threshold : 0.36\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.66087\n",
        "=============================\n",
        "Threshold : 0.37\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.66022\n",
        "=============================\n",
        "Threshold : 0.38\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.65694\n",
        "=============================\n",
        "Threshold : 0.39\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.65757\n",
        "=============================\n",
        "Threshold : 0.40\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.65588\n",
        "=============================\n",
        "Threshold : 0.41\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.64974\n",
        "=============================\n",
        "Threshold : 0.42\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.64063\n",
        "=============================\n",
        "Threshold : 0.43\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.63137\n",
        "=============================\n",
        "Threshold : 0.44\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.63948\n",
        "=============================\n",
        "Threshold : 0.45\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.62907\n",
        "=============================\n",
        "Threshold : 0.46\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.63170\n",
        "=============================\n",
        "Threshold : 0.47\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.62294\n",
        "=============================\n",
        "Threshold : 0.48\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.61683\n",
        "=============================\n",
        "Threshold : 0.49\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.62174\n",
        "=============================\n",
        "Threshold : 0.50\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.61883\n",
        "=============================\n",
        "Threshold : 0.51\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.61242\n",
        "=============================\n",
        "Threshold : 0.52\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.60240\n",
        "=============================\n",
        "Threshold : 0.53\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.59748\n",
        "=============================\n",
        "Threshold : 0.54\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.59112\n",
        "=============================\n",
        "Threshold : 0.55\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.59745\n",
        "=============================\n",
        "Threshold : 0.56\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.59848\n",
        "=============================\n",
        "Threshold : 0.57\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.59287\n",
        "=============================\n",
        "Threshold : 0.58\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.59069\n",
        "=============================\n",
        "Threshold : 0.59\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.58251\n",
        "=============================\n",
        "Threshold : 0.60\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.58646\n",
        "=============================\n",
        "Threshold : 0.61\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.57715\n",
        "=============================\n",
        "Threshold : 0.62\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.56666\n",
        "=============================\n",
        "Threshold : 0.63\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.56625\n",
        "=============================\n",
        "Threshold : 0.64\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.56532\n",
        "=============================\n",
        "Threshold : 0.65\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.55639\n",
        "=============================\n",
        "Threshold : 0.66\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.56219\n",
        "=============================\n",
        "Threshold : 0.67\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.56167\n",
        "=============================\n",
        "Threshold : 0.68\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.54543\n",
        "=============================\n",
        "Threshold : 0.69\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.54571\n",
        "=============================\n",
        "Threshold : 0.70\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.53811\n",
        "=============================\n",
        "Threshold : 0.71\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.53989\n",
        "=============================\n",
        "Threshold : 0.72\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.53536\n",
        "=============================\n",
        "Threshold : 0.73\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.52467\n",
        "=============================\n",
        "Threshold : 0.74\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.51751\n",
        "=============================\n",
        "Threshold : 0.75\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.52003\n",
        "=============================\n",
        "Threshold : 0.76\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.51937\n",
        "=============================\n",
        "Threshold : 0.77\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.50724\n",
        "=============================\n",
        "Threshold : 0.78\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.50691\n",
        "=============================\n",
        "Threshold : 0.79\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.49654\n",
        "=============================\n",
        "Threshold : 0.80\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.50539\n",
        "=============================\n",
        "Threshold : 0.81\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.49205\n",
        "=============================\n",
        "Threshold : 0.82\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.48559\n",
        "=============================\n",
        "Threshold : 0.83\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.47974\n",
        "=============================\n",
        "Threshold : 0.84\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.47620\n",
        "=============================\n",
        "Threshold : 0.85\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.46767\n",
        "=============================\n",
        "Threshold : 0.86\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.46845\n",
        "=============================\n",
        "Threshold : 0.87\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.46134\n",
        "=============================\n",
        "Threshold : 0.88\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.45142\n",
        "=============================\n",
        "Threshold : 0.89\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.44587\n",
        "=============================\n",
        "Threshold : 0.90\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.43968\n",
        "=============================\n",
        "Threshold : 0.91\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.43281\n",
        "=============================\n",
        "Threshold : 0.92\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.43084\n",
        "=============================\n",
        "Threshold : 0.93\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.42357\n",
        "=============================\n",
        "Threshold : 0.94\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.41901\n",
        "=============================\n",
        "Threshold : 0.95\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.40715\n",
        "=============================\n",
        "Threshold : 0.96\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.39934\n",
        "=============================\n",
        "Threshold : 0.97\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.39459\n",
        "=============================\n",
        "Threshold : 0.98\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.38638\n",
        "=============================\n",
        "Threshold : 0.99\n",
        "[0/1000 (0.0%)]\n",
        "Finish\n",
        "Score : 0.36602\n",
        "=============================\n",
        "Best Threshold : 0.25\n",
        "Best Score : 0.67900\n"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "torch.cuda.empty_cache()\n",
      "!nvidia-smi"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fri Nov 22 11:52:41 2019       \n",
        "+-----------------------------------------------------------------------------+\n",
        "| NVIDIA-SMI 418.56       Driver Version: 418.56       CUDA Version: 10.1     |\n",
        "|-------------------------------+----------------------+----------------------+\n",
        "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
        "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
        "|===============================+======================+======================|\n",
        "|   0  GeForce GTX 108...  Off  | 00000000:01:00.0  On |                  N/A |\n",
        "| 55%   76C    P2    81W / 250W |   2007MiB / 11175MiB |      5%      Default |\n",
        "+-------------------------------+----------------------+----------------------+\n",
        "|   1  GeForce GTX 108...  Off  | 00000000:02:00.0 Off |                  N/A |\n",
        "| 42%   69C    P2    76W / 250W |    621MiB / 11178MiB |      0%      Default |\n",
        "+-------------------------------+----------------------+----------------------+\n",
        "                                                                               \n",
        "+-----------------------------------------------------------------------------+\n",
        "| Processes:                                                       GPU Memory |\n",
        "|  GPU       PID   Type   Process name                             Usage      |\n",
        "|=============================================================================|\n",
        "|    0      1137      G   /usr/lib/xorg/Xorg                            80MiB |\n",
        "|    0      2214      G   /opt/teamviewer/tv_bin/TeamViewer              2MiB |\n",
        "|    0     12945      G   ...uest-channel-token=14083820793621432878    85MiB |\n",
        "|    0     22250      G   /usr/lib/xorg/Xorg                           172MiB |\n",
        "|    0     22494      G                                                  4MiB |\n",
        "|    0     22924      G   compiz                                       140MiB |\n",
        "|    0     23722      G   /usr/lib/firefox/firefox                       2MiB |\n",
        "|    0     25016      C   /home/user1/pytorch_g/bin/python            1381MiB |\n",
        "|    0     31156      G   ...uest-channel-token=12496746042476819744    88MiB |\n",
        "|    1     25016      C   /home/user1/pytorch_g/bin/python             607MiB |\n",
        "+-----------------------------------------------------------------------------+\n"
       ]
      }
     ],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sub,_ = test(model = model,dloader = test_dataloader,threshold = bt)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "TypeError",
       "evalue": "'DataFrame' object is not callable",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
        "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-77-63d2bacc5a25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msub\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mTypeError\u001b[0m: 'DataFrame' object is not callable"
       ]
      }
     ],
     "prompt_number": 77
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#print(sub)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sub =  pd.DataFrame(sub)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sub = sub.rename(index=str, columns={0: \"id\", 1: \"attribute_ids\"})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sub.head"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sub.to_csv('submission.csv', index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    }
   ],
   "metadata": {}
  }
 ]
}
